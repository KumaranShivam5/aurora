{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt \n",
    "np.random.seed(91828)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def class_to_int(label , cl):\n",
    "    temp = []\n",
    "    for i in range(len(label)):\n",
    "        #print(label[i])\n",
    "        for j in range(len(cl)):\n",
    "            if(label[i]==cl[j]):\n",
    "                temp.append(j) \n",
    "    return temp\n",
    "classes = ['BH' ,'NS' ]\n",
    "ns_n = 0 \n",
    "bh_n = 0\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "def get_xy(data):\n",
    "    y = data['class']\n",
    "    s = data['significance']\n",
    "    info = data[['src_n' , 'src_id']]\n",
    "    x = data.drop(columns=[ 'class' ,'src_n' ,'src_id' , 'significance'])\n",
    "    #display(x)\n",
    "    y_train_int = class_to_int(y, classes)\n",
    "    one_hot_y_train =  to_categorical(y_train_int)\n",
    "    global ns_n \n",
    "    global bh_n\n",
    "    ns_n = float(y.value_counts()['NS']) \n",
    "    bh_n =  float(y.value_counts()['BH'])    \n",
    "    print(ns_n , bh_n)\n",
    "    return x , one_hot_y_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def fit_model(model , x_train , one_hot_y_train , verbose=0 , validation=0.2):\n",
    "    global ns_n \n",
    "    global bh_n \n",
    "    class_weight = {0: (ns_n/bh_n),\n",
    "                    1: 1}\n",
    "    history = model.fit(x_train, one_hot_y_train, batch_size=64, epochs=120, validation_split=validation, class_weight=class_weight, verbose=verbose )\n",
    "    return history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def res_score(model , x , y ):\n",
    "    y_prob = model.predict(x)\n",
    "    y_pred = np.zeros_like(y_prob)\n",
    "    y_pred[np.arange(len(y_prob)), y_prob.argmax(1)] = 1\n",
    "    cf = np.matrix(np.matmul(y.T , y_pred))\n",
    "    total = cf.sum()\n",
    "    row_sum = cf.sum(axis=0)\n",
    "    acc = np.trace(cf) / total \n",
    "    col_sum = cf.sum(axis=1) \n",
    "    #print(cf)\n",
    "    return cf , acc\n",
    "\n",
    "\n",
    "#_ , score = res_score(model , x , one_hot_y_train)\n",
    "#print(score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "def mc_validation(model_func = '' , x = '' , split_data = '' , s=0.8 , model_name = '' , d_type = '' , impute_method = ''):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kfold = KFold(8, True, 1)\n",
    "    #k-fold cross-validation\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    index = np.arange(0,len(x))\n",
    "    split_no = int(len(x)*s)\n",
    "    print('split_no' , split_no)\n",
    "    np.random.shuffle(index)\n",
    "    data = x.copy()\n",
    "    data = data.sample(frac=1)\n",
    "    x =  data.drop(columns=['class' , 'src_n' ,'src_id' ,'significance'])\n",
    "    y = data['class']\n",
    "    for i in tqdm(range(32)):\n",
    "        x_train , x_test , y_train , y_test = train_test_split(x,y , test_size=0.2 , stratify=y)\n",
    "        x_train.insert(0 , 'class' , y_train)\n",
    "        x_test.insert(0 , 'class' , y_test)\n",
    "        #x_train , x_test = split_data(data)\n",
    "        tf_data_train = tfdf.keras.pd_dataframe_to_tf_dataset(x_train,label=\"class\")\n",
    "        tf_data_test = tfdf.keras.pd_dataframe_to_tf_dataset(x_test,label=\"class\")\n",
    "        model = model_func()\n",
    "        with sys_pipes():\n",
    "            model.fit(tf_data_train)\n",
    "        model.compile(metrics=['accuracy'])\n",
    "\n",
    "        evaluation = model.evaluate(tf_data_train, return_dict=True)\n",
    "        _ ,  train_acc_temp = evaluation.items()\n",
    "        train_acc_temp = train_acc_temp[1]\n",
    "        evaluation = model.evaluate(tf_data_test, return_dict=True)\n",
    "        _ ,  test_acc_temp = evaluation.items()\n",
    "        test_acc_temp = test_acc_temp[1]\n",
    "        #_,train_acc_temp = res_score(model , xtr , ytr)\n",
    "        #_,test_acc_temp = res_score(model , xtst , ytst)\n",
    "        train_acc.append(train_acc_temp)\n",
    "        test_acc.append(test_acc_temp)\n",
    "        #print('-----------------------------------')\n",
    "        #print('training_acc :' , train_acc_temp)\n",
    "        #print('test_acc :' , test_acc_temp)\n",
    "    acc_train =  pd.DataFrame()\n",
    "    acc_test = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    acc_test.insert(0 , 'acc_type' , ['Test_acc']*len(train_acc))\n",
    "    acc_test.insert(1 , 'accuracy' , test_acc)\n",
    "    acc_test = acc_test.reset_index(drop=True)\n",
    "   \n",
    "    acc_train.insert(0 , 'acc_type' , ['Train_acc']*len(train_acc))\n",
    "    acc_train.insert(1 , 'accuracy' , train_acc)\n",
    "    acc_train = acc_train.reset_index(drop=True)\n",
    "\n",
    "    acc = pd.concat([acc_train , acc_test]).reset_index(drop=True)\n",
    "    acc.insert(0 , 'model' , [model_name]*len(acc))\n",
    "    acc.insert(1 , 'data_processing' , [d_type]*len(acc))\n",
    "    acc.insert(1 , 'impute_method' , [impute_method]*len(acc))\n",
    "    return acc\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def src_split(data_sent , s = (5 , 8) ):\n",
    "    data = data_sent.copy().reset_index(drop=True)\n",
    "    data_bh =  data[data['class']=='BH'].sample(frac=1)\n",
    "    data_ns =  data[data['class']=='NS'].sample(frac=1)\n",
    "    n_bh  , n_ns = s \n",
    "    \n",
    "    src_bh =  np.unique(data_bh['src_id'])\n",
    "    np.random.shuffle(src_bh)\n",
    "    src_ns = np.unique(data_ns['src_id'])\n",
    "    np.random.shuffle(src_ns)\n",
    "    s_bh = len(src_bh) - n_bh \n",
    "    s_ns = len(src_ns) - n_ns \n",
    "    print(s_bh , s_ns)\n",
    "    src_bh_train = src_bh[:s_bh]\n",
    "    src_bh_test = src_bh[s_bh:]\n",
    "    src_ns_train = src_ns[:s_ns]\n",
    "    src_ns_test = src_ns[s_ns:]\n",
    "    print(src_bh_test)\n",
    "    train_bh = data_bh[data_bh['src_id'].isin(src_bh_train)].reset_index(drop=True)\n",
    "    test_bh = data_bh[data_bh['src_id'].isin(src_bh_test)].reset_index(drop=True)\n",
    "\n",
    "    train_ns = data_ns[data_ns['src_id'].isin(src_ns_train)].reset_index(drop=True)\n",
    "    test_ns = data_ns[data_ns['src_id'].isin(src_ns_test)].reset_index(drop=True)\n",
    "\n",
    "    train = pd.concat([train_bh , train_ns]).reset_index(drop=True)\n",
    "    train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    test = pd.concat([test_bh , test_ns]).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    return train , test \n",
    "\n",
    "def obs_split(data_sent , s = 0.8):\n",
    "    data = data_sent.copy()\n",
    "    data = data.sample(frac=1)\n",
    "    split_no = int(len(data)*s)\n",
    "    train = data[:split_no]\n",
    "    test = data[split_no:]\n",
    "    return train, test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "data_norm = pd.read_csv('processed_data/train_norm' , index_col=0).reset_index(drop=True)\n",
    "data_std = pd.read_csv('processed_data/train_std' , index_col=0).reset_index(drop=True)\n",
    "data_og = pd.read_csv('processed_data/train_og' , index_col=0).reset_index(drop=True)\n",
    "data_norm.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  class                 src_n  src_id  significance  flux_aper_hilim_s  \\\n",
       "0    NS  XMMU J004245.2+41172  NS0044         49.26           0.440071   \n",
       "1    NS  GRS 1741.9-2853       NS0021        376.06           0.344546   \n",
       "\n",
       "   flux_aper_hilim_u  flux_aper_hilim_m  flux_aper_hilim_h  flux_aper_hilim_b  \\\n",
       "0           0.357367           0.418632           0.398875           0.439279   \n",
       "1           0.000000           0.305586           0.534511           0.477879   \n",
       "\n",
       "   flux_aper_lolim_s  ...  flux_brems  flux_brems_lolim  flux_brems_hilim  \\\n",
       "0           0.510417  ...         0.0               0.0               0.0   \n",
       "1           0.000000  ...         0.0               0.0               0.0   \n",
       "\n",
       "   brems_kt  brems_kt_hilim  brems_kt_lolim  brems_nh  brems_nh_hilim  \\\n",
       "0       0.0             0.0             0.0       0.0             0.0   \n",
       "1       0.0             0.0             0.0       0.0             0.0   \n",
       "\n",
       "   brems_nh_lolim  brems_stat  \n",
       "0             0.0         0.0  \n",
       "1             0.0         0.0  \n",
       "\n",
       "[2 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>src_n</th>\n",
       "      <th>src_id</th>\n",
       "      <th>significance</th>\n",
       "      <th>flux_aper_hilim_s</th>\n",
       "      <th>flux_aper_hilim_u</th>\n",
       "      <th>flux_aper_hilim_m</th>\n",
       "      <th>flux_aper_hilim_h</th>\n",
       "      <th>flux_aper_hilim_b</th>\n",
       "      <th>flux_aper_lolim_s</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_brems</th>\n",
       "      <th>flux_brems_lolim</th>\n",
       "      <th>flux_brems_hilim</th>\n",
       "      <th>brems_kt</th>\n",
       "      <th>brems_kt_hilim</th>\n",
       "      <th>brems_kt_lolim</th>\n",
       "      <th>brems_nh</th>\n",
       "      <th>brems_nh_hilim</th>\n",
       "      <th>brems_nh_lolim</th>\n",
       "      <th>brems_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NS</td>\n",
       "      <td>XMMU J004245.2+41172</td>\n",
       "      <td>NS0044</td>\n",
       "      <td>49.26</td>\n",
       "      <td>0.440071</td>\n",
       "      <td>0.357367</td>\n",
       "      <td>0.418632</td>\n",
       "      <td>0.398875</td>\n",
       "      <td>0.439279</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NS</td>\n",
       "      <td>GRS 1741.9-2853</td>\n",
       "      <td>NS0021</td>\n",
       "      <td>376.06</td>\n",
       "      <td>0.344546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305586</td>\n",
       "      <td>0.534511</td>\n",
       "      <td>0.477879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 96 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "data_nan = pd.read_csv('processed_data/train_norm_no' , index_col=0).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keras Random Forest Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "from wurlitzer import sys_pipes\n",
    "gen_model_rf =  tfdf.keras.RandomForestModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "acc_norm_nan_rf = mc_validation(gen_model_rf , data_nan, obs_split ,model_name = 'RF' , d_type='Normalized' , impute_method='No_impute')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kumaran/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass shuffle=True, random_state=1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "split_no 368\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:320 (86.9565%) mean:0.097847 min:0 max:0.451509 sd:0.132329\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.118775 min:0 max:0.603673 sd:0.161189\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0781388 min:0 max:0.388463 sd:0.110101\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:320 (86.9565%) mean:0.176675 min:0.00335387 max:1 sd:0.207\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.026462 min:0.000195345 max:1 sd:0.14219\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.156263 min:0.000481116 max:1 sd:0.173259\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0759197 min:0 max:1 sd:0.185819\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0964857 min:0 max:1 sd:0.231583\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:339 (92.1196%) mean:0.102026 min:0 max:1 sd:0.206078\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.185603 min:0 max:1 sd:0.155751\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:320 (86.9565%) mean:0.0976659 min:0 max:1 sd:0.246025\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.120919 min:0 max:1 sd:0.191203\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0580182 min:0 max:1 sd:0.152944\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0986821 min:5.72011e-11 max:1 sd:0.20559\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.103281 min:0 max:1 sd:0.220815\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0931012 min:0 max:1 sd:0.192524\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.0854848 min:0 max:0.570059 sd:0.0797462\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.521295 min:0 max:1 sd:0.186255\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.486886 min:0 max:1 sd:0.189378\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:67 (18.2065%) mean:0.473113 min:0.0451185 max:1 sd:0.186756\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.495676 min:0 max:1 sd:0.185158\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.506812 min:0 max:1 sd:0.18901\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.491733 min:0 max:1 sd:0.189247\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:20 (5.43478%) mean:0.438802 min:0 max:1 sd:0.185336\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.435482 min:0 max:1 sd:0.200754\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:97 (26.3587%) mean:0.4007 min:0 max:1 sd:0.195803\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.573827 min:0 max:1 sd:0.178304\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.524687 min:0.0378418 max:1 sd:0.185762\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.512923 min:0.0544485 max:1 sd:0.187971\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.492528 min:0 max:1 sd:0.198807\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.519279 min:0 max:1 sd:0.197417\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:308 (83.6957%) mean:0.44229 min:0 max:1 sd:0.199071\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.418689 min:0 max:1 sd:0.205859\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:123 (33.4239%) mean:0.420255 min:0 max:1 sd:0.21813\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:302 (82.0652%) mean:0.392847 min:0.0423683 max:1 sd:0.187074\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:320 (86.9565%) mean:0.206163 min:0 max:1 sd:0.26566\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.200481 min:0 max:1 sd:0.264993\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.194451 min:0 max:1 sd:0.254794\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:320 (86.9565%) mean:0.209461 min:0.000264866 max:1 sd:0.266158\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.213517 min:0.000264511 max:1 sd:0.268384\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.200151 min:0.00023666 max:1 sd:0.258651\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:320 (86.9565%) mean:0.203074 min:0 max:1 sd:0.253454\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.205338 min:0.000269833 max:1 sd:0.256569\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.193232 min:0 max:1 sd:0.236769\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:19 (5.16304%) mean:0.630472 min:0 max:1 sd:0.314012\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.703754 min:0 max:1 sd:0.275279\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.489413 min:0 max:1 sd:0.277329\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.560245 min:0 max:1 sd:0.357186\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.657014 min:0 max:1 sd:0.310317\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.42763 min:0 max:1 sd:0.324904\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:29 (7.88043%) mean:0.429884 min:0 max:1 sd:0.323002\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:29 (7.88043%) mean:0.590376 min:0.0466496 max:1 sd:0.24974\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:29 (7.88043%) mean:0.348784 min:0 max:1 sd:0.277307\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:112 (30.4348%) mean:0.517454 min:0 max:1 sd:0.226188\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:112 (30.4348%) mean:0.519529 min:0 max:1 sd:0.242311\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.521393 min:0 max:1 sd:0.173589\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.476564 min:0 max:1 sd:0.183634\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:60 (16.3043%) mean:0.464787 min:0.0410427 max:1 sd:0.185228\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.518657 min:0 max:1 sd:0.199396\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.46192 min:0 max:1 sd:0.184685\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.460883 min:0 max:1 sd:0.1961\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.465431 min:0.00394213 max:1 sd:0.200715\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.432138 min:0 max:1 sd:0.202362\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:64 (17.3913%) mean:0.430943 min:0 max:1 sd:0.249453\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.572539 min:0 max:1 sd:0.173917\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.53423 min:0.0234328 max:1 sd:0.177946\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:73 (19.837%) mean:0.494833 min:0.0401454 max:1 sd:0.189064\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:118 (32.0652%) mean:0.527223 min:0 max:1 sd:0.208764\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.539713 min:0 max:1 sd:0.191418\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:269 (73.0978%) mean:0.444077 min:0 max:0.971545 sd:0.214979\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.452557 min:0 max:1 sd:0.22167\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:122 (33.1522%) mean:0.456068 min:0 max:1 sd:0.205777\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:256 (69.5652%) mean:0.349093 min:0.00939159 max:1 sd:0.24683\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:320 (86.9565%) mean:0.0255327 min:0 max:1 sd:0.14297\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0438989 min:0 max:1 sd:0.144204\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0257175 min:0 max:1 sd:0.142865\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:320 (86.9565%) mean:0.40804 min:0 max:1 sd:0.23556\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.397187 min:0 max:1 sd:0.235186\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.522195 min:0 max:1 sd:0.200925\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0958349 min:0 max:1 sd:0.182394\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.119832 min:0 max:1 sd:0.232346\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0808934 min:0.000337785 max:1 sd:0.165887\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.137966 min:0 max:1 sd:0.139661\n",
      "\t83: \"var_index\" NUMERICAL num-nas:112 (30.4348%) mean:0.0823143 min:0 max:1 sd:0.141919\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:33 (8.96739%) mean:0.755417 min:0 max:1 sd:0.274125\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:33 (8.96739%) mean:0.808427 min:0 max:1 sd:0.235373\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:33 (8.96739%) mean:0.0240861 min:0 max:1 sd:0.0903962\n",
      "\t87: \"var_max\" NUMERICAL num-nas:112 (30.4348%) mean:0.00820551 min:0 max:0.233918 sd:0.0232907\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:112 (30.4348%) mean:0.0468724 min:0 max:1 sd:0.112842\n",
      "\t89: \"var_min\" NUMERICAL num-nas:112 (30.4348%) mean:0.0395653 min:0 max:1 sd:0.106212\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:112 (30.4348%) mean:0.429598 min:0 max:1 sd:0.168307\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:112 (30.4348%) mean:0.0045676 min:0 max:0.226755 sd:0.01991\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:1) done accuracy:0.776923 logloss:8.04051\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:12) done accuracy:0.850543 logloss:1.39263\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.88587 logloss:0.457717\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:33) done accuracy:0.899457 logloss:0.441206\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.902174 logloss:0.254527\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.904891 logloss:0.256141\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:61) done accuracy:0.907609 logloss:0.257384\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:71) done accuracy:0.910326 logloss:0.25239\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:66) done accuracy:0.915761 logloss:0.249836\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.915761 logloss:0.249124\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:94) done accuracy:0.918478 logloss:0.247254\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.913043 logloss:0.248472\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.923913 logloss:0.24463\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:129) done accuracy:0.918478 logloss:0.243275\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:126) done accuracy:0.918478 logloss:0.246963\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:148) done accuracy:0.915761 logloss:0.243809\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.921196 logloss:0.242627\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:169) done accuracy:0.921196 logloss:0.242771\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.921196 logloss:0.24325\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:191) done accuracy:0.918478 logloss:0.2431\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:200) done accuracy:0.918478 logloss:0.243111\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.921196 logloss:0.241332\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:220) done accuracy:0.921196 logloss:0.239835\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:230) done accuracy:0.921196 logloss:0.239695\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:242) done accuracy:0.918478 logloss:0.240832\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.918478 logloss:0.240844\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.918478 logloss:0.239876\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:268) done accuracy:0.921196 logloss:0.238933\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:282) done accuracy:0.921196 logloss:0.238699\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:290) done accuracy:0.918478 logloss:0.238957\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.921196 logloss:0.238769\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.921196 logloss:0.238769\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpypgbqfjw\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12706 node(s), and 92 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.8804\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 1/32 [00:05<03:00,  5.82s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 9ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.102743 min:7.20293e-05 max:1 sd:0.187407\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.113087 min:7.14336e-05 max:1 sd:0.19683\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0903425 min:3.5212e-05 max:1 sd:0.178484\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.164191 min:0 max:0.660713 sd:0.129323\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.00568078 min:0 max:0.02396 sd:0.00471527\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.151554 min:0 max:0.586641 sd:0.115893\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0764563 min:1.74113e-10 max:1 sd:0.191597\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0884855 min:0 max:1 sd:0.209837\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:345 (93.75%) mean:0.124751 min:0.00246435 max:1 sd:0.228647\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.177704 min:0 max:0.449374 sd:0.101145\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.0655724 min:0.00115672 max:1 sd:0.165963\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:327 (88.8587%) mean:0.155872 min:0.00400707 max:1 sd:0.210285\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0429025 min:0.00112057 max:0.398003 sd:0.0693929\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0954175 min:0 max:1 sd:0.199104\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0967777 min:0 max:0.917609 sd:0.194264\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.0937223 min:0 max:1 sd:0.193818\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.0952234 min:0 max:1 sd:0.144115\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.523008 min:0 max:1 sd:0.183253\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:31 (8.42391%) mean:0.489084 min:0 max:1 sd:0.186028\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:65 (17.663%) mean:0.471513 min:0 max:1 sd:0.188531\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.49886 min:0 max:0.973154 sd:0.179758\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.509959 min:0 max:1 sd:0.185285\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.497307 min:0 max:1 sd:0.18311\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.442334 min:0 max:1 sd:0.179279\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.437365 min:0.0587585 max:1 sd:0.199886\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:94 (25.5435%) mean:0.406424 min:0 max:0.836502 sd:0.189845\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:12 (3.26087%) mean:0.575256 min:0 max:1 sd:0.177229\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.526678 min:0 max:1 sd:0.183694\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.510184 min:0.000319932 max:1 sd:0.189509\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.494541 min:0 max:1 sd:0.194076\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.512074 min:0 max:1 sd:0.201504\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:308 (83.6957%) mean:0.432258 min:0.0665289 max:0.933891 sd:0.185652\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:108 (29.3478%) mean:0.422654 min:0 max:1 sd:0.198383\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.41774 min:0 max:1 sd:0.220561\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:301 (81.7935%) mean:0.382269 min:0 max:0.84848 sd:0.172331\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:325 (88.3152%) mean:0.197726 min:0.000411857 max:1 sd:0.25383\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.183697 min:0.00028293 max:0.928857 sd:0.233595\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.195816 min:0.00186887 max:1 sd:0.25192\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:325 (88.3152%) mean:0.208258 min:0 max:1 sd:0.263688\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.211325 min:0 max:1 sd:0.265146\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.200526 min:0 max:1 sd:0.258036\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:325 (88.3152%) mean:0.202041 min:0.00172566 max:1 sd:0.249552\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.203625 min:0 max:1 sd:0.252115\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.192519 min:0.00273806 max:1 sd:0.23337\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.642659 min:0 max:1 sd:0.305181\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.716621 min:0.0642085 max:1 sd:0.262496\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.495142 min:0 max:1 sd:0.267909\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.564831 min:0 max:1 sd:0.354439\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.663908 min:0.0327086 max:1 sd:0.304097\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.431431 min:0 max:1 sd:0.32247\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:27 (7.33696%) mean:0.427223 min:0 max:1 sd:0.32665\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:27 (7.33696%) mean:0.590123 min:0 max:1 sd:0.255251\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:27 (7.33696%) mean:0.347456 min:0 max:1 sd:0.286098\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:122 (33.1522%) mean:0.495128 min:0 max:0.999799 sd:0.22956\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:122 (33.1522%) mean:0.505688 min:0.00905979 max:0.999094 sd:0.242191\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.521918 min:0 max:1 sd:0.172406\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.476257 min:0 max:1 sd:0.181704\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:59 (16.0326%) mean:0.463245 min:0 max:1 sd:0.185588\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.524347 min:0 max:1 sd:0.1967\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.462381 min:0 max:1 sd:0.182444\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.464417 min:0 max:1 sd:0.191701\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.4647 min:0 max:0.990302 sd:0.197146\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.432289 min:0.05674 max:1 sd:0.199604\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.446071 min:0 max:1 sd:0.249756\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.571737 min:0 max:1 sd:0.173328\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.531961 min:0.0234328 max:1 sd:0.177757\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:73 (19.837%) mean:0.491958 min:0 max:1 sd:0.189897\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:121 (32.8804%) mean:0.527672 min:0 max:0.995568 sd:0.203371\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.532189 min:0 max:1 sd:0.193271\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:271 (73.6413%) mean:0.445231 min:0 max:1 sd:0.219289\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.457794 min:0.000368284 max:0.991934 sd:0.213294\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.453036 min:0 max:1 sd:0.204484\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:259 (70.3804%) mean:0.358443 min:0 max:1 sd:0.255543\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0256856 min:4.38688e-06 max:1 sd:0.150383\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0224128 min:4.1493e-05 max:0.117754 sd:0.031791\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0260354 min:1.80406e-05 max:1 sd:0.150352\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:325 (88.3152%) mean:0.360087 min:0.0838464 max:0.785254 sd:0.178411\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.343986 min:0.0823497 max:0.785308 sd:0.180381\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.486253 min:0.233913 max:0.827135 sd:0.149762\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0965438 min:0.00234924 max:1 sd:0.190982\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.11217 min:0.00353616 max:1 sd:0.215086\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0841649 min:0 max:1 sd:0.175895\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.121098 min:0.0100233 max:0.273193 sd:0.0577552\n",
      "\t83: \"var_index\" NUMERICAL num-nas:122 (33.1522%) mean:0.0738114 min:0 max:1 sd:0.133424\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:34 (9.23913%) mean:0.750206 min:0 max:1 sd:0.278419\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:34 (9.23913%) mean:0.801795 min:0 max:1 sd:0.240521\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:34 (9.23913%) mean:0.0261703 min:2.13771e-07 max:1 sd:0.0946912\n",
      "\t87: \"var_max\" NUMERICAL num-nas:122 (33.1522%) mean:0.0114919 min:1.72134e-05 max:1 sd:0.0658229\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:122 (33.1522%) mean:0.0488846 min:0.000192368 max:1 sd:0.114314\n",
      "\t89: \"var_min\" NUMERICAL num-nas:122 (33.1522%) mean:0.0409651 min:6.0313e-05 max:1 sd:0.105615\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:122 (33.1522%) mean:0.417578 min:0.0066253 max:1 sd:0.17421\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:122 (33.1522%) mean:0.00769224 min:0 max:1 sd:0.0650335\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:0) done accuracy:0.854015 logloss:5.26185\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.857534 logloss:1.95353\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.866848 logloss:0.440528\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.896739 logloss:0.338518\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:39) done accuracy:0.894022 logloss:0.353098\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:49) done accuracy:0.902174 logloss:0.349637\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.907609 logloss:0.346169\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:71) done accuracy:0.904891 logloss:0.34637\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:81) done accuracy:0.904891 logloss:0.349385\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.907609 logloss:0.259787\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:102) done accuracy:0.904891 logloss:0.259156\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:112) done accuracy:0.904891 logloss:0.257347\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.913043 logloss:0.249631\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:101) done accuracy:0.910326 logloss:0.249873\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.904891 logloss:0.252157\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.902174 logloss:0.249873\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.910326 logloss:0.249268\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.904891 logloss:0.247532\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:161) done accuracy:0.907609 logloss:0.247849\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:192) done accuracy:0.907609 logloss:0.248615\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:199) done accuracy:0.907609 logloss:0.248507\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.904891 logloss:0.247585\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:220) done accuracy:0.904891 logloss:0.246794\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:225) done accuracy:0.904891 logloss:0.246909\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:242) done accuracy:0.902174 logloss:0.247521\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:251) done accuracy:0.907609 logloss:0.247177\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:261) done accuracy:0.904891 logloss:0.247913\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:269) done accuracy:0.904891 logloss:0.246919\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:284) done accuracy:0.907609 logloss:0.24627\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:293) done accuracy:0.907609 logloss:0.247459\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:296) done accuracy:0.913043 logloss:0.247415\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.913043 logloss:0.247415\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp41cjma26\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12834 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.8804\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  6%|▋         | 2/32 [00:09<02:23,  4.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:323 (87.7717%) mean:0.0994784 min:0 max:1 sd:0.180675\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.112206 min:0 max:1 sd:0.189858\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0866123 min:0 max:1 sd:0.173349\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:323 (87.7717%) mean:0.174813 min:0 max:1 sd:0.209552\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0277987 min:0 max:1 sd:0.146752\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.153278 min:0 max:1 sd:0.173369\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:323 (87.7717%) mean:0.059508 min:0 max:0.496254 sd:0.138493\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0825511 min:0 max:0.978189 sd:0.204206\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:345 (93.75%) mean:0.0851413 min:0.00246435 max:0.427298 sd:0.13336\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:323 (87.7717%) mean:0.197299 min:0.0344311 max:1 sd:0.153289\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:323 (87.7717%) mean:0.0823219 min:0.000481551 max:1 sd:0.213834\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.132308 min:0.00182679 max:1 sd:0.196027\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0534132 min:0.000412191 max:1 sd:0.148885\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:323 (87.7717%) mean:0.0819777 min:0 max:0.726902 sd:0.170222\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0911659 min:0 max:1 sd:0.199513\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0758993 min:0 max:0.58012 sd:0.148207\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:323 (87.7717%) mean:0.106891 min:0.0140926 max:1 sd:0.157198\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.520943 min:0 max:0.988978 sd:0.180984\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.479763 min:0 max:1 sd:0.188742\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:68 (18.4783%) mean:0.463786 min:0 max:0.980907 sd:0.190061\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.494856 min:0 max:1 sd:0.181691\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.503909 min:0 max:1 sd:0.186007\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:9 (2.44565%) mean:0.487348 min:0 max:0.980704 sd:0.188333\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.440538 min:0 max:1 sd:0.179625\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.435191 min:0 max:1 sd:0.201614\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:91 (24.7283%) mean:0.403323 min:0.0521682 max:1 sd:0.194046\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.572039 min:0 max:0.990661 sd:0.174939\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:40 (10.8696%) mean:0.518875 min:0 max:1 sd:0.184892\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:82 (22.2826%) mean:0.505534 min:0 max:0.985639 sd:0.191409\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.488574 min:0 max:1 sd:0.19371\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.520029 min:0.0265645 max:1 sd:0.201327\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:306 (83.1522%) mean:0.458842 min:0.020997 max:1 sd:0.200888\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:103 (27.9891%) mean:0.414531 min:0.0091239 max:1 sd:0.200856\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.4224 min:0.00700149 max:1 sd:0.221132\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:298 (80.9783%) mean:0.392841 min:0 max:1 sd:0.193945\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:323 (87.7717%) mean:0.180393 min:0 max:0.949443 sd:0.234598\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.176375 min:0 max:1 sd:0.240041\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.170803 min:0 max:1 sd:0.224733\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:323 (87.7717%) mean:0.183895 min:0 max:1 sd:0.238972\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.187078 min:0 max:1 sd:0.239813\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.177873 min:0 max:1 sd:0.23724\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:323 (87.7717%) mean:0.181147 min:0 max:1 sd:0.230441\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.182238 min:0 max:1 sd:0.23161\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.176754 min:0 max:1 sd:0.225019\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.616664 min:0 max:1 sd:0.318083\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.694601 min:0.0483153 max:1 sd:0.274299\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.474139 min:0 max:0.993699 sd:0.275204\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:19 (5.16304%) mean:0.54925 min:0 max:1 sd:0.362564\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.646306 min:0.0102696 max:1 sd:0.317428\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.417913 min:0 max:0.99189 sd:0.326583\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:27 (7.33696%) mean:0.428224 min:0 max:1 sd:0.324116\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:27 (7.33696%) mean:0.585982 min:0 max:1 sd:0.256983\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:27 (7.33696%) mean:0.349334 min:0 max:1 sd:0.282562\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.51595 min:0.0105506 max:1 sd:0.232766\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.520732 min:0.00905979 max:1 sd:0.240992\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.518983 min:0 max:1 sd:0.167915\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:26 (7.06522%) mean:0.473645 min:0.0953108 max:1 sd:0.179099\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:59 (16.0326%) mean:0.454846 min:0 max:1 sd:0.185951\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.51871 min:0 max:1 sd:0.194675\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.460778 min:0 max:1 sd:0.179706\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:2 (0.543478%) mean:0.454973 min:0 max:1 sd:0.193599\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.464231 min:0 max:0.990302 sd:0.196239\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:18 (4.8913%) mean:0.431759 min:0 max:1 sd:0.200719\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:62 (16.8478%) mean:0.431359 min:0 max:0.963645 sd:0.249385\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.571467 min:0 max:1 sd:0.168741\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.529053 min:0.0234328 max:1 sd:0.17591\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.484714 min:0 max:1 sd:0.191907\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:116 (31.5217%) mean:0.522222 min:0 max:0.995568 sd:0.203441\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.540204 min:0 max:1 sd:0.191412\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:272 (73.913%) mean:0.456451 min:0 max:1 sd:0.222512\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.446934 min:0 max:0.991934 sd:0.216716\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.455641 min:0 max:1 sd:0.205956\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:261 (70.9239%) mean:0.35369 min:0 max:0.949324 sd:0.252121\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:323 (87.7717%) mean:0.00239263 min:0 max:0.0162683 sd:0.00352646\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0217886 min:0 max:0.117754 sd:0.0307716\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.00272463 min:0 max:0.0205002 sd:0.00437305\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:323 (87.7717%) mean:0.383328 min:0 max:0.891234 sd:0.212406\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.374883 min:0 max:0.896264 sd:0.213225\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.500382 min:0 max:0.911156 sd:0.183057\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:323 (87.7717%) mean:0.0779655 min:0 max:0.531611 sd:0.137771\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.104885 min:0 max:0.974137 sd:0.209278\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0604768 min:0 max:0.426528 sd:0.103929\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:323 (87.7717%) mean:0.143476 min:0 max:1 sd:0.141491\n",
      "\t83: \"var_index\" NUMERICAL num-nas:119 (32.337%) mean:0.0785097 min:0 max:1 sd:0.144908\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:34 (9.23913%) mean:0.754154 min:0 max:1 sd:0.274601\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:34 (9.23913%) mean:0.804616 min:0 max:1 sd:0.238602\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:34 (9.23913%) mean:0.0211243 min:0 max:1 sd:0.0850598\n",
      "\t87: \"var_max\" NUMERICAL num-nas:119 (32.337%) mean:0.00795517 min:0 max:0.233918 sd:0.0232843\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:119 (32.337%) mean:0.0452684 min:0 max:1 sd:0.109149\n",
      "\t89: \"var_min\" NUMERICAL num-nas:119 (32.337%) mean:0.038302 min:0 max:1 sd:0.102997\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.424114 min:0 max:1 sd:0.176133\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:119 (32.337%) mean:0.00438481 min:0 max:0.226755 sd:0.0201192\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.875 logloss:4.50546\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.877384 logloss:1.17528\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.88587 logloss:0.638561\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.904891 logloss:0.625519\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.921196 logloss:0.430073\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:47) done accuracy:0.913043 logloss:0.429632\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:59) done accuracy:0.913043 logloss:0.429821\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:71) done accuracy:0.921196 logloss:0.430386\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:79) done accuracy:0.923913 logloss:0.253502\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.915761 logloss:0.257202\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.913043 logloss:0.252216\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.915761 logloss:0.253941\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.915761 logloss:0.248782\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:129) done accuracy:0.915761 logloss:0.249291\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:138) done accuracy:0.915761 logloss:0.248586\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.915761 logloss:0.246466\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:157) done accuracy:0.918478 logloss:0.248492\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.918478 logloss:0.249232\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:182) done accuracy:0.918478 logloss:0.252162\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:194) done accuracy:0.915761 logloss:0.251777\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.918478 logloss:0.248236\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:212) done accuracy:0.918478 logloss:0.24786\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.915761 logloss:0.245809\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:231) done accuracy:0.913043 logloss:0.246657\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:238) done accuracy:0.910326 logloss:0.246823\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:251) done accuracy:0.913043 logloss:0.246878\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:261) done accuracy:0.915761 logloss:0.245188\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.913043 logloss:0.244173\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.918478 logloss:0.24443\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.921196 logloss:0.243716\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.915761 logloss:0.243142\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.915761 logloss:0.243142\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpkwkuztzt\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12742 node(s), and 91 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9891\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8696\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  9%|▉         | 3/32 [00:13<02:01,  4.20s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.0752038 min:0 max:0.395994 sd:0.117487\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0949059 min:0 max:0.603673 sd:0.152208\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0579546 min:0 max:0.388463 sd:0.0926445\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.189083 min:0.00335387 max:1 sd:0.212112\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0298567 min:0.000195345 max:1 sd:0.151698\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.165542 min:0.000481116 max:1 sd:0.17521\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0782338 min:0 max:1 sd:0.190836\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.100528 min:0 max:1 sd:0.238314\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:344 (93.4783%) mean:0.109958 min:0 max:1 sd:0.2174\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.189618 min:0.0344311 max:1 sd:0.157287\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.0881985 min:0 max:1 sd:0.220312\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:329 (89.4022%) mean:0.15237 min:0 max:1 sd:0.217282\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.05658 min:0 max:1 sd:0.153657\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.102117 min:5.72011e-11 max:1 sd:0.213773\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.107615 min:0 max:1 sd:0.229312\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.0962077 min:0.000690433 max:1 sd:0.201209\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.0841103 min:0.0153633 max:0.570059 sd:0.0822196\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.513556 min:0.0152442 max:1 sd:0.181522\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.476282 min:0 max:0.989319 sd:0.187098\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:73 (19.837%) mean:0.466414 min:0.0451185 max:1 sd:0.186852\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.488484 min:0.0995208 max:1 sd:0.180361\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.498421 min:0.0305007 max:0.989925 sd:0.186333\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:11 (2.98913%) mean:0.484645 min:0.0266211 max:1 sd:0.188022\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:23 (6.25%) mean:0.432979 min:0.0181182 max:0.953386 sd:0.17819\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.425981 min:0 max:0.987476 sd:0.194078\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:92 (25%) mean:0.399163 min:0 max:1 sd:0.188816\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.568378 min:0.0286664 max:1 sd:0.172036\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.515903 min:0 max:0.990984 sd:0.181982\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:83 (22.5543%) mean:0.504209 min:0 max:1 sd:0.18876\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:111 (30.163%) mean:0.475116 min:0 max:0.955238 sd:0.195379\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:136 (36.9565%) mean:0.505782 min:0 max:0.99344 sd:0.195373\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.406146 min:0 max:1 sd:0.190182\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.404961 min:0 max:0.947005 sd:0.198642\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:126 (34.2391%) mean:0.408979 min:0 max:0.988705 sd:0.211712\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:301 (81.7935%) mean:0.354786 min:0 max:1 sd:0.187691\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:326 (88.587%) mean:0.191599 min:0 max:1 sd:0.26031\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.188555 min:0 max:1 sd:0.264132\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.177873 min:0 max:1 sd:0.245425\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:326 (88.587%) mean:0.191999 min:0 max:0.988614 sd:0.253784\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.196471 min:0 max:0.992443 sd:0.256714\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.182213 min:0 max:1 sd:0.244623\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:326 (88.587%) mean:0.185181 min:0 max:0.94107 sd:0.237566\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.187822 min:0 max:0.930383 sd:0.241572\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.174089 min:0 max:0.955403 sd:0.215917\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:16 (4.34783%) mean:0.617612 min:0 max:1 sd:0.320934\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:16 (4.34783%) mean:0.698362 min:0 max:1 sd:0.275353\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:16 (4.34783%) mean:0.47689 min:0 max:1 sd:0.281414\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:15 (4.07609%) mean:0.558937 min:0 max:1 sd:0.362643\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:15 (4.07609%) mean:0.659377 min:0 max:1 sd:0.311722\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:15 (4.07609%) mean:0.42107 min:0 max:1 sd:0.327065\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:22 (5.97826%) mean:0.428279 min:0 max:1 sd:0.327349\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.591494 min:0.0466496 max:1 sd:0.254702\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.342054 min:0 max:1 sd:0.276848\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.508023 min:0.0105506 max:1 sd:0.226731\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.510198 min:0 max:1 sd:0.238006\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:4 (1.08696%) mean:0.51198 min:0.0816971 max:0.957751 sd:0.168065\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:25 (6.79348%) mean:0.465026 min:0 max:0.951877 sd:0.179452\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:67 (18.2065%) mean:0.454911 min:0 max:1 sd:0.186714\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.512536 min:0.0278547 max:0.952412 sd:0.196016\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.452248 min:0.0163507 max:0.947944 sd:0.179893\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:2 (0.543478%) mean:0.449138 min:0.00266063 max:1 sd:0.195838\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.458408 min:0 max:1 sd:0.197298\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:14 (3.80435%) mean:0.421237 min:0 max:0.973811 sd:0.194782\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:58 (15.7609%) mean:0.428647 min:0 max:1 sd:0.247536\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.563706 min:0.024159 max:0.965585 sd:0.168514\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:35 (9.51087%) mean:0.520063 min:0 max:0.961149 sd:0.177238\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.484862 min:0.0401454 max:1 sd:0.189545\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.510544 min:0 max:1 sd:0.207352\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:135 (36.6848%) mean:0.526972 min:0.00422152 max:0.983341 sd:0.187246\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:272 (73.913%) mean:0.436057 min:0.0394833 max:0.955908 sd:0.194703\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:104 (28.2609%) mean:0.440682 min:0 max:1 sd:0.217018\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.444838 min:0.00566975 max:0.975678 sd:0.198486\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:257 (69.837%) mean:0.334116 min:0 max:1 sd:0.241905\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.0283178 min:0 max:1 sd:0.15263\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0422267 min:0 max:1 sd:0.153773\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0284026 min:0 max:1 sd:0.152526\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:326 (88.587%) mean:0.378265 min:0 max:1 sd:0.225785\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.369849 min:0 max:1 sd:0.223223\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.495621 min:0 max:1 sd:0.195007\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.09727 min:0 max:1 sd:0.187368\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.123081 min:0 max:1 sd:0.238421\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0810653 min:0.000337785 max:1 sd:0.171713\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.137696 min:0 max:1 sd:0.14524\n",
      "\t83: \"var_index\" NUMERICAL num-nas:119 (32.337%) mean:0.0736715 min:0 max:1 sd:0.131013\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:30 (8.15217%) mean:0.75408 min:0 max:1 sd:0.274545\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:30 (8.15217%) mean:0.806444 min:0 max:1 sd:0.235974\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:30 (8.15217%) mean:0.0259759 min:1.01339e-06 max:1 sd:0.0941883\n",
      "\t87: \"var_max\" NUMERICAL num-nas:119 (32.337%) mean:0.0104857 min:0 max:1 sd:0.0656131\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:119 (32.337%) mean:0.042544 min:0 max:0.623456 sd:0.0985482\n",
      "\t89: \"var_min\" NUMERICAL num-nas:119 (32.337%) mean:0.0345854 min:0 max:0.54179 sd:0.0854723\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.422855 min:0 max:1 sd:0.166195\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:119 (32.337%) mean:0.00743945 min:0 max:1 sd:0.0653313\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.875 logloss:4.50546\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.852861 logloss:1.48958\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.894022 logloss:0.724145\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:26) done accuracy:0.899457 logloss:0.350804\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.894022 logloss:0.261904\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:49) done accuracy:0.899457 logloss:0.255642\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:61) done accuracy:0.902174 logloss:0.252294\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:67) done accuracy:0.891304 logloss:0.256188\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:79) done accuracy:0.896739 logloss:0.254036\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.896739 logloss:0.255782\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:101) done accuracy:0.902174 logloss:0.253069\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.899457 logloss:0.253045\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:119) done accuracy:0.907609 logloss:0.24947\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.907609 logloss:0.249455\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:142) done accuracy:0.915761 logloss:0.251062\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.910326 logloss:0.252228\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.904891 logloss:0.252285\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.902174 logloss:0.250006\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:182) done accuracy:0.902174 logloss:0.249464\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:188) done accuracy:0.904891 logloss:0.250788\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.910326 logloss:0.248379\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.904891 logloss:0.248505\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:221) done accuracy:0.907609 logloss:0.248053\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:230) done accuracy:0.913043 logloss:0.248998\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:238) done accuracy:0.915761 logloss:0.249227\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:253) done accuracy:0.915761 logloss:0.247431\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:262) done accuracy:0.918478 logloss:0.247463\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:273) done accuracy:0.921196 logloss:0.246358\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.918478 logloss:0.246148\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.921196 logloss:0.246611\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.913043 logloss:0.247253\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.913043 logloss:0.247253\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpj9p6zh_j\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13010 node(s), and 91 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9022\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 12%|█▎        | 4/32 [00:16<01:46,  3.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0964404 min:0 max:0.451509 sd:0.134164\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.117194 min:0 max:0.603673 sd:0.163578\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0771096 min:0 max:0.388463 sd:0.111713\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.166522 min:0.00335387 max:0.946182 sd:0.173325\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0267888 min:0.000195345 max:1 sd:0.145152\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.14431 min:0.000481116 max:0.586641 sd:0.124817\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0750093 min:0 max:1 sd:0.183727\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0964527 min:0 max:1 sd:0.229988\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.102755 min:0 max:1 sd:0.207157\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.160357 min:0 max:0.449374 sd:0.0939216\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.0796652 min:0 max:1 sd:0.212057\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.131159 min:0 max:1 sd:0.207092\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0380834 min:0 max:0.398003 sd:0.0683435\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0999645 min:5.72011e-11 max:1 sd:0.205653\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.105218 min:0 max:1 sd:0.221516\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0919181 min:0.000690433 max:1 sd:0.191254\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.0750863 min:0 max:0.149243 sd:0.0375315\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.5218 min:0.0152442 max:1 sd:0.184309\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:32 (8.69565%) mean:0.487105 min:0 max:1 sd:0.188301\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:68 (18.4783%) mean:0.46899 min:0 max:1 sd:0.186604\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.496267 min:0.0996667 max:1 sd:0.181256\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.506806 min:0.0305007 max:1 sd:0.187246\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:13 (3.53261%) mean:0.49413 min:0.0266211 max:1 sd:0.183734\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:25 (6.79348%) mean:0.439625 min:0.0181182 max:1 sd:0.180762\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:25 (6.79348%) mean:0.434571 min:0 max:1 sd:0.201818\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:97 (26.3587%) mean:0.403819 min:0 max:1 sd:0.19099\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.573947 min:0.0286664 max:1 sd:0.176106\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.52469 min:0 max:1 sd:0.184017\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:83 (22.5543%) mean:0.509784 min:0.000319932 max:1 sd:0.187088\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.486661 min:0 max:1 sd:0.199366\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.509956 min:0 max:1 sd:0.201766\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:306 (83.1522%) mean:0.439041 min:0 max:1 sd:0.210127\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:110 (29.8913%) mean:0.417435 min:0 max:1 sd:0.202068\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.419865 min:0 max:1 sd:0.218267\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:300 (81.5217%) mean:0.388782 min:0.0423683 max:1 sd:0.197786\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:322 (87.5%) mean:0.20177 min:0 max:1 sd:0.265077\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.188203 min:0 max:0.928857 sd:0.244728\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.198033 min:0 max:1 sd:0.26203\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:322 (87.5%) mean:0.212338 min:0 max:1 sd:0.273922\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.216067 min:0 max:1 sd:0.276327\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.203099 min:0 max:1 sd:0.266151\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:322 (87.5%) mean:0.204179 min:0 max:1 sd:0.25998\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.206444 min:0 max:1 sd:0.263001\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.194005 min:0 max:1 sd:0.243136\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.634325 min:0 max:1 sd:0.316751\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.710397 min:0 max:1 sd:0.271901\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.489749 min:0 max:1 sd:0.27719\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.56418 min:0 max:1 sd:0.355916\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.661567 min:0 max:1 sd:0.311399\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.423988 min:0 max:1 sd:0.325556\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:29 (7.88043%) mean:0.423023 min:0 max:1 sd:0.331939\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:29 (7.88043%) mean:0.586024 min:0 max:1 sd:0.260029\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:29 (7.88043%) mean:0.344815 min:0 max:1 sd:0.291218\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.501862 min:0 max:0.999799 sd:0.232854\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.503473 min:0 max:0.999094 sd:0.242414\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.520444 min:0.100042 max:1 sd:0.171322\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:25 (6.79348%) mean:0.470054 min:0 max:1 sd:0.183637\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:61 (16.5761%) mean:0.456431 min:0 max:1 sd:0.185555\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.519242 min:0.0278547 max:1 sd:0.196793\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.45828 min:0.0163507 max:1 sd:0.182337\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.457782 min:0.0161488 max:1 sd:0.191234\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.460259 min:0 max:1 sd:0.197614\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.428837 min:0 max:1 sd:0.200905\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.434167 min:0 max:1 sd:0.248345\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.571296 min:0.024159 max:1 sd:0.170286\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.52658 min:0 max:1 sd:0.180027\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.486101 min:0 max:1 sd:0.191362\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:123 (33.4239%) mean:0.519778 min:0 max:1 sd:0.208893\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.531129 min:0.00422152 max:1 sd:0.191452\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:269 (73.0978%) mean:0.451716 min:0 max:1 sd:0.222597\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:115 (31.25%) mean:0.448477 min:0 max:1 sd:0.218423\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.451481 min:0.00566975 max:1 sd:0.203291\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:257 (69.837%) mean:0.363353 min:0 max:1 sd:0.258894\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0265463 min:0 max:1 sd:0.145961\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0430778 min:0 max:1 sd:0.146869\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0267707 min:0 max:1 sd:0.145847\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:322 (87.5%) mean:0.403292 min:0 max:1 sd:0.225148\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.394299 min:0.0823497 max:1 sd:0.221941\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.517206 min:0 max:1 sd:0.194782\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0956796 min:0.00234924 max:1 sd:0.179007\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.120857 min:0.00353616 max:1 sd:0.22979\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0783064 min:0.000337785 max:1 sd:0.162175\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.120928 min:0 max:0.297436 sd:0.0630176\n",
      "\t83: \"var_index\" NUMERICAL num-nas:117 (31.7935%) mean:0.0778552 min:0 max:1 sd:0.128847\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.752052 min:0 max:1 sd:0.276103\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.802866 min:0 max:1 sd:0.241465\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.027287 min:0 max:1 sd:0.0964852\n",
      "\t87: \"var_max\" NUMERICAL num-nas:117 (31.7935%) mean:0.0112112 min:0 max:1 sd:0.065262\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:117 (31.7935%) mean:0.0500089 min:0 max:1 sd:0.120647\n",
      "\t89: \"var_min\" NUMERICAL num-nas:117 (31.7935%) mean:0.0426242 min:0 max:1 sd:0.111678\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.423183 min:0 max:1 sd:0.17018\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:117 (31.7935%) mean:0.00712552 min:1.46236e-05 max:1 sd:0.0642407\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.897059 logloss:3.71038\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.803815 logloss:1.90412\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:22) done accuracy:0.896739 logloss:0.441053\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:19) done accuracy:0.910326 logloss:0.350962\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.902174 logloss:0.342752\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.904891 logloss:0.342013\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.910326 logloss:0.251276\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.913043 logloss:0.251684\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:78) done accuracy:0.910326 logloss:0.252338\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.907609 logloss:0.25755\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.913043 logloss:0.258427\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:101) done accuracy:0.913043 logloss:0.254682\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:119) done accuracy:0.915761 logloss:0.248743\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.918478 logloss:0.250189\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.918478 logloss:0.249113\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.918478 logloss:0.250137\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.915761 logloss:0.24872\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.918478 logloss:0.251808\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:181) done accuracy:0.915761 logloss:0.25149\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.918478 logloss:0.249649\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:200) done accuracy:0.915761 logloss:0.249037\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.918478 logloss:0.247509\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:220) done accuracy:0.918478 logloss:0.248397\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:230) done accuracy:0.918478 logloss:0.247975\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.921196 logloss:0.249371\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:252) done accuracy:0.915761 logloss:0.250922\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:259) done accuracy:0.915761 logloss:0.250827\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:270) done accuracy:0.915761 logloss:0.250459\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:282) done accuracy:0.918478 logloss:0.249666\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.918478 logloss:0.249002\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.921196 logloss:0.250337\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.921196 logloss:0.250337\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmppezrs11q\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13158 node(s), and 91 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f68c87f4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f68c87f4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 16%|█▌        | 5/32 [00:19<01:37,  3.60s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.10005 min:0 max:1 sd:0.182687\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.116211 min:0 max:1 sd:0.201537\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0837546 min:0 max:1 sd:0.168955\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.188946 min:0 max:1 sd:0.209901\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0277985 min:0 max:1 sd:0.145118\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.166463 min:0 max:1 sd:0.174552\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0635543 min:0 max:1 sd:0.172903\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0821628 min:6.01976e-05 max:1 sd:0.216599\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.087029 min:0 max:1 sd:0.199683\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.191348 min:0 max:1 sd:0.156819\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.101439 min:0 max:1 sd:0.250012\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.139971 min:0 max:1 sd:0.204617\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0592501 min:0 max:1 sd:0.154841\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0882028 min:0 max:1 sd:0.196571\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0935078 min:0 max:1 sd:0.210444\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0855427 min:0 max:1 sd:0.187974\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.104314 min:0 max:1 sd:0.156413\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.524157 min:0.0152442 max:1 sd:0.181751\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.48876 min:0 max:1 sd:0.186381\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:67 (18.2065%) mean:0.469233 min:0.0451185 max:1 sd:0.189336\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.498153 min:0.0995208 max:1 sd:0.179998\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.510938 min:0.0305007 max:1 sd:0.18482\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:8 (2.17391%) mean:0.492736 min:0.0266211 max:1 sd:0.18672\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.444778 min:0.0181182 max:1 sd:0.176626\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.437854 min:0 max:1 sd:0.200195\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.399348 min:0 max:1 sd:0.191747\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.578403 min:0.0549214 max:1 sd:0.173288\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.526836 min:0.0378418 max:1 sd:0.182681\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.508917 min:0 max:1 sd:0.191229\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:110 (29.8913%) mean:0.488566 min:0 max:1 sd:0.194717\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.519823 min:0 max:1 sd:0.192515\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:304 (82.6087%) mean:0.418867 min:0 max:1 sd:0.210471\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:99 (26.9022%) mean:0.415204 min:0 max:1 sd:0.199929\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:120 (32.6087%) mean:0.423249 min:0 max:1 sd:0.214072\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:296 (80.4348%) mean:0.363358 min:0 max:1 sd:0.196803\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:322 (87.5%) mean:0.199168 min:0 max:1 sd:0.269176\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.194738 min:0 max:1 sd:0.269146\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.186636 min:0 max:1 sd:0.257245\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:322 (87.5%) mean:0.200477 min:0.000264866 max:1 sd:0.269396\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.205017 min:0.000264511 max:1 sd:0.271801\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.190777 min:0.00023666 max:1 sd:0.26157\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:322 (87.5%) mean:0.195434 min:0 max:1 sd:0.255828\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.198183 min:0.000269833 max:1 sd:0.259164\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.184955 min:0 max:1 sd:0.238179\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.621058 min:0 max:1 sd:0.30949\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.699067 min:0 max:1 sd:0.268089\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.480238 min:0 max:1 sd:0.270722\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:23 (6.25%) mean:0.552161 min:0 max:1 sd:0.356951\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:23 (6.25%) mean:0.64949 min:0 max:1 sd:0.311116\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:23 (6.25%) mean:0.423941 min:0 max:1 sd:0.323703\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:31 (8.42391%) mean:0.432771 min:0 max:1 sd:0.321877\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:31 (8.42391%) mean:0.589575 min:0 max:1 sd:0.253489\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:31 (8.42391%) mean:0.354742 min:0 max:1 sd:0.284054\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:111 (30.163%) mean:0.503018 min:0 max:1 sd:0.222029\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:111 (30.163%) mean:0.500646 min:0 max:1 sd:0.233779\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:7 (1.90217%) mean:0.520855 min:0.0816971 max:1 sd:0.169756\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.47699 min:0 max:1 sd:0.18187\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.460827 min:0.0410427 max:1 sd:0.186877\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.519248 min:0.0278547 max:1 sd:0.197058\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.463105 min:0.0163507 max:1 sd:0.182108\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.460591 min:0.00266063 max:1 sd:0.194075\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.469722 min:0 max:1 sd:0.193106\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.436173 min:0 max:1 sd:0.198861\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:66 (17.9348%) mean:0.43058 min:0 max:0.963645 sd:0.253415\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.573403 min:0.024159 max:1 sd:0.170402\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.534124 min:0 max:1 sd:0.176021\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:72 (19.5652%) mean:0.485877 min:0.0401454 max:1 sd:0.194058\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:112 (30.4348%) mean:0.52089 min:0 max:1 sd:0.205248\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.540383 min:0.00422152 max:1 sd:0.18601\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:275 (74.7283%) mean:0.449186 min:0 max:1 sd:0.211726\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:103 (27.9891%) mean:0.448453 min:0 max:1 sd:0.215358\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:119 (32.337%) mean:0.456684 min:0.00566975 max:1 sd:0.201169\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:262 (71.1957%) mean:0.344049 min:0 max:0.949324 sd:0.247827\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0261462 min:0 max:1 sd:0.146025\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0380772 min:0 max:1 sd:0.147053\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0263679 min:0 max:1 sd:0.14591\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:322 (87.5%) mean:0.365066 min:0 max:1 sd:0.210996\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.352608 min:0 max:1 sd:0.202154\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.488103 min:0 max:1 sd:0.186449\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0827091 min:0 max:1 sd:0.16754\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.104397 min:0 max:1 sd:0.214398\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0691742 min:0 max:1 sd:0.155746\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.139136 min:0.0100233 max:1 sd:0.142467\n",
      "\t83: \"var_index\" NUMERICAL num-nas:111 (30.163%) mean:0.0760024 min:0 max:0.978261 sd:0.133107\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:34 (9.23913%) mean:0.753955 min:0 max:1 sd:0.27682\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:34 (9.23913%) mean:0.805539 min:0 max:1 sd:0.243152\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:34 (9.23913%) mean:0.0225114 min:0 max:1 sd:0.0882084\n",
      "\t87: \"var_max\" NUMERICAL num-nas:111 (30.163%) mean:0.0117808 min:0 max:1 sd:0.065894\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:111 (30.163%) mean:0.0472731 min:0 max:1 sd:0.112891\n",
      "\t89: \"var_min\" NUMERICAL num-nas:111 (30.163%) mean:0.0385052 min:0 max:1 sd:0.101765\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:111 (30.163%) mean:0.426766 min:0 max:0.99369 sd:0.162727\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:111 (30.163%) mean:0.00827372 min:9.36969e-06 max:1 sd:0.0650126\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.897059 logloss:3.71038\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.828804 logloss:1.70686\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.855978 logloss:0.673196\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.877717 logloss:0.373941\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.877717 logloss:0.286521\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:51) done accuracy:0.891304 logloss:0.279069\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.88587 logloss:0.276\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.894022 logloss:0.276745\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:82) done accuracy:0.899457 logloss:0.27329\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.891304 logloss:0.273819\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.904891 logloss:0.269972\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.904891 logloss:0.271062\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.904891 logloss:0.271167\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:131) done accuracy:0.904891 logloss:0.271168\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.899457 logloss:0.271668\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:139) done accuracy:0.902174 logloss:0.270692\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.904891 logloss:0.270605\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:169) done accuracy:0.904891 logloss:0.269516\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:176) done accuracy:0.907609 logloss:0.273044\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:189) done accuracy:0.907609 logloss:0.273191\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:203) done accuracy:0.904891 logloss:0.273434\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.904891 logloss:0.272949\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:221) done accuracy:0.904891 logloss:0.273012\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:234) done accuracy:0.904891 logloss:0.271307\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:241) done accuracy:0.899457 logloss:0.272235\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.904891 logloss:0.27215\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:259) done accuracy:0.902174 logloss:0.271527\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:270) done accuracy:0.896739 logloss:0.270645\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:282) done accuracy:0.904891 logloss:0.269349\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.902174 logloss:0.268291\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:298) done accuracy:0.899457 logloss:0.268122\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.899457 logloss:0.268122\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpvx3uove5\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13470 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f68e03d1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f68e03d1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9348\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 19%|█▉        | 6/32 [00:22<01:27,  3.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.102173 min:0 max:1 sd:0.186331\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.116023 min:0 max:1 sd:0.202664\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0879506 min:0 max:1 sd:0.17465\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.185279 min:0 max:1 sd:0.207918\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0276073 min:0 max:1 sd:0.145139\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.164524 min:0 max:1 sd:0.17349\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0678251 min:0 max:1 sd:0.180173\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0868309 min:0 max:1 sd:0.224951\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.0978135 min:0 max:1 sd:0.209321\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.188714 min:0 max:1 sd:0.154374\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.10153 min:0 max:1 sd:0.250295\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.123262 min:0 max:1 sd:0.185788\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0603607 min:0 max:1 sd:0.155375\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0912861 min:0 max:1 sd:0.201577\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0966963 min:0 max:1 sd:0.216015\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0867397 min:0 max:1 sd:0.190528\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.104623 min:0 max:1 sd:0.156252\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.524334 min:0 max:1 sd:0.185091\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.485222 min:0 max:1 sd:0.191438\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.467872 min:0 max:1 sd:0.19395\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.49707 min:0 max:1 sd:0.185146\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.506515 min:0 max:1 sd:0.190846\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.493031 min:0 max:1 sd:0.190742\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:24 (6.52174%) mean:0.439649 min:0 max:1 sd:0.183328\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.434199 min:0 max:1 sd:0.204347\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:102 (27.7174%) mean:0.407365 min:0 max:1 sd:0.194365\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.577723 min:0 max:1 sd:0.176243\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.525251 min:0 max:1 sd:0.18641\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:79 (21.4674%) mean:0.510311 min:0 max:1 sd:0.194313\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.489629 min:0 max:1 sd:0.197699\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.521604 min:0 max:1 sd:0.198042\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:309 (83.9674%) mean:0.447142 min:0 max:1 sd:0.210681\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.41663 min:0 max:1 sd:0.203476\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.426092 min:0 max:1 sd:0.219304\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:302 (82.0652%) mean:0.394633 min:0 max:1 sd:0.194149\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:322 (87.5%) mean:0.20939 min:0 max:1 sd:0.270508\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.203673 min:0 max:1 sd:0.269844\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.198018 min:0 max:1 sd:0.259557\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:322 (87.5%) mean:0.211037 min:0 max:1 sd:0.27116\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.21473 min:0 max:1 sd:0.273553\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.20227 min:0 max:1 sd:0.263443\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:322 (87.5%) mean:0.205704 min:0 max:1 sd:0.257687\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.208079 min:0 max:1 sd:0.260864\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.195477 min:0 max:1 sd:0.240594\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.624702 min:0 max:1 sd:0.310575\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.703572 min:0 max:1 sd:0.265248\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.48661 min:0 max:1 sd:0.276854\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:20 (5.43478%) mean:0.558802 min:0 max:1 sd:0.358702\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.654351 min:0 max:1 sd:0.309805\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.427427 min:0 max:1 sd:0.327373\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:28 (7.6087%) mean:0.433824 min:0 max:1 sd:0.324899\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:28 (7.6087%) mean:0.589532 min:0 max:1 sd:0.255545\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:28 (7.6087%) mean:0.350332 min:0 max:1 sd:0.280399\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.520206 min:0 max:1 sd:0.231723\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.52504 min:0 max:1 sd:0.237534\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:7 (1.90217%) mean:0.520161 min:0 max:1 sd:0.173269\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:25 (6.79348%) mean:0.472151 min:0 max:1 sd:0.184934\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:58 (15.7609%) mean:0.458642 min:0 max:1 sd:0.190868\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.516473 min:0 max:1 sd:0.199887\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.459924 min:0 max:1 sd:0.185365\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.459119 min:0 max:1 sd:0.197621\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:19 (5.16304%) mean:0.46364 min:0 max:1 sd:0.199932\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:18 (4.8913%) mean:0.430567 min:0 max:1 sd:0.20241\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:67 (18.2065%) mean:0.429322 min:0 max:1 sd:0.253475\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.573656 min:0 max:1 sd:0.17175\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.528189 min:0 max:1 sd:0.18122\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:75 (20.3804%) mean:0.490007 min:0 max:1 sd:0.19519\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.521249 min:0 max:1 sd:0.207062\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.542839 min:0 max:1 sd:0.189181\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:276 (75%) mean:0.451652 min:0 max:1 sd:0.233474\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.449602 min:0 max:1 sd:0.21759\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:123 (33.4239%) mean:0.457196 min:0 max:1 sd:0.206484\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:263 (71.4674%) mean:0.348122 min:0 max:1 sd:0.263936\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0262724 min:0 max:1 sd:0.146004\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0408184 min:0 max:1 sd:0.147157\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0264667 min:0 max:1 sd:0.145894\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:322 (87.5%) mean:0.36708 min:0 max:1 sd:0.205923\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.354441 min:0 max:1 sd:0.201617\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.490106 min:0 max:1 sd:0.179478\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0863794 min:0 max:1 sd:0.175037\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.108774 min:0 max:1 sd:0.223771\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0727778 min:0 max:1 sd:0.161672\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.140889 min:0 max:1 sd:0.143065\n",
      "\t83: \"var_index\" NUMERICAL num-nas:119 (32.337%) mean:0.0826131 min:0 max:1 sd:0.148559\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.756684 min:0 max:1 sd:0.26871\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.809607 min:0 max:1 sd:0.230009\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.0204519 min:2.13771e-07 max:0.389902 sd:0.070281\n",
      "\t87: \"var_max\" NUMERICAL num-nas:119 (32.337%) mean:0.0124102 min:0 max:1 sd:0.0670363\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:119 (32.337%) mean:0.050156 min:0 max:1 sd:0.118293\n",
      "\t89: \"var_min\" NUMERICAL num-nas:119 (32.337%) mean:0.0409805 min:0 max:1 sd:0.107594\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.427287 min:0 max:1 sd:0.175081\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:119 (32.337%) mean:0.00870182 min:9.36969e-06 max:1 sd:0.0661598\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:3) done accuracy:0.857143 logloss:5.14909\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.877717 logloss:0.998017\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.902174 logloss:0.440908\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:31) done accuracy:0.891304 logloss:0.337518\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:39) done accuracy:0.899457 logloss:0.259547\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:52) done accuracy:0.902174 logloss:0.249388\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.899457 logloss:0.255348\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:73) done accuracy:0.899457 logloss:0.253214\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:81) done accuracy:0.894022 logloss:0.255056\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:92) done accuracy:0.894022 logloss:0.253583\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:96) done accuracy:0.899457 logloss:0.251635\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:108) done accuracy:0.896739 logloss:0.253437\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:123) done accuracy:0.894022 logloss:0.250694\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:131) done accuracy:0.896739 logloss:0.251176\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.894022 logloss:0.250603\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.894022 logloss:0.250177\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:159) done accuracy:0.899457 logloss:0.253857\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:169) done accuracy:0.899457 logloss:0.253223\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:181) done accuracy:0.899457 logloss:0.252758\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.902174 logloss:0.251995\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:200) done accuracy:0.902174 logloss:0.252968\n",
      "[INFO random_forest.cc:578] Training of tree  212/300 (tree index:208) done accuracy:0.899457 logloss:0.253556\n",
      "[INFO random_forest.cc:578] Training of tree  222/300 (tree index:221) done accuracy:0.902174 logloss:0.25251\n",
      "[INFO random_forest.cc:578] Training of tree  232/300 (tree index:231) done accuracy:0.899457 logloss:0.253163\n",
      "[INFO random_forest.cc:578] Training of tree  242/300 (tree index:239) done accuracy:0.902174 logloss:0.253412\n",
      "[INFO random_forest.cc:578] Training of tree  252/300 (tree index:251) done accuracy:0.904891 logloss:0.253274\n",
      "[INFO random_forest.cc:578] Training of tree  262/300 (tree index:264) done accuracy:0.902174 logloss:0.252088\n",
      "[INFO random_forest.cc:578] Training of tree  272/300 (tree index:271) done accuracy:0.899457 logloss:0.251031\n",
      "[INFO random_forest.cc:578] Training of tree  282/300 (tree index:282) done accuracy:0.904891 logloss:0.250683\n",
      "[INFO random_forest.cc:578] Training of tree  292/300 (tree index:291) done accuracy:0.902174 logloss:0.25004\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.904891 logloss:0.249306\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.904891 logloss:0.249306\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp47iufwk7\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12982 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.8696\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 22%|██▏       | 7/32 [00:25<01:21,  3.25s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:321 (87.2283%) mean:0.099787 min:0 max:1 sd:0.177981\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.117248 min:0 max:1 sd:0.196032\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0841963 min:0 max:1 sd:0.167935\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:321 (87.2283%) mean:0.184305 min:0 max:1 sd:0.209967\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0272476 min:0 max:1 sd:0.143617\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.16102 min:0 max:1 sd:0.174925\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:321 (87.2283%) mean:0.0626524 min:0 max:0.496254 sd:0.134972\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0860782 min:0 max:0.978189 sd:0.198923\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.080284 min:0.00246435 max:0.427298 sd:0.12397\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:321 (87.2283%) mean:0.172819 min:0 max:1 sd:0.149421\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:321 (87.2283%) mean:0.0991219 min:0 max:1 sd:0.248259\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.136373 min:0 max:1 sd:0.208742\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0578717 min:0 max:1 sd:0.154371\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:321 (87.2283%) mean:0.0874972 min:0 max:0.726902 sd:0.165676\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0964802 min:0.00425412 max:1 sd:0.194107\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0792956 min:0.000690433 max:0.58012 sd:0.142901\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:321 (87.2283%) mean:0.102207 min:0 max:1 sd:0.155001\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.51765 min:0.0152442 max:0.988978 sd:0.178149\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.478222 min:0 max:1 sd:0.182801\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:68 (18.4783%) mean:0.457362 min:0.0451185 max:0.980907 sd:0.184479\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.490048 min:0.0995208 max:1 sd:0.177899\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.499688 min:0.0305007 max:1 sd:0.182504\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:13 (3.53261%) mean:0.484941 min:0.0329348 max:0.980704 sd:0.181832\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:21 (5.70652%) mean:0.436584 min:0.0181182 max:1 sd:0.176565\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:27 (7.33696%) mean:0.432554 min:0 max:1 sd:0.198029\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.400174 min:0 max:1 sd:0.194345\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.572016 min:0.0286664 max:0.990661 sd:0.170293\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.520612 min:0.0677501 max:1 sd:0.176423\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.498956 min:0 max:0.985639 sd:0.187183\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:108 (29.3478%) mean:0.483094 min:0 max:1 sd:0.191919\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.515976 min:0.0562777 max:1 sd:0.193013\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:303 (82.337%) mean:0.443076 min:0 max:1 sd:0.198142\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:97 (26.3587%) mean:0.407975 min:0 max:1 sd:0.197025\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:122 (33.1522%) mean:0.41431 min:0.00700149 max:1 sd:0.21375\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:296 (80.4348%) mean:0.380853 min:0 max:1 sd:0.197075\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:321 (87.2283%) mean:0.175449 min:0 max:0.949443 sd:0.243872\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.172108 min:0 max:1 sd:0.247568\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.164694 min:0 max:1 sd:0.233318\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:321 (87.2283%) mean:0.176393 min:0 max:1 sd:0.246572\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.180223 min:0 max:1 sd:0.248384\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.168918 min:0 max:1 sd:0.242531\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:321 (87.2283%) mean:0.172721 min:0 max:1 sd:0.236383\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.17444 min:0 max:1 sd:0.23823\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.166941 min:0 max:1 sd:0.22892\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.609521 min:0 max:1 sd:0.315852\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.689911 min:0 max:1 sd:0.271417\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.471643 min:0 max:0.993699 sd:0.278423\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.554649 min:0 max:1 sd:0.359326\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.652343 min:0 max:1 sd:0.314031\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.419401 min:0 max:0.99189 sd:0.325778\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:28 (7.6087%) mean:0.441291 min:0 max:1 sd:0.324428\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:28 (7.6087%) mean:0.597401 min:0 max:1 sd:0.257105\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:28 (7.6087%) mean:0.359202 min:0 max:1 sd:0.281941\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:113 (30.7065%) mean:0.503162 min:0 max:1 sd:0.225655\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:113 (30.7065%) mean:0.506884 min:0 max:1 sd:0.23744\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.518457 min:0.0816971 max:1 sd:0.167315\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.469422 min:0.0902793 max:1 sd:0.176595\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.448855 min:0 max:1 sd:0.182658\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.514124 min:0.0278547 max:1 sd:0.194127\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.455618 min:0.0448893 max:1 sd:0.176728\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.450888 min:0.00266063 max:1 sd:0.188046\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.461109 min:0.00394213 max:1 sd:0.193188\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.426976 min:0 max:1 sd:0.198083\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.428189 min:0 max:1 sd:0.253663\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.57071 min:0.0743731 max:1 sd:0.165679\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.5252 min:0 max:1 sd:0.175577\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.480793 min:0.0455659 max:1 sd:0.185362\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.514534 min:0 max:1 sd:0.201997\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:131 (35.5978%) mean:0.535201 min:0.102958 max:1 sd:0.184281\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:266 (72.2826%) mean:0.450355 min:0 max:1 sd:0.226972\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:102 (27.7174%) mean:0.442823 min:0 max:1 sd:0.211815\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:122 (33.1522%) mean:0.450884 min:0.0788239 max:1 sd:0.198396\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:256 (69.5652%) mean:0.361939 min:0.00939159 max:1 sd:0.263105\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:321 (87.2283%) mean:0.00440877 min:0 max:0.107496 sd:0.0155456\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.041143 min:0 max:1 sd:0.144367\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.00452832 min:0 max:0.100884 sd:0.014775\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:321 (87.2283%) mean:0.399128 min:0 max:1 sd:0.230846\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.394014 min:0 max:1 sd:0.229599\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.510722 min:0 max:1 sd:0.198523\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:321 (87.2283%) mean:0.0840987 min:0 max:0.531611 sd:0.134128\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.111676 min:0 max:0.974137 sd:0.203509\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0660827 min:0 max:0.426528 sd:0.101568\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:321 (87.2283%) mean:0.140634 min:0 max:1 sd:0.142751\n",
      "\t83: \"var_index\" NUMERICAL num-nas:113 (30.7065%) mean:0.0808113 min:0 max:1 sd:0.144364\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:31 (8.42391%) mean:0.752528 min:0 max:1 sd:0.274799\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:31 (8.42391%) mean:0.806883 min:0 max:1 sd:0.238304\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:31 (8.42391%) mean:0.0220391 min:0 max:1 sd:0.0870864\n",
      "\t87: \"var_max\" NUMERICAL num-nas:113 (30.7065%) mean:0.0114112 min:0 max:1 sd:0.0661663\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:113 (30.7065%) mean:0.0432703 min:0 max:1 sd:0.109411\n",
      "\t89: \"var_min\" NUMERICAL num-nas:113 (30.7065%) mean:0.0341573 min:0 max:1 sd:0.097316\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:113 (30.7065%) mean:0.42697 min:0 max:1 sd:0.169649\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:113 (30.7065%) mean:0.00836745 min:0 max:1 sd:0.0653844\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.889706 logloss:3.9754\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.820163 logloss:1.70603\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:22) done accuracy:0.872283 logloss:0.47688\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:17) done accuracy:0.88587 logloss:0.280364\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.894022 logloss:0.272031\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.899457 logloss:0.269058\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:62) done accuracy:0.899457 logloss:0.261705\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.907609 logloss:0.263847\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.904891 logloss:0.264341\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.902174 logloss:0.262541\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.904891 logloss:0.263655\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.902174 logloss:0.261964\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:112) done accuracy:0.896739 logloss:0.2602\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:133) done accuracy:0.894022 logloss:0.258747\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:142) done accuracy:0.888587 logloss:0.261891\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.888587 logloss:0.259826\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.88587 logloss:0.260097\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.891304 logloss:0.259028\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.891304 logloss:0.258814\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.891304 logloss:0.258397\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.891304 logloss:0.257901\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.888587 logloss:0.257396\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:222) done accuracy:0.88587 logloss:0.257425\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:232) done accuracy:0.888587 logloss:0.258265\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:241) done accuracy:0.888587 logloss:0.25907\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:252) done accuracy:0.891304 logloss:0.258458\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:262) done accuracy:0.894022 logloss:0.25807\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:272) done accuracy:0.896739 logloss:0.259061\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:283) done accuracy:0.896739 logloss:0.258604\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.894022 logloss:0.257992\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.902174 logloss:0.257368\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.902174 logloss:0.257368\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp7b4h4_ph\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13240 node(s), and 91 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.8913\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 25%|██▌       | 8/32 [00:28<01:15,  3.15s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:319 (86.6848%) mean:0.0941191 min:0 max:0.451509 sd:0.132064\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.113561 min:0 max:0.603673 sd:0.160527\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0754518 min:0 max:0.388463 sd:0.109909\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:319 (86.6848%) mean:0.175263 min:0.00335387 max:1 sd:0.205507\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0260618 min:0.000195345 max:1 sd:0.140763\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.153725 min:0.000481116 max:1 sd:0.170826\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:319 (86.6848%) mean:0.0796738 min:0 max:1 sd:0.187515\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.101715 min:1.82725e-05 max:1 sd:0.23449\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:337 (91.5761%) mean:0.100955 min:0 max:1 sd:0.202063\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:319 (86.6848%) mean:0.183415 min:0 max:1 sd:0.15167\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:319 (86.6848%) mean:0.0938945 min:0 max:1 sd:0.243865\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.10882 min:0 max:0.696288 sd:0.155016\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0550284 min:0 max:1 sd:0.151104\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:319 (86.6848%) mean:0.10201 min:5.72011e-11 max:1 sd:0.20825\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.10764 min:0 max:1 sd:0.224325\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0950796 min:0 max:1 sd:0.193648\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:319 (86.6848%) mean:0.083752 min:0 max:0.570059 sd:0.0787589\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.517044 min:0 max:1 sd:0.186379\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.48164 min:0 max:1 sd:0.189924\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:75 (20.3804%) mean:0.466686 min:0 max:1 sd:0.190948\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.492951 min:0 max:1 sd:0.185126\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.501054 min:0 max:1 sd:0.189907\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:13 (3.53261%) mean:0.48624 min:0 max:1 sd:0.189806\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.442057 min:0 max:1 sd:0.178384\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:25 (6.79348%) mean:0.439882 min:0 max:1 sd:0.202692\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.401515 min:0 max:1 sd:0.196513\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.571133 min:0 max:1 sd:0.178142\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:42 (11.413%) mean:0.522239 min:0 max:1 sd:0.185398\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:88 (23.913%) mean:0.51124 min:0.0544485 max:1 sd:0.187474\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.483672 min:0 max:1 sd:0.194389\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.51718 min:0 max:1 sd:0.201725\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:306 (83.1522%) mean:0.440025 min:0 max:1 sd:0.199861\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:97 (26.3587%) mean:0.413298 min:0.0091239 max:1 sd:0.198057\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:120 (32.6087%) mean:0.423588 min:0 max:1 sd:0.220034\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:299 (81.25%) mean:0.377539 min:0 max:1 sd:0.19484\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:319 (86.6848%) mean:0.185465 min:0 max:1 sd:0.244419\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.181751 min:0 max:1 sd:0.248657\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.172783 min:0 max:0.96449 sd:0.228106\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:319 (86.6848%) mean:0.188131 min:0 max:1 sd:0.242964\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.192603 min:0 max:1 sd:0.246936\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.178546 min:0 max:0.99507 sd:0.233015\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:319 (86.6848%) mean:0.183164 min:0 max:1 sd:0.231918\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.18587 min:0 max:1 sd:0.236763\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.173057 min:0 max:1 sd:0.211776\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:17 (4.61957%) mean:0.61026 min:0 max:1 sd:0.320112\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:17 (4.61957%) mean:0.689694 min:0 max:1 sd:0.276344\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:17 (4.61957%) mean:0.468091 min:0 max:1 sd:0.27861\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:19 (5.16304%) mean:0.537128 min:0 max:1 sd:0.362284\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.639343 min:0 max:1 sd:0.31341\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.405077 min:0 max:1 sd:0.327863\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:27 (7.33696%) mean:0.425658 min:0 max:1 sd:0.322846\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:27 (7.33696%) mean:0.584241 min:0 max:1 sd:0.254439\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:27 (7.33696%) mean:0.351291 min:0 max:0.985907 sd:0.2828\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.523573 min:0.0105506 max:1 sd:0.226524\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.519618 min:0 max:1 sd:0.238992\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:7 (1.90217%) mean:0.516014 min:0 max:1 sd:0.171906\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.473485 min:0 max:1 sd:0.183179\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:69 (18.75%) mean:0.458504 min:0.0410427 max:0.988268 sd:0.187392\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.517099 min:0 max:1 sd:0.200443\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.457612 min:0 max:1 sd:0.18418\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.452681 min:0 max:0.989602 sd:0.196194\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:15 (4.07609%) mean:0.465373 min:0 max:1 sd:0.196334\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:17 (4.61957%) mean:0.433191 min:0 max:1 sd:0.203184\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:62 (16.8478%) mean:0.428903 min:0 max:0.963645 sd:0.253457\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.568043 min:0 max:1 sd:0.173515\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:38 (10.3261%) mean:0.529215 min:0 max:1 sd:0.178043\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:79 (21.4674%) mean:0.485167 min:0 max:0.988906 sd:0.193622\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.517621 min:0 max:1 sd:0.204206\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.53599 min:0 max:1 sd:0.193661\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:271 (73.6413%) mean:0.435643 min:0 max:1 sd:0.214713\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.446433 min:0 max:1 sd:0.215047\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:118 (32.0652%) mean:0.456743 min:0 max:1 sd:0.204949\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:259 (70.3804%) mean:0.33089 min:0 max:0.949324 sd:0.239965\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:319 (86.6848%) mean:0.024737 min:0 max:1 sd:0.14158\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0412019 min:0 max:1 sd:0.142534\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.024841 min:0 max:1 sd:0.14148\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:319 (86.6848%) mean:0.400664 min:0 max:1 sd:0.224945\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.391286 min:0 max:1 sd:0.223427\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.514817 min:0 max:1 sd:0.193582\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:319 (86.6848%) mean:0.0988264 min:0 max:1 sd:0.185342\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.124667 min:0 max:1 sd:0.236973\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0823079 min:0.000337785 max:1 sd:0.166801\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:319 (86.6848%) mean:0.136687 min:0 max:1 sd:0.137825\n",
      "\t83: \"var_index\" NUMERICAL num-nas:119 (32.337%) mean:0.0793464 min:0 max:0.978261 sd:0.130072\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.75297 min:0 max:1 sd:0.277199\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.804118 min:0 max:1 sd:0.245017\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.0181935 min:0 max:0.389902 sd:0.0686358\n",
      "\t87: \"var_max\" NUMERICAL num-nas:119 (32.337%) mean:0.0120449 min:0 max:1 sd:0.0668578\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:119 (32.337%) mean:0.049836 min:0 max:1 sd:0.119139\n",
      "\t89: \"var_min\" NUMERICAL num-nas:119 (32.337%) mean:0.0422547 min:0 max:1 sd:0.111854\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.42406 min:0 max:0.99369 sd:0.173599\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:119 (32.337%) mean:0.00791098 min:0 max:1 sd:0.0656744\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:3) done accuracy:0.888889 logloss:4.00485\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.888587 logloss:1.47035\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:18) done accuracy:0.891304 logloss:0.440227\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:31) done accuracy:0.896739 logloss:0.258213\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.875 logloss:0.259818\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.872283 logloss:0.26277\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:59) done accuracy:0.877717 logloss:0.257312\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:69) done accuracy:0.883152 logloss:0.260759\n",
      "[INFO random_forest.cc:578] Training of tree  82/300 (tree index:82) done accuracy:0.877717 logloss:0.259297\n",
      "[INFO random_forest.cc:578] Training of tree  92/300 (tree index:92) done accuracy:0.888587 logloss:0.258803\n",
      "[INFO random_forest.cc:578] Training of tree  102/300 (tree index:99) done accuracy:0.888587 logloss:0.258508\n",
      "[INFO random_forest.cc:578] Training of tree  112/300 (tree index:111) done accuracy:0.880435 logloss:0.261472\n",
      "[INFO random_forest.cc:578] Training of tree  122/300 (tree index:122) done accuracy:0.88587 logloss:0.260433\n",
      "[INFO random_forest.cc:578] Training of tree  132/300 (tree index:132) done accuracy:0.894022 logloss:0.260841\n",
      "[INFO random_forest.cc:578] Training of tree  142/300 (tree index:140) done accuracy:0.888587 logloss:0.259994\n",
      "[INFO random_forest.cc:578] Training of tree  152/300 (tree index:153) done accuracy:0.899457 logloss:0.256957\n",
      "[INFO random_forest.cc:578] Training of tree  162/300 (tree index:161) done accuracy:0.894022 logloss:0.260777\n",
      "[INFO random_forest.cc:578] Training of tree  172/300 (tree index:171) done accuracy:0.896739 logloss:0.258499\n",
      "[INFO random_forest.cc:578] Training of tree  182/300 (tree index:182) done accuracy:0.894022 logloss:0.257685\n",
      "[INFO random_forest.cc:578] Training of tree  192/300 (tree index:192) done accuracy:0.894022 logloss:0.258405\n",
      "[INFO random_forest.cc:578] Training of tree  202/300 (tree index:201) done accuracy:0.899457 logloss:0.258074\n",
      "[INFO random_forest.cc:578] Training of tree  212/300 (tree index:211) done accuracy:0.896739 logloss:0.25759\n",
      "[INFO random_forest.cc:578] Training of tree  222/300 (tree index:220) done accuracy:0.899457 logloss:0.258422\n",
      "[INFO random_forest.cc:578] Training of tree  232/300 (tree index:234) done accuracy:0.899457 logloss:0.256878\n",
      "[INFO random_forest.cc:578] Training of tree  242/300 (tree index:241) done accuracy:0.896739 logloss:0.257498\n",
      "[INFO random_forest.cc:578] Training of tree  252/300 (tree index:249) done accuracy:0.896739 logloss:0.258391\n",
      "[INFO random_forest.cc:578] Training of tree  262/300 (tree index:259) done accuracy:0.894022 logloss:0.258937\n",
      "[INFO random_forest.cc:578] Training of tree  272/300 (tree index:271) done accuracy:0.896739 logloss:0.259571\n",
      "[INFO random_forest.cc:578] Training of tree  282/300 (tree index:281) done accuracy:0.894022 logloss:0.258372\n",
      "[INFO random_forest.cc:578] Training of tree  292/300 (tree index:291) done accuracy:0.894022 logloss:0.257238\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.896739 logloss:0.25761\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.896739 logloss:0.25761\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpwgc1z7mr\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13100 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9946\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 28%|██▊       | 9/32 [00:31<01:11,  3.10s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.101765 min:7.20293e-05 max:1 sd:0.185213\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.119088 min:7.14336e-05 max:1 sd:0.204321\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0855211 min:2.30324e-07 max:1 sd:0.172743\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.16252 min:0 max:1 sd:0.164906\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.00591479 min:0 max:0.0453877 sd:0.00711427\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.149923 min:0 max:1 sd:0.160102\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0685172 min:0 max:1 sd:0.179144\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0800077 min:6.01976e-05 max:1 sd:0.19571\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.0964156 min:0 max:1 sd:0.205375\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.195205 min:0 max:1 sd:0.15971\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.0699375 min:0 max:1 sd:0.204353\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.137282 min:0 max:1 sd:0.205108\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0539833 min:0 max:1 sd:0.156073\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0848934 min:0 max:1 sd:0.18037\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0873447 min:0 max:0.917609 sd:0.177793\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0824936 min:0 max:1 sd:0.17526\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.107756 min:0 max:1 sd:0.159661\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.523555 min:0 max:1 sd:0.180502\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.485211 min:0 max:1 sd:0.185219\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:71 (19.2935%) mean:0.472955 min:0 max:1 sd:0.186583\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.498272 min:0 max:0.973154 sd:0.17812\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.5087 min:0 max:1 sd:0.183819\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.49272 min:0 max:1 sd:0.188298\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:24 (6.52174%) mean:0.445742 min:0 max:1 sd:0.176572\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:28 (7.6087%) mean:0.441068 min:0.0587585 max:1 sd:0.196869\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:97 (26.3587%) mean:0.399808 min:0 max:0.758723 sd:0.188248\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.576013 min:0 max:1 sd:0.173048\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.522131 min:0 max:1 sd:0.182332\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:84 (22.8261%) mean:0.514182 min:0 max:1 sd:0.185825\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.493836 min:0.0631581 max:1 sd:0.188972\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.512042 min:0 max:1 sd:0.200949\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:315 (85.5978%) mean:0.428139 min:0 max:0.850997 sd:0.196702\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.423569 min:0 max:1 sd:0.194415\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.419146 min:0 max:1 sd:0.217535\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:306 (83.1522%) mean:0.373001 min:0.0423683 max:0.753454 sd:0.179086\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:324 (88.0435%) mean:0.18658 min:0 max:1 sd:0.265359\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.182658 min:0 max:1 sd:0.265988\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.176589 min:0.00113829 max:1 sd:0.257612\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:324 (88.0435%) mean:0.186712 min:0.000264866 max:1 sd:0.264659\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.190229 min:0.000264511 max:1 sd:0.265178\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.177977 min:0.00023666 max:1 sd:0.258257\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:324 (88.0435%) mean:0.185255 min:0.00202142 max:1 sd:0.255509\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.186714 min:0.000269833 max:1 sd:0.257261\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.177603 min:0.00301021 max:1 sd:0.242724\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:19 (5.16304%) mean:0.614544 min:0 max:1 sd:0.321021\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.6937 min:0 max:1 sd:0.274762\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.475175 min:0 max:1 sd:0.27988\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:23 (6.25%) mean:0.544907 min:0 max:1 sd:0.358769\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:23 (6.25%) mean:0.647082 min:0 max:1 sd:0.312075\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:23 (6.25%) mean:0.417157 min:0 max:1 sd:0.325498\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:30 (8.15217%) mean:0.427467 min:0 max:1 sd:0.321912\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:30 (8.15217%) mean:0.586816 min:0 max:1 sd:0.253535\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:30 (8.15217%) mean:0.348363 min:0 max:1 sd:0.282422\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.507638 min:0 max:1 sd:0.229064\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.517802 min:0 max:1 sd:0.236776\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.521689 min:0 max:1 sd:0.167527\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.474909 min:0 max:1 sd:0.178359\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.460573 min:0 max:1 sd:0.183708\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.521653 min:0 max:1 sd:0.193566\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:8 (2.17391%) mean:0.46206 min:0 max:1 sd:0.178636\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.458702 min:0 max:1 sd:0.193662\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.469529 min:0 max:1 sd:0.193143\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.436518 min:0.05674 max:1 sd:0.19675\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:66 (17.9348%) mean:0.434932 min:0.0148538 max:1 sd:0.250398\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:8 (2.17391%) mean:0.57409 min:0 max:1 sd:0.166121\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.528397 min:0 max:1 sd:0.174655\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.489132 min:0 max:1 sd:0.188778\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:116 (31.5217%) mean:0.527476 min:0.0398283 max:1 sd:0.197276\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.532679 min:0 max:1 sd:0.191752\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:276 (75%) mean:0.446582 min:0.0394833 max:1 sd:0.217882\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:107 (29.0761%) mean:0.455974 min:0.000368284 max:1 sd:0.209682\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:119 (32.337%) mean:0.453814 min:0 max:1 sd:0.201834\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:265 (72.0109%) mean:0.351487 min:0 max:1 sd:0.25157\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0273589 min:0 max:1 sd:0.149193\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0440415 min:0 max:1 sd:0.150768\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0274867 min:1.40628e-05 max:1 sd:0.149091\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:324 (88.0435%) mean:0.395702 min:0.0312225 max:1 sd:0.209639\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.383495 min:0 max:1 sd:0.215304\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.512554 min:0.223379 max:1 sd:0.172133\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0912538 min:0 max:1 sd:0.181182\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.105573 min:0 max:1 sd:0.202308\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0816668 min:0 max:1 sd:0.169724\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.14004 min:0 max:1 sd:0.146423\n",
      "\t83: \"var_index\" NUMERICAL num-nas:117 (31.7935%) mean:0.0790678 min:0 max:0.978261 sd:0.130251\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:29 (7.88043%) mean:0.749545 min:0 max:1 sd:0.278969\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:29 (7.88043%) mean:0.80153 min:0 max:1 sd:0.243399\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:29 (7.88043%) mean:0.0232784 min:0 max:1 sd:0.089709\n",
      "\t87: \"var_max\" NUMERICAL num-nas:117 (31.7935%) mean:0.0117229 min:1.72134e-05 max:1 sd:0.0666853\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:117 (31.7935%) mean:0.0466238 min:7.9609e-05 max:1 sd:0.115089\n",
      "\t89: \"var_min\" NUMERICAL num-nas:117 (31.7935%) mean:0.0382797 min:2.4978e-05 max:1 sd:0.104364\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.425687 min:0.0066253 max:0.99369 sd:0.169003\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:117 (31.7935%) mean:0.00817405 min:0 max:1 sd:0.0657679\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.875 logloss:4.50546\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.866485 logloss:1.20071\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.899457 logloss:0.536706\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.902174 logloss:0.452404\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.904891 logloss:0.448754\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:48) done accuracy:0.904891 logloss:0.352662\n",
      "[INFO random_forest.cc:578] Training of tree  62/300 (tree index:61) done accuracy:0.907609 logloss:0.351936\n",
      "[INFO random_forest.cc:578] Training of tree  72/300 (tree index:71) done accuracy:0.913043 logloss:0.354006\n",
      "[INFO random_forest.cc:578] Training of tree  82/300 (tree index:80) done accuracy:0.910326 logloss:0.267008\n",
      "[INFO random_forest.cc:578] Training of tree  93/300 (tree index:92) done accuracy:0.913043 logloss:0.268055\n",
      "[INFO random_forest.cc:578] Training of tree  103/300 (tree index:105) done accuracy:0.907609 logloss:0.271275\n",
      "[INFO random_forest.cc:578] Training of tree  113/300 (tree index:113) done accuracy:0.913043 logloss:0.270075\n",
      "[INFO random_forest.cc:578] Training of tree  123/300 (tree index:124) done accuracy:0.907609 logloss:0.269847\n",
      "[INFO random_forest.cc:578] Training of tree  133/300 (tree index:133) done accuracy:0.904891 logloss:0.269034\n",
      "[INFO random_forest.cc:578] Training of tree  143/300 (tree index:143) done accuracy:0.904891 logloss:0.269245\n",
      "[INFO random_forest.cc:578] Training of tree  153/300 (tree index:150) done accuracy:0.907609 logloss:0.263502\n",
      "[INFO random_forest.cc:578] Training of tree  163/300 (tree index:165) done accuracy:0.910326 logloss:0.263049\n",
      "[INFO random_forest.cc:578] Training of tree  173/300 (tree index:173) done accuracy:0.910326 logloss:0.262045\n",
      "[INFO random_forest.cc:578] Training of tree  183/300 (tree index:183) done accuracy:0.915761 logloss:0.261888\n",
      "[INFO random_forest.cc:578] Training of tree  193/300 (tree index:190) done accuracy:0.904891 logloss:0.262194\n",
      "[INFO random_forest.cc:578] Training of tree  203/300 (tree index:203) done accuracy:0.904891 logloss:0.261877\n",
      "[INFO random_forest.cc:578] Training of tree  213/300 (tree index:214) done accuracy:0.907609 logloss:0.261714\n",
      "[INFO random_forest.cc:578] Training of tree  223/300 (tree index:225) done accuracy:0.907609 logloss:0.261008\n",
      "[INFO random_forest.cc:578] Training of tree  233/300 (tree index:232) done accuracy:0.904891 logloss:0.2606\n",
      "[INFO random_forest.cc:578] Training of tree  243/300 (tree index:242) done accuracy:0.904891 logloss:0.260581\n",
      "[INFO random_forest.cc:578] Training of tree  253/300 (tree index:250) done accuracy:0.907609 logloss:0.261339\n",
      "[INFO random_forest.cc:578] Training of tree  263/300 (tree index:260) done accuracy:0.907609 logloss:0.26152\n",
      "[INFO random_forest.cc:578] Training of tree  273/300 (tree index:271) done accuracy:0.910326 logloss:0.260466\n",
      "[INFO random_forest.cc:578] Training of tree  283/300 (tree index:282) done accuracy:0.904891 logloss:0.261131\n",
      "[INFO random_forest.cc:578] Training of tree  293/300 (tree index:293) done accuracy:0.904891 logloss:0.260782\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.907609 logloss:0.259685\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.907609 logloss:0.259685\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp4y0dwh1_\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13218 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 31%|███▏      | 10/32 [00:34<01:04,  2.95s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.0661012 min:0 max:0.395994 sd:0.109093\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0856858 min:0 max:0.603673 sd:0.14681\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0490265 min:0 max:0.273173 sd:0.0798385\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.197774 min:0.00335387 max:1 sd:0.216166\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0302085 min:0.000195345 max:1 sd:0.15165\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.172115 min:0.000481116 max:1 sd:0.17962\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0675989 min:0 max:0.496254 sd:0.141627\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0933636 min:0 max:0.978189 sd:0.208925\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:343 (93.2065%) mean:0.0831517 min:0.00246435 max:0.427298 sd:0.128309\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.188185 min:0 max:1 sd:0.162042\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.109086 min:0 max:1 sd:0.260569\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:330 (89.6739%) mean:0.145654 min:0 max:1 sd:0.215382\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0630048 min:0 max:1 sd:0.162125\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0939488 min:5.72011e-11 max:0.726902 sd:0.173864\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.102686 min:0 max:1 sd:0.204272\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.0853948 min:0.000690433 max:0.58012 sd:0.150188\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.0878947 min:0 max:0.570059 sd:0.0834122\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.516542 min:0.0152442 max:0.988978 sd:0.180265\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:32 (8.69565%) mean:0.481511 min:0 max:1 sd:0.181559\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:68 (18.4783%) mean:0.464251 min:0 max:0.980907 sd:0.187542\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.492664 min:0.0995208 max:1 sd:0.178739\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.503435 min:0.0305007 max:1 sd:0.181681\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:12 (3.26087%) mean:0.49163 min:0.0266211 max:0.980704 sd:0.183866\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:23 (6.25%) mean:0.437438 min:0.0181182 max:1 sd:0.176474\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:27 (7.33696%) mean:0.433773 min:0 max:1 sd:0.193552\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.399947 min:0 max:1 sd:0.193434\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:12 (3.26087%) mean:0.569801 min:0.0286664 max:0.990661 sd:0.172674\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.518579 min:0 max:1 sd:0.179491\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:84 (22.8261%) mean:0.506303 min:0 max:0.985639 sd:0.186827\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:116 (31.5217%) mean:0.483992 min:0.0458262 max:1 sd:0.191592\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.513912 min:0 max:1 sd:0.187751\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:314 (85.3261%) mean:0.422813 min:0.020997 max:1 sd:0.187924\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.412875 min:0 max:1 sd:0.195809\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.417045 min:0 max:1 sd:0.206508\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:305 (82.8804%) mean:0.369024 min:0 max:1 sd:0.184711\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:326 (88.587%) mean:0.169588 min:0 max:0.949443 sd:0.253545\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.168148 min:0 max:1 sd:0.258628\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.15665 min:0 max:1 sd:0.241018\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:326 (88.587%) mean:0.171552 min:0 max:1 sd:0.255668\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.175728 min:0 max:1 sd:0.257869\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.163643 min:0 max:1 sd:0.251029\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:326 (88.587%) mean:0.166681 min:0 max:1 sd:0.244829\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.168803 min:0 max:1 sd:0.247013\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.160238 min:0 max:1 sd:0.236523\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.624307 min:0 max:1 sd:0.316387\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.703928 min:0 max:1 sd:0.270254\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.481192 min:0 max:0.993699 sd:0.276625\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:23 (6.25%) mean:0.553904 min:0 max:1 sd:0.354488\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:23 (6.25%) mean:0.655622 min:0 max:1 sd:0.307411\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:23 (6.25%) mean:0.418812 min:0 max:0.99189 sd:0.324193\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:30 (8.15217%) mean:0.425942 min:0 max:1 sd:0.322753\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:30 (8.15217%) mean:0.587266 min:0.0466496 max:1 sd:0.2527\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:30 (8.15217%) mean:0.341642 min:0 max:1 sd:0.28018\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.500679 min:0 max:1 sd:0.229129\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.502566 min:0.00905979 max:1 sd:0.235826\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:7 (1.90217%) mean:0.515388 min:0.0816971 max:1 sd:0.167647\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.468686 min:0 max:1 sd:0.177173\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.454938 min:0.0410427 max:1 sd:0.18303\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.516583 min:0.0278547 max:1 sd:0.194707\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.455366 min:0.0163507 max:1 sd:0.177088\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.455397 min:0.00266063 max:1 sd:0.19149\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.462261 min:0 max:1 sd:0.193517\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.429308 min:0 max:1 sd:0.195646\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.434573 min:0 max:1 sd:0.252768\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.56752 min:0.024159 max:1 sd:0.167573\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:40 (10.8696%) mean:0.523625 min:0 max:1 sd:0.175519\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:75 (20.3804%) mean:0.479254 min:0 max:1 sd:0.192162\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.518852 min:0.0111018 max:1 sd:0.199897\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.535036 min:0.00422152 max:1 sd:0.180153\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:279 (75.8152%) mean:0.441888 min:0 max:0.943335 sd:0.209015\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.447559 min:0 max:1 sd:0.211035\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.453149 min:0.00566975 max:1 sd:0.194048\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:268 (72.8261%) mean:0.34896 min:0 max:1 sd:0.25305\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.00450272 min:0 max:0.107496 sd:0.016432\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0427291 min:0 max:1 sd:0.152588\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0045625 min:0 max:0.100884 sd:0.0156085\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:326 (88.587%) mean:0.376918 min:0 max:1 sd:0.231501\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.373741 min:0 max:1 sd:0.231777\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.490819 min:0 max:1 sd:0.198122\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0888137 min:0 max:0.531611 sd:0.140787\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.119037 min:0 max:0.974137 sd:0.213761\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0692612 min:0.000337785 max:0.426528 sd:0.106776\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.144716 min:0.0100233 max:1 sd:0.146219\n",
      "\t83: \"var_index\" NUMERICAL num-nas:118 (32.0652%) mean:0.0788623 min:0 max:1 sd:0.136862\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:30 (8.15217%) mean:0.756527 min:0 max:1 sd:0.273757\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:30 (8.15217%) mean:0.806905 min:0 max:1 sd:0.239672\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:30 (8.15217%) mean:0.0247256 min:0 max:1 sd:0.092104\n",
      "\t87: \"var_max\" NUMERICAL num-nas:118 (32.0652%) mean:0.011342 min:0 max:1 sd:0.066668\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:118 (32.0652%) mean:0.0417447 min:0 max:1 sd:0.105126\n",
      "\t89: \"var_min\" NUMERICAL num-nas:118 (32.0652%) mean:0.0328458 min:0 max:1 sd:0.0926879\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.430527 min:0 max:1 sd:0.163505\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:118 (32.0652%) mean:0.00839956 min:0 max:1 sd:0.0659097\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.889706 logloss:3.9754\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.861035 logloss:1.38579\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.894022 logloss:0.555075\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.894022 logloss:0.267186\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.888587 logloss:0.257788\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.904891 logloss:0.256933\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:58) done accuracy:0.904891 logloss:0.250597\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:56) done accuracy:0.902174 logloss:0.242335\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.910326 logloss:0.249444\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:92) done accuracy:0.913043 logloss:0.252276\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:97) done accuracy:0.921196 logloss:0.247389\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.918478 logloss:0.248028\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.918478 logloss:0.243325\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.918478 logloss:0.245957\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.921196 logloss:0.246488\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.921196 logloss:0.245337\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.921196 logloss:0.244322\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.921196 logloss:0.248879\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:181) done accuracy:0.923913 logloss:0.249671\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.921196 logloss:0.249829\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.92663 logloss:0.250006\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:212) done accuracy:0.92663 logloss:0.251329\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.923913 logloss:0.251077\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:232) done accuracy:0.92663 logloss:0.251226\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.921196 logloss:0.250417\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:249) done accuracy:0.921196 logloss:0.248996\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:257) done accuracy:0.92663 logloss:0.24882\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:269) done accuracy:0.923913 logloss:0.248754\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:282) done accuracy:0.923913 logloss:0.249642\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:290) done accuracy:0.923913 logloss:0.248251\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.923913 logloss:0.247358\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.923913 logloss:0.247358\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpe14zt2v6\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13036 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9239\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 34%|███▍      | 11/32 [00:37<01:03,  3.02s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.110842 min:0 max:1 sd:0.187807\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.131242 min:0 max:1 sd:0.209116\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0917617 min:0 max:1 sd:0.173755\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.180083 min:0 max:1 sd:0.215957\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0284906 min:0 max:1 sd:0.14835\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.157623 min:0 max:1 sd:0.17978\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0530528 min:0 max:0.478136 sd:0.122678\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0743457 min:0 max:0.978189 sd:0.188624\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.0645105 min:0 max:0.427298 sd:0.110206\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.204041 min:0.0344311 max:1 sd:0.152675\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.104326 min:0 max:1 sd:0.255577\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.128599 min:0 max:1 sd:0.197669\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0610432 min:0 max:1 sd:0.15886\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0771158 min:0 max:0.726902 sd:0.158424\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0850755 min:0 max:1 sd:0.18732\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0722563 min:0.000690433 max:0.58012 sd:0.138374\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.113505 min:0.0205614 max:1 sd:0.157454\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.513682 min:0 max:0.988978 sd:0.182358\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:32 (8.69565%) mean:0.473416 min:0 max:1 sd:0.187566\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:72 (19.5652%) mean:0.459704 min:0.0451185 max:0.980907 sd:0.18782\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.488867 min:0 max:1 sd:0.181818\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.496084 min:0 max:1 sd:0.186349\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:11 (2.98913%) mean:0.481025 min:0 max:0.980704 sd:0.187576\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:23 (6.25%) mean:0.434357 min:0 max:1 sd:0.181245\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:28 (7.6087%) mean:0.434589 min:0 max:1 sd:0.199499\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:92 (25%) mean:0.400729 min:0 max:1 sd:0.19343\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.566294 min:0 max:0.990661 sd:0.174527\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:44 (11.9565%) mean:0.513665 min:0.0378418 max:1 sd:0.180968\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:86 (23.3696%) mean:0.499203 min:0 max:0.985639 sd:0.190477\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.483694 min:0 max:1 sd:0.197836\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.513758 min:0 max:1 sd:0.200972\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:300 (81.5217%) mean:0.428832 min:0 max:1 sd:0.196048\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:108 (29.3478%) mean:0.409922 min:0 max:1 sd:0.203852\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:127 (34.5109%) mean:0.416539 min:0 max:1 sd:0.221282\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:293 (79.6196%) mean:0.371777 min:0 max:1 sd:0.189728\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:324 (88.0435%) mean:0.1931 min:0 max:0.949443 sd:0.250932\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.189172 min:0 max:1 sd:0.254517\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.181175 min:0 max:1 sd:0.24015\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:324 (88.0435%) mean:0.195707 min:0.000264866 max:1 sd:0.254002\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.199328 min:0.000264511 max:1 sd:0.25618\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.187809 min:0.00023666 max:1 sd:0.249407\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:324 (88.0435%) mean:0.192723 min:0 max:1 sd:0.243984\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.194655 min:0.000269833 max:1 sd:0.245982\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.186586 min:0 max:1 sd:0.236384\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.618347 min:0 max:1 sd:0.318612\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.698116 min:0 max:1 sd:0.275111\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.472396 min:0 max:0.993699 sd:0.273317\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.548932 min:0 max:1 sd:0.362659\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.647807 min:0 max:1 sd:0.315905\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.408391 min:0 max:0.99189 sd:0.320792\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:30 (8.15217%) mean:0.415631 min:0 max:1 sd:0.324454\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:30 (8.15217%) mean:0.578256 min:0 max:1 sd:0.254631\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:30 (8.15217%) mean:0.335423 min:0 max:1 sd:0.280923\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:121 (32.8804%) mean:0.508263 min:0 max:1 sd:0.231401\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:121 (32.8804%) mean:0.509244 min:0 max:1 sd:0.23846\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:7 (1.90217%) mean:0.513142 min:0 max:1 sd:0.170957\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.464134 min:0 max:1 sd:0.18116\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.449069 min:0 max:1 sd:0.184851\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.512658 min:0 max:1 sd:0.196834\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:8 (2.17391%) mean:0.450386 min:0 max:1 sd:0.182216\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.446368 min:0 max:1 sd:0.194472\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.458248 min:0 max:1 sd:0.197396\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.428577 min:0 max:1 sd:0.199701\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:61 (16.5761%) mean:0.428861 min:0 max:1 sd:0.247957\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.565261 min:0 max:1 sd:0.169904\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.520149 min:0 max:1 sd:0.177815\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.476665 min:0.0401454 max:1 sd:0.189153\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.514127 min:0 max:1 sd:0.20819\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:136 (36.9565%) mean:0.536022 min:0 max:1 sd:0.191207\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:263 (71.4674%) mean:0.451361 min:0 max:1 sd:0.210154\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:111 (30.163%) mean:0.442995 min:0 max:1 sd:0.218304\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.451863 min:0 max:1 sd:0.20611\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:252 (68.4783%) mean:0.352225 min:0 max:1 sd:0.244773\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0047781 min:0 max:0.107496 sd:0.0160731\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0423614 min:0 max:1 sd:0.148892\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.00498939 min:0 max:0.100884 sd:0.0152839\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:324 (88.0435%) mean:0.384941 min:0 max:1 sd:0.225262\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.376292 min:0 max:1 sd:0.224178\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.501627 min:0 max:1 sd:0.193507\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0724604 min:0 max:0.529646 sd:0.120927\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.097082 min:0 max:0.974137 sd:0.191354\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0563871 min:0 max:0.426528 sd:0.0894472\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.149179 min:0.0193473 max:1 sd:0.142973\n",
      "\t83: \"var_index\" NUMERICAL num-nas:121 (32.8804%) mean:0.0805536 min:0 max:1 sd:0.138559\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:33 (8.96739%) mean:0.750336 min:0 max:1 sd:0.272981\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:33 (8.96739%) mean:0.80665 min:0 max:1 sd:0.234078\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:33 (8.96739%) mean:0.0244336 min:0 max:1 sd:0.0906137\n",
      "\t87: \"var_max\" NUMERICAL num-nas:121 (32.8804%) mean:0.011011 min:0 max:1 sd:0.0662149\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:121 (32.8804%) mean:0.0451409 min:0 max:1 sd:0.1148\n",
      "\t89: \"var_min\" NUMERICAL num-nas:121 (32.8804%) mean:0.0366089 min:0 max:1 sd:0.103438\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:121 (32.8804%) mean:0.433025 min:0 max:1 sd:0.163874\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:121 (32.8804%) mean:0.00790102 min:0 max:1 sd:0.0657148\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.882353 logloss:4.24043\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.834239 logloss:1.24236\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.877717 logloss:0.280343\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:32) done accuracy:0.899457 logloss:0.268024\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.894022 logloss:0.264369\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:52) done accuracy:0.902174 logloss:0.270557\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.896739 logloss:0.267793\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:73) done accuracy:0.894022 logloss:0.26165\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:79) done accuracy:0.896739 logloss:0.266458\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:81) done accuracy:0.894022 logloss:0.266162\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.899457 logloss:0.263116\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.896739 logloss:0.264586\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.904891 logloss:0.261483\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:131) done accuracy:0.896739 logloss:0.261105\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.894022 logloss:0.261035\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.899457 logloss:0.26013\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.902174 logloss:0.259948\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.899457 logloss:0.258832\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.899457 logloss:0.260501\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.904891 logloss:0.260581\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.902174 logloss:0.259356\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.904891 logloss:0.259257\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.902174 logloss:0.258513\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:228) done accuracy:0.904891 logloss:0.258987\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.899457 logloss:0.258798\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.899457 logloss:0.258199\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.902174 logloss:0.258663\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:269) done accuracy:0.896739 logloss:0.256724\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:279) done accuracy:0.902174 logloss:0.255972\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:288) done accuracy:0.904891 logloss:0.25522\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.902174 logloss:0.254437\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.902174 logloss:0.254437\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp1ht1vnbz\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13132 node(s), and 92 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 38%|███▊      | 12/32 [00:40<01:01,  3.09s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:318 (86.413%) mean:0.0848228 min:0 max:0.451509 sd:0.127705\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.104995 min:0 max:0.603673 sd:0.158603\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.0662153 min:0 max:0.388463 sd:0.102788\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:318 (86.413%) mean:0.167382 min:0.00335387 max:1 sd:0.191074\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0253607 min:0.000195345 max:1 sd:0.139395\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.147078 min:0.000481116 max:1 sd:0.157657\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:318 (86.413%) mean:0.0505308 min:0 max:0.496254 sd:0.117232\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.071357 min:0 max:0.978189 sd:0.182795\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:338 (91.8478%) mean:0.0598081 min:0 max:0.39925 sd:0.100031\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:318 (86.413%) mean:0.189894 min:0 max:1 sd:0.151308\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:318 (86.413%) mean:0.0838095 min:0 max:1 sd:0.23296\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.113912 min:0 max:0.696288 sd:0.155052\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.0518712 min:0 max:1 sd:0.147585\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:318 (86.413%) mean:0.0713899 min:5.72011e-11 max:0.726902 sd:0.143115\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0792636 min:0 max:1 sd:0.177062\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0637395 min:0 max:0.571134 sd:0.118352\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:318 (86.413%) mean:0.0852235 min:0 max:0.570059 sd:0.0785597\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.518344 min:0 max:0.988978 sd:0.187669\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:33 (8.96739%) mean:0.483735 min:0 max:1 sd:0.189541\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:74 (20.1087%) mean:0.472035 min:0 max:0.980907 sd:0.186912\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.495016 min:0 max:1 sd:0.183637\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.502964 min:0 max:1 sd:0.190421\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.488101 min:0 max:0.980704 sd:0.190491\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:23 (6.25%) mean:0.441697 min:0 max:1 sd:0.185865\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:25 (6.79348%) mean:0.436706 min:0 max:1 sd:0.202094\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:91 (24.7283%) mean:0.404306 min:0.0641818 max:1 sd:0.188248\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:13 (3.53261%) mean:0.572673 min:0 max:0.990661 sd:0.179933\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:46 (12.5%) mean:0.524155 min:0 max:1 sd:0.185\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:87 (23.6413%) mean:0.512223 min:0 max:0.985639 sd:0.189081\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:117 (31.7935%) mean:0.493524 min:0 max:1 sd:0.200103\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.521471 min:0 max:1 sd:0.197658\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:304 (82.6087%) mean:0.442939 min:0.0665289 max:1 sd:0.188359\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.422495 min:0.0091239 max:1 sd:0.205217\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.424661 min:0 max:1 sd:0.219424\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:296 (80.4348%) mean:0.381133 min:0 max:1 sd:0.183664\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:318 (86.413%) mean:0.164652 min:0 max:0.949443 sd:0.225964\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.161313 min:0 max:1 sd:0.230595\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.155907 min:0 max:1 sd:0.219698\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:318 (86.413%) mean:0.168183 min:0 max:1 sd:0.227745\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.171269 min:0 max:1 sd:0.227687\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.161069 min:0 max:1 sd:0.225142\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:318 (86.413%) mean:0.166458 min:0 max:1 sd:0.223808\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.167352 min:0 max:1 sd:0.223799\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.163757 min:0 max:1 sd:0.222042\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:19 (5.16304%) mean:0.614019 min:0 max:1 sd:0.32131\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.694096 min:0 max:1 sd:0.274862\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.474366 min:0 max:0.981097 sd:0.279093\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.544982 min:0 max:1 sd:0.359628\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.645707 min:0 max:1 sd:0.311873\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.414117 min:0 max:0.987484 sd:0.326644\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:28 (7.6087%) mean:0.420495 min:0 max:1 sd:0.323064\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:28 (7.6087%) mean:0.583711 min:0 max:1 sd:0.252936\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:28 (7.6087%) mean:0.344046 min:0 max:1 sd:0.281759\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.515653 min:0 max:1 sd:0.223704\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.519743 min:0.00905979 max:1 sd:0.227859\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:4 (1.08696%) mean:0.519648 min:0 max:1 sd:0.175076\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.473176 min:0 max:1 sd:0.184784\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:65 (17.663%) mean:0.46215 min:0 max:1 sd:0.186462\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.520625 min:0 max:1 sd:0.197342\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:8 (2.17391%) mean:0.459413 min:0 max:1 sd:0.185361\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.454996 min:0 max:1 sd:0.198424\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.465073 min:0 max:1 sd:0.203867\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:20 (5.43478%) mean:0.432995 min:0 max:1 sd:0.203065\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:61 (16.5761%) mean:0.433441 min:0 max:1 sd:0.247354\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.570725 min:0 max:1 sd:0.174728\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.527687 min:0 max:1 sd:0.182641\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.492358 min:0 max:1 sd:0.190123\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.527817 min:0 max:1 sd:0.209374\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:130 (35.3261%) mean:0.540158 min:0 max:1 sd:0.189677\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:269 (73.0978%) mean:0.453537 min:0 max:1 sd:0.215582\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:111 (30.163%) mean:0.458827 min:0 max:1 sd:0.220503\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:122 (33.1522%) mean:0.458678 min:0 max:1 sd:0.205363\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:257 (69.837%) mean:0.354444 min:0 max:1 sd:0.252459\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:318 (86.413%) mean:0.00446521 min:0 max:0.107496 sd:0.0151216\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0408976 min:0 max:1 sd:0.140272\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.00463741 min:0 max:0.100884 sd:0.0143963\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:318 (86.413%) mean:0.395013 min:0 max:1 sd:0.220702\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.387221 min:0 max:1 sd:0.223306\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.509423 min:0 max:1 sd:0.187181\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:318 (86.413%) mean:0.0719017 min:0 max:0.531611 sd:0.120349\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0958437 min:0 max:0.974137 sd:0.188992\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0561822 min:0.000337785 max:0.426528 sd:0.0882811\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:318 (86.413%) mean:0.137142 min:0 max:1 sd:0.13697\n",
      "\t83: \"var_index\" NUMERICAL num-nas:118 (32.0652%) mean:0.076913 min:0 max:1 sd:0.140551\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:33 (8.96739%) mean:0.750976 min:0 max:1 sd:0.276545\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:33 (8.96739%) mean:0.800983 min:0 max:1 sd:0.242749\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:33 (8.96739%) mean:0.0226277 min:0 max:1 sd:0.0874063\n",
      "\t87: \"var_max\" NUMERICAL num-nas:118 (32.0652%) mean:0.00815029 min:0 max:0.233918 sd:0.0234278\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:118 (32.0652%) mean:0.0464719 min:0 max:1 sd:0.112149\n",
      "\t89: \"var_min\" NUMERICAL num-nas:118 (32.0652%) mean:0.0395111 min:0 max:1 sd:0.1056\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.421431 min:0 max:1 sd:0.173051\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:118 (32.0652%) mean:0.00446147 min:0 max:0.226755 sd:0.0200694\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.897059 logloss:3.71038\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.858311 logloss:1.4897\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.896739 logloss:0.83317\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:31) done accuracy:0.891304 logloss:0.272597\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.899457 logloss:0.26909\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.88587 logloss:0.271684\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.888587 logloss:0.268748\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.891304 logloss:0.268931\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:79) done accuracy:0.894022 logloss:0.266221\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.88587 logloss:0.270012\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:101) done accuracy:0.891304 logloss:0.264297\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.891304 logloss:0.2687\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.888587 logloss:0.266\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.88587 logloss:0.269268\n",
      "[INFO random_forest.cc:578] Training of tree  142/300 (tree index:142) done accuracy:0.88587 logloss:0.268362\n",
      "[INFO random_forest.cc:578] Training of tree  152/300 (tree index:152) done accuracy:0.888587 logloss:0.264595\n",
      "[INFO random_forest.cc:578] Training of tree  162/300 (tree index:161) done accuracy:0.888587 logloss:0.264625\n",
      "[INFO random_forest.cc:578] Training of tree  172/300 (tree index:172) done accuracy:0.888587 logloss:0.264929\n",
      "[INFO random_forest.cc:578] Training of tree  182/300 (tree index:180) done accuracy:0.894022 logloss:0.264147\n",
      "[INFO random_forest.cc:578] Training of tree  192/300 (tree index:192) done accuracy:0.891304 logloss:0.263264\n",
      "[INFO random_forest.cc:578] Training of tree  203/300 (tree index:203) done accuracy:0.888587 logloss:0.261683\n",
      "[INFO random_forest.cc:578] Training of tree  213/300 (tree index:214) done accuracy:0.899457 logloss:0.260116\n",
      "[INFO random_forest.cc:578] Training of tree  223/300 (tree index:223) done accuracy:0.894022 logloss:0.260473\n",
      "[INFO random_forest.cc:578] Training of tree  233/300 (tree index:232) done accuracy:0.896739 logloss:0.260905\n",
      "[INFO random_forest.cc:578] Training of tree  244/300 (tree index:245) done accuracy:0.899457 logloss:0.260859\n",
      "[INFO random_forest.cc:578] Training of tree  254/300 (tree index:254) done accuracy:0.896739 logloss:0.261276\n",
      "[INFO random_forest.cc:578] Training of tree  264/300 (tree index:265) done accuracy:0.899457 logloss:0.262\n",
      "[INFO random_forest.cc:578] Training of tree  274/300 (tree index:272) done accuracy:0.902174 logloss:0.260624\n",
      "[INFO random_forest.cc:578] Training of tree  284/300 (tree index:283) done accuracy:0.904891 logloss:0.25963\n",
      "[INFO random_forest.cc:578] Training of tree  294/300 (tree index:292) done accuracy:0.904891 logloss:0.259171\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.902174 logloss:0.259542\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.902174 logloss:0.259542\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp5j1jhjlr\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12992 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9130\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 41%|████      | 13/32 [00:44<01:00,  3.19s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.110776 min:0 max:1 sd:0.189521\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.129396 min:0 max:1 sd:0.209107\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0934369 min:0 max:1 sd:0.177206\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.18561 min:0 max:1 sd:0.215909\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0286609 min:0 max:1 sd:0.148324\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.16316 min:0 max:1 sd:0.180158\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.075237 min:0 max:1 sd:0.186994\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.096638 min:0 max:1 sd:0.233568\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:344 (93.4783%) mean:0.110728 min:0 max:1 sd:0.217042\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.192378 min:0 max:1 sd:0.156825\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.10561 min:0 max:1 sd:0.255419\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.134175 min:0 max:1 sd:0.200923\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0622522 min:0 max:1 sd:0.158985\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0995682 min:0 max:1 sd:0.209612\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.105889 min:0 max:1 sd:0.224401\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0961532 min:0.000690433 max:1 sd:0.198901\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.1103 min:0 max:1 sd:0.158331\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.516066 min:0 max:1 sd:0.187031\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:31 (8.42391%) mean:0.477815 min:0 max:1 sd:0.191299\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:72 (19.5652%) mean:0.463164 min:0 max:1 sd:0.194969\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.492189 min:0 max:1 sd:0.185713\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.500401 min:0 max:1 sd:0.188952\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:9 (2.44565%) mean:0.484134 min:0 max:1 sd:0.192292\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.434627 min:0 max:1 sd:0.180002\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.434322 min:0 max:1 sd:0.197387\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:95 (25.8152%) mean:0.402138 min:0 max:1 sd:0.197533\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.569374 min:0 max:1 sd:0.178612\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.517743 min:0 max:1 sd:0.185274\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:85 (23.0978%) mean:0.504778 min:0 max:1 sd:0.195158\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:117 (31.7935%) mean:0.483484 min:0.0458262 max:1 sd:0.195542\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.512082 min:0 max:1 sd:0.196948\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.444179 min:0.020997 max:1 sd:0.204446\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.408026 min:0 max:1 sd:0.202688\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.412035 min:0 max:1 sd:0.218709\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:301 (81.7935%) mean:0.387239 min:0 max:1 sd:0.201398\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:324 (88.0435%) mean:0.210295 min:0 max:1 sd:0.275283\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.204969 min:0 max:1 sd:0.274837\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.198175 min:0 max:1 sd:0.263891\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:324 (88.0435%) mean:0.21192 min:0 max:1 sd:0.276119\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.21562 min:0 max:1 sd:0.27868\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.202893 min:0 max:1 sd:0.268143\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:324 (88.0435%) mean:0.206368 min:0 max:1 sd:0.262095\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.208763 min:0 max:1 sd:0.265402\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.195898 min:0 max:1 sd:0.244538\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.627184 min:0 max:1 sd:0.317325\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.704857 min:0 max:1 sd:0.273481\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.480367 min:0 max:1 sd:0.275946\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:18 (4.8913%) mean:0.549945 min:0 max:1 sd:0.359904\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.651416 min:0 max:1 sd:0.313047\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.413672 min:0 max:1 sd:0.323198\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:26 (7.06522%) mean:0.417628 min:0 max:1 sd:0.323422\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:26 (7.06522%) mean:0.582245 min:0 max:1 sd:0.254215\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:26 (7.06522%) mean:0.337337 min:0 max:1 sd:0.27871\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.509054 min:0 max:1 sd:0.227805\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.510616 min:0.014093 max:1 sd:0.236442\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.515268 min:0 max:1 sd:0.174078\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.4686 min:0 max:1 sd:0.183188\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:63 (17.1196%) mean:0.452248 min:0 max:1 sd:0.193141\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.515098 min:0 max:1 sd:0.200007\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.454408 min:0 max:1 sd:0.183766\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:2 (0.543478%) mean:0.450478 min:0 max:1 sd:0.199611\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.457729 min:0 max:1 sd:0.197552\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:17 (4.61957%) mean:0.429044 min:0 max:1 sd:0.198211\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.432167 min:0 max:1 sd:0.254127\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.566187 min:0 max:1 sd:0.175072\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.52518 min:0 max:1 sd:0.17879\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.484165 min:0 max:1 sd:0.196919\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.516608 min:0.0111018 max:1 sd:0.204699\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:130 (35.3261%) mean:0.531519 min:0 max:1 sd:0.190421\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:269 (73.0978%) mean:0.444177 min:0.0394833 max:1 sd:0.222731\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.441364 min:0 max:1 sd:0.21847\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.447887 min:0 max:1 sd:0.203823\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:256 (69.5652%) mean:0.353176 min:0 max:1 sd:0.255713\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0273426 min:0 max:1 sd:0.149197\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0421265 min:0 max:1 sd:0.150594\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0275295 min:0 max:1 sd:0.149085\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:324 (88.0435%) mean:0.391271 min:0 max:1 sd:0.230275\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.382302 min:0 max:1 sd:0.227197\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.506707 min:0 max:1 sd:0.198818\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0948742 min:0 max:1 sd:0.183513\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.119747 min:0 max:1 sd:0.233618\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0791239 min:0 max:1 sd:0.167957\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.149592 min:0.0100233 max:1 sd:0.144752\n",
      "\t83: \"var_index\" NUMERICAL num-nas:120 (32.6087%) mean:0.0776064 min:0 max:1 sd:0.140513\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:31 (8.42391%) mean:0.748992 min:0 max:1 sd:0.280164\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:31 (8.42391%) mean:0.802887 min:0 max:1 sd:0.243614\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:31 (8.42391%) mean:0.0231802 min:0 max:1 sd:0.0899899\n",
      "\t87: \"var_max\" NUMERICAL num-nas:120 (32.6087%) mean:0.00730933 min:0 max:0.233918 sd:0.0202757\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:120 (32.6087%) mean:0.0448957 min:0 max:1 sd:0.110398\n",
      "\t89: \"var_min\" NUMERICAL num-nas:120 (32.6087%) mean:0.0380271 min:0 max:1 sd:0.102968\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.427987 min:0 max:1 sd:0.169603\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:120 (32.6087%) mean:0.00408697 min:0 max:0.226755 sd:0.0180132\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:3) done accuracy:0.81746 logloss:6.5794\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.844262 logloss:1.14086\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:13) done accuracy:0.861413 logloss:0.476891\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:29) done accuracy:0.888587 logloss:0.360888\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.891304 logloss:0.262235\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:51) done accuracy:0.904891 logloss:0.269392\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:63) done accuracy:0.913043 logloss:0.262174\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:61) done accuracy:0.907609 logloss:0.264483\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:82) done accuracy:0.896739 logloss:0.265627\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:93) done accuracy:0.891304 logloss:0.263437\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:101) done accuracy:0.904891 logloss:0.263675\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.904891 logloss:0.264907\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.902174 logloss:0.261101\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.894022 logloss:0.263693\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.899457 logloss:0.263866\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.899457 logloss:0.264061\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:159) done accuracy:0.894022 logloss:0.267601\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.88587 logloss:0.268467\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:182) done accuracy:0.891304 logloss:0.268829\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:189) done accuracy:0.891304 logloss:0.268933\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:200) done accuracy:0.896739 logloss:0.268446\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.902174 logloss:0.268118\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.899457 logloss:0.268526\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:231) done accuracy:0.902174 logloss:0.268408\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:238) done accuracy:0.899457 logloss:0.266539\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:251) done accuracy:0.904891 logloss:0.265258\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.902174 logloss:0.264133\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:269) done accuracy:0.904891 logloss:0.262249\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:279) done accuracy:0.910326 logloss:0.261619\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.913043 logloss:0.261128\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.910326 logloss:0.260613\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.910326 logloss:0.260613\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpenc60g98\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13184 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9348\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 44%|████▍     | 14/32 [00:47<00:58,  3.26s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.114999 min:0 max:1 sd:0.186919\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.133879 min:0 max:1 sd:0.206427\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0969426 min:0 max:1 sd:0.174226\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.170783 min:0 max:1 sd:0.209865\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0271409 min:0 max:1 sd:0.145211\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.150614 min:0 max:1 sd:0.174938\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.046532 min:0 max:0.478136 sd:0.113106\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0648869 min:0 max:0.978189 sd:0.17698\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.0577362 min:0.00246435 max:0.427298 sd:0.102569\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.198694 min:0 max:1 sd:0.156914\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.0997193 min:0 max:1 sd:0.250745\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.103046 min:0 max:0.653588 sd:0.133123\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0589325 min:0 max:1 sd:0.155664\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0686631 min:0 max:0.726902 sd:0.148202\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0751932 min:0 max:1 sd:0.175922\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0649658 min:0 max:0.58012 sd:0.130377\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.10523 min:0 max:1 sd:0.156069\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.519742 min:0 max:0.988978 sd:0.186311\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.483666 min:0 max:1 sd:0.1883\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:69 (18.75%) mean:0.464208 min:0 max:0.980907 sd:0.192366\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.495201 min:0 max:1 sd:0.185118\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.504717 min:0 max:1 sd:0.188185\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.487978 min:0 max:0.980704 sd:0.189087\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:21 (5.70652%) mean:0.44196 min:0 max:1 sd:0.181858\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:25 (6.79348%) mean:0.446556 min:0 max:1 sd:0.200005\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:85 (23.0978%) mean:0.407208 min:0 max:1 sd:0.194841\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.571861 min:0 max:0.990661 sd:0.177518\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.520365 min:0 max:1 sd:0.183878\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:82 (22.2826%) mean:0.503741 min:0 max:0.985639 sd:0.192222\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.487886 min:0 max:1 sd:0.197517\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.518514 min:0.0265645 max:1 sd:0.198089\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:301 (81.7935%) mean:0.45183 min:0 max:1 sd:0.20485\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.416298 min:0 max:1 sd:0.202287\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:114 (30.9783%) mean:0.421955 min:0.00700149 max:1 sd:0.219888\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:294 (79.8913%) mean:0.390024 min:0.0423683 max:1 sd:0.194778\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:322 (87.5%) mean:0.192623 min:0 max:0.949443 sd:0.245983\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.188184 min:0 max:1 sd:0.249414\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.181483 min:0 max:1 sd:0.235543\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:322 (87.5%) mean:0.195771 min:0 max:1 sd:0.248707\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.199633 min:0 max:1 sd:0.250692\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.187965 min:0 max:1 sd:0.244259\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:322 (87.5%) mean:0.192258 min:0 max:1 sd:0.238951\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.194046 min:0 max:1 sd:0.240899\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.186421 min:0 max:1 sd:0.231518\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:15 (4.07609%) mean:0.622765 min:0 max:1 sd:0.314167\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:15 (4.07609%) mean:0.701148 min:0 max:1 sd:0.272754\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:15 (4.07609%) mean:0.47585 min:0 max:0.993699 sd:0.27228\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.531348 min:0 max:1 sd:0.355679\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.636058 min:0 max:1 sd:0.309038\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.399696 min:0 max:0.99189 sd:0.319826\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:26 (7.06522%) mean:0.412797 min:0 max:1 sd:0.317235\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:26 (7.06522%) mean:0.575048 min:0 max:1 sd:0.254063\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:26 (7.06522%) mean:0.335186 min:0 max:1 sd:0.279608\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.509731 min:0 max:1 sd:0.233589\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.508717 min:0 max:1 sd:0.240623\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.521355 min:0 max:1 sd:0.173866\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.475416 min:0.0902793 max:1 sd:0.182513\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:63 (17.1196%) mean:0.454541 min:0 max:1 sd:0.190695\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.522802 min:0 max:1 sd:0.200712\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.460695 min:0 max:1 sd:0.184257\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.455769 min:0 max:1 sd:0.19527\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:14 (3.80435%) mean:0.465257 min:0 max:1 sd:0.199138\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.44213 min:0 max:1 sd:0.200149\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:57 (15.4891%) mean:0.441844 min:0.0116859 max:1 sd:0.25193\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.572033 min:0 max:1 sd:0.171379\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.527844 min:0 max:1 sd:0.179656\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.481428 min:0 max:1 sd:0.195876\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.52113 min:0 max:1 sd:0.206951\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.538074 min:0 max:1 sd:0.189757\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:264 (71.7391%) mean:0.468702 min:0 max:1 sd:0.216883\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:104 (28.2609%) mean:0.449288 min:0.000368284 max:1 sd:0.217879\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:114 (30.9783%) mean:0.457476 min:0 max:1 sd:0.204132\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:254 (69.0217%) mean:0.365275 min:0 max:1 sd:0.256521\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.00476852 min:0 max:0.107496 sd:0.0157158\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0420831 min:0 max:1 sd:0.145619\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.00499564 min:0 max:0.100884 sd:0.0149436\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:322 (87.5%) mean:0.390683 min:0 max:1 sd:0.22733\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.378082 min:0 max:1 sd:0.225434\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.509483 min:0 max:1 sd:0.195043\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0652659 min:0 max:0.529646 sd:0.110017\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.086607 min:0 max:0.974137 sd:0.177862\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.051538 min:0 max:0.426528 sd:0.0816521\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.141046 min:0 max:1 sd:0.143044\n",
      "\t83: \"var_index\" NUMERICAL num-nas:118 (32.0652%) mean:0.0771449 min:0 max:1 sd:0.132656\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.75594 min:0 max:1 sd:0.279665\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.808388 min:0 max:1 sd:0.243516\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.0222378 min:0 max:1 sd:0.0891972\n",
      "\t87: \"var_max\" NUMERICAL num-nas:118 (32.0652%) mean:0.0122059 min:3.11037e-05 max:1 sd:0.0668606\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:118 (32.0652%) mean:0.0495297 min:7.9609e-05 max:1 sd:0.117899\n",
      "\t89: \"var_min\" NUMERICAL num-nas:118 (32.0652%) mean:0.0406985 min:2.4978e-05 max:1 sd:0.107019\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.427922 min:0 max:1 sd:0.168264\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:118 (32.0652%) mean:0.0085048 min:0 max:1 sd:0.0659513\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:1) done accuracy:0.869231 logloss:4.7134\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.855586 logloss:1.48552\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.910326 logloss:0.534231\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:32) done accuracy:0.899457 logloss:0.449011\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.902174 logloss:0.451206\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.902174 logloss:0.35497\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:52) done accuracy:0.910326 logloss:0.264243\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:68) done accuracy:0.910326 logloss:0.262515\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:82) done accuracy:0.902174 logloss:0.260796\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:88) done accuracy:0.899457 logloss:0.26163\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.910326 logloss:0.260395\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.907609 logloss:0.258057\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.915761 logloss:0.252822\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:132) done accuracy:0.913043 logloss:0.254212\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.918478 logloss:0.25354\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.915761 logloss:0.253845\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:163) done accuracy:0.910326 logloss:0.254492\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.918478 logloss:0.254283\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:179) done accuracy:0.913043 logloss:0.255655\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.918478 logloss:0.256149\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:198) done accuracy:0.915761 logloss:0.258526\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:208) done accuracy:0.907609 logloss:0.259323\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:221) done accuracy:0.910326 logloss:0.258412\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:228) done accuracy:0.910326 logloss:0.258691\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.910326 logloss:0.258421\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:252) done accuracy:0.910326 logloss:0.258534\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:261) done accuracy:0.910326 logloss:0.260735\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:272) done accuracy:0.907609 logloss:0.259403\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:282) done accuracy:0.910326 logloss:0.258674\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.910326 logloss:0.256579\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:293) done accuracy:0.907609 logloss:0.25573\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.907609 logloss:0.25573\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp1yv9qi7q\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13156 node(s), and 91 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8913\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 47%|████▋     | 15/32 [00:50<00:55,  3.29s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:323 (87.7717%) mean:0.0947491 min:0 max:0.451509 sd:0.130349\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.11459 min:0 max:0.603673 sd:0.157732\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0762208 min:0 max:0.388463 sd:0.109798\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:323 (87.7717%) mean:0.153478 min:0.00335387 max:0.946182 sd:0.169059\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0268543 min:0.000195345 max:1 sd:0.146773\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.130903 min:0.000481116 max:0.586641 sd:0.11724\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:323 (87.7717%) mean:0.0844423 min:0 max:1 sd:0.195044\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.108107 min:0 max:1 sd:0.243599\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.117363 min:0 max:1 sd:0.217135\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:323 (87.7717%) mean:0.176556 min:0.0344311 max:0.449374 sd:0.0954195\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:323 (87.7717%) mean:0.0582535 min:0 max:1 sd:0.163572\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.130619 min:0 max:1 sd:0.210178\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0288837 min:0 max:0.242752 sd:0.0421714\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:323 (87.7717%) mean:0.10732 min:5.72011e-11 max:1 sd:0.216277\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.113562 min:0 max:1 sd:0.232871\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.100239 min:0 max:1 sd:0.20156\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:323 (87.7717%) mean:0.0810904 min:0.0153633 max:0.149243 sd:0.0360195\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.523465 min:0 max:1 sd:0.180293\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.48412 min:0.0158986 max:1 sd:0.18318\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:67 (18.2065%) mean:0.464209 min:0 max:1 sd:0.187824\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.498439 min:0 max:1 sd:0.17901\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.506702 min:0 max:1 sd:0.182936\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:9 (2.44565%) mean:0.489474 min:0 max:1 sd:0.185004\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:26 (7.06522%) mean:0.441248 min:0 max:1 sd:0.177469\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.435704 min:0.0587585 max:1 sd:0.202264\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:95 (25.8152%) mean:0.414123 min:0.0521682 max:1 sd:0.189683\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.574301 min:0 max:1 sd:0.173603\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.521178 min:0 max:1 sd:0.180037\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:77 (20.9239%) mean:0.502385 min:0 max:1 sd:0.188542\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:117 (31.7935%) mean:0.487673 min:0.0458262 max:1 sd:0.192836\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:138 (37.5%) mean:0.520941 min:0 max:1 sd:0.201449\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:306 (83.1522%) mean:0.458618 min:0 max:1 sd:0.202873\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.417622 min:0.0091239 max:1 sd:0.198067\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.422177 min:0 max:1 sd:0.222679\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:297 (80.7065%) mean:0.401094 min:0 max:1 sd:0.192982\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:323 (87.7717%) mean:0.199233 min:0 max:1 sd:0.269604\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.185661 min:0 max:0.928857 sd:0.24898\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.195818 min:0 max:1 sd:0.266466\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:323 (87.7717%) mean:0.210157 min:0 max:1 sd:0.278331\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.213697 min:0 max:1 sd:0.280857\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.201356 min:0 max:1 sd:0.270317\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:323 (87.7717%) mean:0.20211 min:0 max:1 sd:0.264077\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.204176 min:0 max:1 sd:0.267246\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.19206 min:0 max:1 sd:0.246912\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.628175 min:0 max:1 sd:0.315672\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.70168 min:0 max:1 sd:0.276121\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.482381 min:0 max:1 sd:0.277171\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.544639 min:0 max:1 sd:0.358242\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.646618 min:0 max:1 sd:0.312153\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.415466 min:0 max:1 sd:0.325312\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:31 (8.42391%) mean:0.419612 min:0 max:1 sd:0.325756\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:31 (8.42391%) mean:0.582702 min:0 max:1 sd:0.255396\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:31 (8.42391%) mean:0.342164 min:0 max:1 sd:0.281873\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.501598 min:0 max:0.999799 sd:0.226051\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.506216 min:0 max:0.999094 sd:0.234544\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:4 (1.08696%) mean:0.519555 min:0 max:1 sd:0.170721\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.472083 min:0 max:1 sd:0.180026\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:58 (15.7609%) mean:0.451152 min:0 max:1 sd:0.187334\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.522269 min:0 max:1 sd:0.195808\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.459504 min:0 max:1 sd:0.178853\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.456385 min:0 max:1 sd:0.189877\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.462726 min:0 max:1 sd:0.194461\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:20 (5.43478%) mean:0.432482 min:0.05674 max:1 sd:0.200888\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:62 (16.8478%) mean:0.441323 min:0 max:1 sd:0.251424\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:8 (2.17391%) mean:0.571218 min:0 max:1 sd:0.168446\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:38 (10.3261%) mean:0.527264 min:0 max:1 sd:0.176439\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:75 (20.3804%) mean:0.482015 min:0 max:1 sd:0.190589\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:121 (32.8804%) mean:0.522112 min:0.0111018 max:1 sd:0.201847\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:136 (36.9565%) mean:0.539391 min:0 max:1 sd:0.192365\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:273 (74.1848%) mean:0.467838 min:0 max:1 sd:0.222201\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.449049 min:0 max:1 sd:0.214709\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.454862 min:0 max:1 sd:0.206589\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:260 (70.6522%) mean:0.377272 min:0 max:1 sd:0.260537\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:323 (87.7717%) mean:0.0270766 min:0 max:1 sd:0.147528\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0457478 min:0 max:1 sd:0.148762\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0272501 min:0 max:1 sd:0.147421\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:323 (87.7717%) mean:0.419548 min:0 max:1 sd:0.22281\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.412372 min:0.100125 max:1 sd:0.221398\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.528911 min:0 max:1 sd:0.192333\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:323 (87.7717%) mean:0.104482 min:0.00234924 max:1 sd:0.192333\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.13206 min:0.00353616 max:1 sd:0.245678\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0851624 min:0.000337785 max:1 sd:0.172141\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:323 (87.7717%) mean:0.129946 min:0 max:0.297436 sd:0.058712\n",
      "\t83: \"var_index\" NUMERICAL num-nas:114 (30.9783%) mean:0.0730771 min:0 max:1 sd:0.131056\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:30 (8.15217%) mean:0.765853 min:0 max:1 sd:0.269392\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:30 (8.15217%) mean:0.815722 min:0 max:1 sd:0.233548\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:30 (8.15217%) mean:0.0265 min:0 max:1 sd:0.0954794\n",
      "\t87: \"var_max\" NUMERICAL num-nas:114 (30.9783%) mean:0.011056 min:0 max:1 sd:0.0649033\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:114 (30.9783%) mean:0.0472742 min:0 max:1 sd:0.116914\n",
      "\t89: \"var_min\" NUMERICAL num-nas:114 (30.9783%) mean:0.0394783 min:0 max:1 sd:0.107478\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.418418 min:0 max:1 sd:0.165782\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:114 (30.9783%) mean:0.00745709 min:0 max:1 sd:0.0640058\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.933824 logloss:2.38524\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.872283 logloss:0.823268\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.875 logloss:0.344787\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:31) done accuracy:0.888587 logloss:0.344374\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.888587 logloss:0.252926\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.904891 logloss:0.256319\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:62) done accuracy:0.918478 logloss:0.250593\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:69) done accuracy:0.899457 logloss:0.2614\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:82) done accuracy:0.888587 logloss:0.263691\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.894022 logloss:0.259014\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:102) done accuracy:0.896739 logloss:0.2616\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.896739 logloss:0.257154\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.902174 logloss:0.254251\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:134) done accuracy:0.902174 logloss:0.254973\n",
      "[INFO random_forest.cc:578] Training of tree  142/300 (tree index:140) done accuracy:0.902174 logloss:0.255622\n",
      "[INFO random_forest.cc:578] Training of tree  152/300 (tree index:153) done accuracy:0.907609 logloss:0.254068\n",
      "[INFO random_forest.cc:578] Training of tree  163/300 (tree index:159) done accuracy:0.910326 logloss:0.255077\n",
      "[INFO random_forest.cc:578] Training of tree  173/300 (tree index:174) done accuracy:0.907609 logloss:0.252856\n",
      "[INFO random_forest.cc:578] Training of tree  183/300 (tree index:182) done accuracy:0.907609 logloss:0.251806\n",
      "[INFO random_forest.cc:578] Training of tree  193/300 (tree index:193) done accuracy:0.902174 logloss:0.252639\n",
      "[INFO random_forest.cc:578] Training of tree  203/300 (tree index:203) done accuracy:0.899457 logloss:0.251937\n",
      "[INFO random_forest.cc:578] Training of tree  213/300 (tree index:214) done accuracy:0.902174 logloss:0.251203\n",
      "[INFO random_forest.cc:578] Training of tree  223/300 (tree index:222) done accuracy:0.904891 logloss:0.251984\n",
      "[INFO random_forest.cc:578] Training of tree  233/300 (tree index:232) done accuracy:0.904891 logloss:0.250631\n",
      "[INFO random_forest.cc:578] Training of tree  243/300 (tree index:243) done accuracy:0.904891 logloss:0.249958\n",
      "[INFO random_forest.cc:578] Training of tree  253/300 (tree index:255) done accuracy:0.904891 logloss:0.251152\n",
      "[INFO random_forest.cc:578] Training of tree  263/300 (tree index:263) done accuracy:0.907609 logloss:0.250178\n",
      "[INFO random_forest.cc:578] Training of tree  273/300 (tree index:273) done accuracy:0.902174 logloss:0.248799\n",
      "[INFO random_forest.cc:578] Training of tree  283/300 (tree index:281) done accuracy:0.902174 logloss:0.249098\n",
      "[INFO random_forest.cc:578] Training of tree  293/300 (tree index:293) done accuracy:0.907609 logloss:0.247854\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:296) done accuracy:0.907609 logloss:0.247982\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.907609 logloss:0.247982\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpmd64g3nw\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12880 node(s), and 91 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8804\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 16/32 [00:55<00:57,  3.60s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0998901 min:0 max:1 sd:0.177653\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.115969 min:0 max:1 sd:0.189744\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0850256 min:0 max:1 sd:0.170065\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.183887 min:0 max:1 sd:0.215649\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0286344 min:0 max:1 sd:0.148328\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.160838 min:0 max:1 sd:0.179484\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0664666 min:1.03904e-10 max:0.496254 sd:0.138666\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0910747 min:0 max:0.978189 sd:0.204624\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.0796669 min:0 max:0.427298 sd:0.124335\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.182582 min:0 max:1 sd:0.15888\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.103115 min:0.000481551 max:1 sd:0.255885\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.120186 min:0.00182679 max:1 sd:0.193029\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0601776 min:0.000412191 max:1 sd:0.159046\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0915752 min:0 max:0.726902 sd:0.17043\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.100849 min:0 max:1 sd:0.199839\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0834731 min:0 max:0.58012 sd:0.14698\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.106661 min:0 max:1 sd:0.15864\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.5182 min:0.0152442 max:0.9862 sd:0.185015\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.481052 min:0 max:0.988198 sd:0.189021\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:71 (19.2935%) mean:0.465322 min:0 max:0.980907 sd:0.190493\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.493261 min:0.0995208 max:1 sd:0.183538\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.502203 min:0.0305007 max:0.987381 sd:0.187824\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:11 (2.98913%) mean:0.486679 min:0.0329348 max:0.980704 sd:0.188736\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:19 (5.16304%) mean:0.437308 min:0.0181182 max:0.953386 sd:0.180427\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.437165 min:0 max:0.987476 sd:0.198688\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:87 (23.6413%) mean:0.401947 min:0 max:1 sd:0.195351\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.572512 min:0.0286664 max:0.983801 sd:0.175533\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.522285 min:0 max:0.990984 sd:0.182495\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:84 (22.8261%) mean:0.508872 min:0 max:0.985639 sd:0.187958\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.486501 min:0 max:0.955238 sd:0.197886\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:131 (35.5978%) mean:0.521362 min:0.0604775 max:0.99344 sd:0.192518\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:302 (82.0652%) mean:0.436409 min:0 max:1 sd:0.211902\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.413991 min:0 max:0.947005 sd:0.202987\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:122 (33.1522%) mean:0.420383 min:0.00700149 max:0.988705 sd:0.216973\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:294 (79.8913%) mean:0.379625 min:0 max:1 sd:0.201602\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:324 (88.0435%) mean:0.175288 min:0.000411857 max:0.949443 sd:0.225056\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.172853 min:0.00028293 max:1 sd:0.234137\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.162948 min:0 max:1 sd:0.210481\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:324 (88.0435%) mean:0.175383 min:0 max:0.988614 sd:0.220898\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.179531 min:0 max:0.972096 sd:0.223433\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.167008 min:0 max:1 sd:0.215756\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:324 (88.0435%) mean:0.171794 min:0 max:0.94107 sd:0.208764\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.173676 min:0 max:0.923367 sd:0.21122\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.165539 min:0 max:0.955403 sd:0.199378\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:15 (4.07609%) mean:0.614469 min:0 max:1 sd:0.321511\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:15 (4.07609%) mean:0.693564 min:0.0483153 max:1 sd:0.275099\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:15 (4.07609%) mean:0.475082 min:0 max:0.993699 sd:0.280733\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:20 (5.43478%) mean:0.550311 min:0 max:1 sd:0.362482\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.646902 min:0.0102696 max:1 sd:0.315177\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.414873 min:0 max:0.99189 sd:0.324348\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:25 (6.79348%) mean:0.422023 min:0 max:1 sd:0.321519\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:25 (6.79348%) mean:0.58449 min:0 max:1 sd:0.25266\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:25 (6.79348%) mean:0.342736 min:0 max:1 sd:0.278544\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.509632 min:0 max:1 sd:0.226106\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.50487 min:0 max:1 sd:0.233376\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:7 (1.90217%) mean:0.519076 min:0.0816971 max:0.957751 sd:0.170776\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.472343 min:0.0902793 max:0.951877 sd:0.180941\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.45496 min:0.0410427 max:1 sd:0.187703\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.517744 min:0.0278547 max:0.952412 sd:0.1962\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.458125 min:0.0448893 max:0.947944 sd:0.180946\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.453373 min:0.00266063 max:1 sd:0.194387\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:13 (3.53261%) mean:0.462565 min:0 max:1 sd:0.199487\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:18 (4.8913%) mean:0.431151 min:0 max:0.973811 sd:0.198772\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:58 (15.7609%) mean:0.430456 min:0 max:1 sd:0.250898\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:12 (3.26087%) mean:0.571956 min:0.0743731 max:0.965585 sd:0.169389\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.526926 min:0 max:0.961149 sd:0.180077\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.485458 min:0 max:1 sd:0.191385\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.519029 min:0 max:1 sd:0.210391\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.542073 min:0.102958 max:0.983341 sd:0.182435\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:265 (72.0109%) mean:0.447959 min:0 max:1 sd:0.222777\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.449713 min:0 max:1 sd:0.219881\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:123 (33.4239%) mean:0.454568 min:0.0788239 max:0.975678 sd:0.201931\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:252 (68.4783%) mean:0.34876 min:0 max:1 sd:0.256931\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.00461352 min:4.38688e-06 max:0.107496 sd:0.0159847\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0433352 min:4.1493e-05 max:1 sd:0.148681\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.00470719 min:0 max:0.100884 sd:0.0151437\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:324 (88.0435%) mean:0.396098 min:0 max:0.891234 sd:0.218226\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.390312 min:0 max:0.896264 sd:0.218117\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.50876 min:0 max:0.911156 sd:0.188349\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0874189 min:0 max:0.531611 sd:0.137979\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.116151 min:0 max:0.974137 sd:0.209576\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0688635 min:0 max:0.426528 sd:0.104427\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.143431 min:0 max:1 sd:0.143265\n",
      "\t83: \"var_index\" NUMERICAL num-nas:117 (31.7935%) mean:0.0779852 min:0 max:1 sd:0.136307\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.748909 min:0 max:1 sd:0.275207\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.802145 min:0 max:1 sd:0.239751\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.020871 min:0 max:1 sd:0.0834527\n",
      "\t87: \"var_max\" NUMERICAL num-nas:117 (31.7935%) mean:0.0107288 min:0 max:1 sd:0.0654119\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:117 (31.7935%) mean:0.0442275 min:0 max:0.623456 sd:0.0994837\n",
      "\t89: \"var_min\" NUMERICAL num-nas:117 (31.7935%) mean:0.0361315 min:0 max:0.54179 sd:0.0860563\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.422771 min:0 max:1 sd:0.172877\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:117 (31.7935%) mean:0.00762177 min:0 max:1 sd:0.0651765\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.897059 logloss:3.71038\n",
      "[INFO random_forest.cc:578] Training of tree  12/300 (tree index:12) done accuracy:0.887324 logloss:1.16067\n",
      "[INFO random_forest.cc:578] Training of tree  22/300 (tree index:22) done accuracy:0.899457 logloss:0.401777\n",
      "[INFO random_forest.cc:578] Training of tree  32/300 (tree index:33) done accuracy:0.891304 logloss:0.332666\n",
      "[INFO random_forest.cc:578] Training of tree  42/300 (tree index:45) done accuracy:0.894022 logloss:0.242765\n",
      "[INFO random_forest.cc:578] Training of tree  52/300 (tree index:54) done accuracy:0.899457 logloss:0.235485\n",
      "[INFO random_forest.cc:578] Training of tree  62/300 (tree index:63) done accuracy:0.904891 logloss:0.233338\n",
      "[INFO random_forest.cc:578] Training of tree  72/300 (tree index:71) done accuracy:0.907609 logloss:0.237681\n",
      "[INFO random_forest.cc:578] Training of tree  82/300 (tree index:82) done accuracy:0.907609 logloss:0.236351\n",
      "[INFO random_forest.cc:578] Training of tree  92/300 (tree index:92) done accuracy:0.918478 logloss:0.238554\n",
      "[INFO random_forest.cc:578] Training of tree  102/300 (tree index:103) done accuracy:0.921196 logloss:0.236506\n",
      "[INFO random_forest.cc:578] Training of tree  112/300 (tree index:112) done accuracy:0.915761 logloss:0.235488\n",
      "[INFO random_forest.cc:578] Training of tree  122/300 (tree index:122) done accuracy:0.921196 logloss:0.230873\n",
      "[INFO random_forest.cc:578] Training of tree  132/300 (tree index:132) done accuracy:0.921196 logloss:0.235387\n",
      "[INFO random_forest.cc:578] Training of tree  142/300 (tree index:144) done accuracy:0.918478 logloss:0.235996\n",
      "[INFO random_forest.cc:578] Training of tree  152/300 (tree index:153) done accuracy:0.918478 logloss:0.234025\n",
      "[INFO random_forest.cc:578] Training of tree  162/300 (tree index:163) done accuracy:0.918478 logloss:0.231951\n",
      "[INFO random_forest.cc:578] Training of tree  172/300 (tree index:172) done accuracy:0.915761 logloss:0.231966\n",
      "[INFO random_forest.cc:578] Training of tree  182/300 (tree index:182) done accuracy:0.915761 logloss:0.231027\n",
      "[INFO random_forest.cc:578] Training of tree  192/300 (tree index:190) done accuracy:0.921196 logloss:0.232299\n",
      "[INFO random_forest.cc:578] Training of tree  202/300 (tree index:200) done accuracy:0.921196 logloss:0.232281\n",
      "[INFO random_forest.cc:578] Training of tree  212/300 (tree index:210) done accuracy:0.918478 logloss:0.232451\n",
      "[INFO random_forest.cc:578] Training of tree  222/300 (tree index:221) done accuracy:0.923913 logloss:0.233284\n",
      "[INFO random_forest.cc:578] Training of tree  232/300 (tree index:231) done accuracy:0.918478 logloss:0.233321\n",
      "[INFO random_forest.cc:578] Training of tree  242/300 (tree index:239) done accuracy:0.921196 logloss:0.232844\n",
      "[INFO random_forest.cc:578] Training of tree  252/300 (tree index:251) done accuracy:0.923913 logloss:0.231387\n",
      "[INFO random_forest.cc:578] Training of tree  262/300 (tree index:261) done accuracy:0.92663 logloss:0.230917\n",
      "[INFO random_forest.cc:578] Training of tree  272/300 (tree index:273) done accuracy:0.923913 logloss:0.231377\n",
      "[INFO random_forest.cc:578] Training of tree  282/300 (tree index:283) done accuracy:0.921196 logloss:0.23108\n",
      "[INFO random_forest.cc:578] Training of tree  292/300 (tree index:291) done accuracy:0.923913 logloss:0.231021\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:295) done accuracy:0.923913 logloss:0.230516\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.923913 logloss:0.230516\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpoyc581ww\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12516 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9946\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.8587\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 53%|█████▎    | 17/32 [00:58<00:53,  3.58s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.108734 min:0 max:1 sd:0.185141\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.128699 min:0 max:1 sd:0.205874\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0899784 min:0 max:1 sd:0.171129\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.186603 min:0 max:1 sd:0.211791\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0277483 min:0 max:1 sd:0.145128\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.1636 min:0 max:1 sd:0.176723\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0755248 min:0 max:1 sd:0.182545\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0966505 min:0 max:1 sd:0.228043\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:340 (92.3913%) mean:0.0999657 min:0 max:1 sd:0.202716\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.177425 min:0 max:1 sd:0.153515\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.101196 min:0 max:1 sd:0.250528\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.139149 min:0 max:1 sd:0.211075\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.059082 min:0 max:1 sd:0.155746\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.100035 min:0 max:1 sd:0.204451\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.106136 min:0.00169533 max:1 sd:0.218938\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0941527 min:0 max:1 sd:0.19202\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.104909 min:0 max:1 sd:0.156686\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.519609 min:0.0152442 max:1 sd:0.183374\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.482084 min:0 max:1 sd:0.188483\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:73 (19.837%) mean:0.468369 min:0 max:1 sd:0.190614\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.494749 min:0.0995208 max:1 sd:0.183355\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.50457 min:0.0305007 max:1 sd:0.187192\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:13 (3.53261%) mean:0.489781 min:0.0266211 max:1 sd:0.189866\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:21 (5.70652%) mean:0.441409 min:0.0181182 max:1 sd:0.177991\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:26 (7.06522%) mean:0.436615 min:0 max:1 sd:0.19963\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.40338 min:0 max:1 sd:0.19599\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:12 (3.26087%) mean:0.572815 min:0.0286664 max:1 sd:0.175151\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.522063 min:0.0378418 max:1 sd:0.182719\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:87 (23.6413%) mean:0.510932 min:0 max:1 sd:0.1884\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.485447 min:0 max:1 sd:0.196059\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.517439 min:0 max:1 sd:0.195546\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:309 (83.9674%) mean:0.441937 min:0.0665289 max:1 sd:0.192318\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.412055 min:0 max:1 sd:0.201856\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.421794 min:0 max:1 sd:0.217027\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:300 (81.5217%) mean:0.387372 min:0 max:1 sd:0.183003\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:322 (87.5%) mean:0.203446 min:0 max:1 sd:0.272348\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.198518 min:0 max:1 sd:0.271558\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.191062 min:0 max:1 sd:0.261198\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:322 (87.5%) mean:0.204689 min:0 max:1 sd:0.273557\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.20902 min:0 max:1 sd:0.275786\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.195055 min:0 max:1 sd:0.265926\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:322 (87.5%) mean:0.200037 min:0 max:1 sd:0.260297\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.202532 min:0 max:1 sd:0.263443\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.189664 min:0 max:1 sd:0.243261\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.612484 min:0 max:1 sd:0.320186\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.693126 min:0 max:1 sd:0.275381\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.473923 min:0 max:1 sd:0.278863\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.55058 min:0 max:1 sd:0.361793\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.648026 min:0 max:1 sd:0.317037\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.414003 min:0 max:1 sd:0.326139\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:29 (7.88043%) mean:0.426988 min:0 max:1 sd:0.320895\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:29 (7.88043%) mean:0.587456 min:0 max:1 sd:0.253263\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:29 (7.88043%) mean:0.346211 min:0 max:1 sd:0.280778\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.514886 min:0 max:1 sd:0.228261\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.516655 min:0.0191262 max:1 sd:0.237213\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.51951 min:0.100042 max:1 sd:0.170419\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:25 (6.79348%) mean:0.471272 min:0 max:1 sd:0.181182\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:61 (16.5761%) mean:0.458091 min:0.0410427 max:1 sd:0.187304\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.521219 min:0.0278547 max:1 sd:0.198925\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.45968 min:0.0163507 max:1 sd:0.181155\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.455732 min:0.00266063 max:1 sd:0.196816\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.465926 min:0 max:1 sd:0.194216\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:20 (5.43478%) mean:0.432717 min:0 max:1 sd:0.198626\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:63 (17.1196%) mean:0.437358 min:0 max:1 sd:0.254342\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:8 (2.17391%) mean:0.570262 min:0.024159 max:1 sd:0.169437\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:35 (9.51087%) mean:0.525056 min:0 max:1 sd:0.179094\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:74 (20.1087%) mean:0.482915 min:0 max:1 sd:0.192982\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.518301 min:0 max:1 sd:0.205964\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.537941 min:0.00422152 max:1 sd:0.185677\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:268 (72.8261%) mean:0.440983 min:0 max:1 sd:0.222134\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:104 (28.2609%) mean:0.444794 min:0 max:1 sd:0.217281\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.455591 min:0.00566975 max:1 sd:0.202864\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:256 (69.5652%) mean:0.34275 min:0 max:1 sd:0.255964\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0263678 min:0 max:1 sd:0.14599\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0421955 min:0 max:1 sd:0.147242\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0265526 min:0 max:1 sd:0.145882\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:322 (87.5%) mean:0.393933 min:0 max:1 sd:0.226331\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.386196 min:0 max:1 sd:0.223264\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.508001 min:0 max:1 sd:0.19544\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0956425 min:0 max:1 sd:0.179005\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.120258 min:0 max:1 sd:0.227936\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0799886 min:0 max:1 sd:0.163808\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.140048 min:0 max:1 sd:0.144604\n",
      "\t83: \"var_index\" NUMERICAL num-nas:117 (31.7935%) mean:0.0855563 min:0 max:1 sd:0.149616\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:35 (9.51087%) mean:0.754498 min:0 max:1 sd:0.273991\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:35 (9.51087%) mean:0.808085 min:0 max:1 sd:0.23786\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:35 (9.51087%) mean:0.0215684 min:0 max:1 sd:0.0859929\n",
      "\t87: \"var_max\" NUMERICAL num-nas:117 (31.7935%) mean:0.0122547 min:0 max:1 sd:0.0668137\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:117 (31.7935%) mean:0.0490177 min:0 max:1 sd:0.119205\n",
      "\t89: \"var_min\" NUMERICAL num-nas:117 (31.7935%) mean:0.039511 min:0 max:1 sd:0.10837\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.433137 min:0 max:1 sd:0.171586\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:117 (31.7935%) mean:0.00871448 min:0 max:1 sd:0.0658989\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.875 logloss:4.50546\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.858696 logloss:1.498\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.88587 logloss:0.2675\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.896739 logloss:0.261949\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.899457 logloss:0.26076\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.894022 logloss:0.263183\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:61) done accuracy:0.899457 logloss:0.259377\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:72) done accuracy:0.913043 logloss:0.259596\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:81) done accuracy:0.910326 logloss:0.258919\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.907609 logloss:0.258546\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.913043 logloss:0.257104\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.904891 logloss:0.257105\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:119) done accuracy:0.904891 logloss:0.254374\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.907609 logloss:0.254281\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.904891 logloss:0.257181\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.899457 logloss:0.254732\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.902174 logloss:0.253802\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.904891 logloss:0.25525\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:179) done accuracy:0.899457 logloss:0.255555\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.907609 logloss:0.254503\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.910326 logloss:0.253756\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.904891 logloss:0.254931\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.904891 logloss:0.254076\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:227) done accuracy:0.902174 logloss:0.255488\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:241) done accuracy:0.907609 logloss:0.256041\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:249) done accuracy:0.904891 logloss:0.256523\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:261) done accuracy:0.904891 logloss:0.257875\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.907609 logloss:0.256233\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:281) done accuracy:0.910326 logloss:0.256599\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.907609 logloss:0.256119\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.910326 logloss:0.256734\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.910326 logloss:0.256734\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpnq9q_06h\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12972 node(s), and 92 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9891\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9239\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 56%|█████▋    | 18/32 [01:01<00:46,  3.33s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0904122 min:7.20293e-05 max:1 sd:0.173327\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.104158 min:7.14336e-05 max:1 sd:0.182939\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0766393 min:2.30324e-07 max:1 sd:0.165585\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.167542 min:0 max:1 sd:0.17955\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.00608638 min:0 max:0.0453877 sd:0.00756266\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.155175 min:0 max:1 sd:0.172269\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.07805 min:0 max:1 sd:0.189303\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0900558 min:0 max:1 sd:0.207343\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:344 (93.4783%) mean:0.124807 min:0 max:1 sd:0.223434\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.194688 min:0 max:1 sd:0.160323\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.0820678 min:0.00115672 max:1 sd:0.21609\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:327 (88.8587%) mean:0.12076 min:0.00400707 max:0.696288 sd:0.16115\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0605464 min:0.00112057 max:1 sd:0.158878\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0952569 min:0 max:1 sd:0.197343\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0965455 min:0 max:0.917609 sd:0.192492\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0934078 min:0 max:1 sd:0.192004\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.104658 min:0 max:1 sd:0.159131\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.527828 min:0 max:1 sd:0.176042\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.487674 min:0 max:0.989319 sd:0.184375\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:61 (16.5761%) mean:0.472794 min:0 max:1 sd:0.186216\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.499369 min:0 max:0.973154 sd:0.177263\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.512443 min:0 max:0.989925 sd:0.182409\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:8 (2.17391%) mean:0.496826 min:0 max:1 sd:0.187045\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:21 (5.70652%) mean:0.441984 min:0 max:0.953386 sd:0.179503\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.438136 min:0 max:0.987476 sd:0.196962\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:96 (26.087%) mean:0.401355 min:0 max:0.813887 sd:0.190145\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:12 (3.26087%) mean:0.583487 min:0 max:1 sd:0.164651\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.528622 min:0.0378418 max:0.990984 sd:0.175839\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:74 (20.1087%) mean:0.512249 min:0 max:1 sd:0.186941\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:111 (30.163%) mean:0.490707 min:0 max:0.955238 sd:0.192929\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:127 (34.5109%) mean:0.515964 min:0 max:0.99344 sd:0.191736\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.414792 min:0 max:0.850997 sd:0.194903\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.418814 min:0.0091239 max:0.947005 sd:0.19788\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:119 (32.337%) mean:0.422769 min:0 max:0.988705 sd:0.210332\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:299 (81.25%) mean:0.363077 min:0 max:0.753454 sd:0.172171\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:324 (88.0435%) mean:0.18543 min:0 max:1 sd:0.255843\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.182196 min:0 max:1 sd:0.259779\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.172391 min:0.00113829 max:1 sd:0.240529\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:324 (88.0435%) mean:0.184768 min:0 max:0.988614 sd:0.249801\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.18899 min:0 max:0.992443 sd:0.252881\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.175158 min:0 max:1 sd:0.240446\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:324 (88.0435%) mean:0.180531 min:0.00172566 max:0.94107 sd:0.233514\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.182716 min:0 max:0.930383 sd:0.237719\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.169809 min:0.00273806 max:0.955403 sd:0.21239\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.624623 min:0 max:1 sd:0.307805\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.702596 min:0.0642085 max:1 sd:0.266793\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.484551 min:0 max:1 sd:0.272945\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.556858 min:0 max:1 sd:0.356868\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.652343 min:0.0327086 max:1 sd:0.309972\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.428619 min:0 max:1 sd:0.324046\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:27 (7.33696%) mean:0.425924 min:0 max:1 sd:0.317402\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:27 (7.33696%) mean:0.586049 min:0.0466496 max:1 sd:0.251182\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:27 (7.33696%) mean:0.346272 min:0 max:1 sd:0.278383\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:110 (29.8913%) mean:0.503183 min:0 max:1 sd:0.232333\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:110 (29.8913%) mean:0.509394 min:0 max:1 sd:0.244551\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.524382 min:0 max:0.957751 sd:0.165856\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.478808 min:0 max:0.951877 sd:0.176814\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:57 (15.4891%) mean:0.462174 min:0 max:1 sd:0.184818\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.520758 min:0 max:0.952412 sd:0.195799\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.464096 min:0 max:0.947944 sd:0.179269\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.463127 min:0 max:1 sd:0.193484\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.470635 min:0.00394213 max:1 sd:0.196215\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.434807 min:0 max:0.973811 sd:0.197484\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:69 (18.75%) mean:0.440352 min:0 max:1 sd:0.250276\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.577997 min:0 max:0.965585 sd:0.162738\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.535935 min:0.0524558 max:0.961149 sd:0.168175\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:71 (19.2935%) mean:0.491578 min:0 max:1 sd:0.188086\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:111 (30.163%) mean:0.524762 min:0 max:1 sd:0.205449\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:126 (34.2391%) mean:0.535097 min:0 max:0.983341 sd:0.18543\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:273 (74.1848%) mean:0.453608 min:0 max:0.955908 sd:0.205833\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:102 (27.7174%) mean:0.453424 min:0 max:1 sd:0.217147\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:117 (31.7935%) mean:0.456188 min:0 max:0.975678 sd:0.197257\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:261 (70.9239%) mean:0.355748 min:0.00939159 max:1 sd:0.241797\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0271455 min:0 max:1 sd:0.149219\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0427337 min:0 max:1 sd:0.150584\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0272049 min:1.40628e-05 max:1 sd:0.149123\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:324 (88.0435%) mean:0.386723 min:0.0312225 max:0.785254 sd:0.199338\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.37384 min:0 max:0.785308 sd:0.205602\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.505691 min:0.223379 max:0.827135 sd:0.163423\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0978242 min:0 max:1 sd:0.189436\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.113381 min:0 max:1 sd:0.213253\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0874787 min:0 max:1 sd:0.176048\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.139007 min:0 max:1 sd:0.143569\n",
      "\t83: \"var_index\" NUMERICAL num-nas:110 (29.8913%) mean:0.0788886 min:0 max:1 sd:0.13162\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:30 (8.15217%) mean:0.767727 min:0 max:1 sd:0.266169\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:30 (8.15217%) mean:0.816455 min:0 max:1 sd:0.231905\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:30 (8.15217%) mean:0.0263398 min:0 max:1 sd:0.0955067\n",
      "\t87: \"var_max\" NUMERICAL num-nas:110 (29.8913%) mean:0.0113669 min:0 max:1 sd:0.0655484\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:110 (29.8913%) mean:0.0440329 min:0 max:0.623456 sd:0.0991304\n",
      "\t89: \"var_min\" NUMERICAL num-nas:110 (29.8913%) mean:0.0355243 min:0 max:0.54179 sd:0.0859483\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:110 (29.8913%) mean:0.431376 min:0.0066253 max:1 sd:0.167697\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:110 (29.8913%) mean:0.00819958 min:0 max:1 sd:0.0649349\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:1) done accuracy:0.838462 logloss:5.82244\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.855191 logloss:1.68381\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:22) done accuracy:0.86413 logloss:0.468434\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:29) done accuracy:0.888587 logloss:0.352875\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.899457 logloss:0.259205\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:51) done accuracy:0.88587 logloss:0.259313\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:59) done accuracy:0.883152 logloss:0.259934\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:67) done accuracy:0.894022 logloss:0.257102\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:81) done accuracy:0.891304 logloss:0.259458\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.902174 logloss:0.251773\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:101) done accuracy:0.904891 logloss:0.251503\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.894022 logloss:0.254905\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:119) done accuracy:0.899457 logloss:0.254204\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.896739 logloss:0.256537\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:135) done accuracy:0.894022 logloss:0.257198\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.894022 logloss:0.256322\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:161) done accuracy:0.888587 logloss:0.257456\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.894022 logloss:0.257825\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:175) done accuracy:0.896739 logloss:0.257656\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.896739 logloss:0.255129\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:199) done accuracy:0.899457 logloss:0.256849\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.904891 logloss:0.254057\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:215) done accuracy:0.904891 logloss:0.254115\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:228) done accuracy:0.902174 logloss:0.254429\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:242) done accuracy:0.902174 logloss:0.254985\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:251) done accuracy:0.904891 logloss:0.254248\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:261) done accuracy:0.899457 logloss:0.254926\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.896739 logloss:0.255554\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:267) done accuracy:0.896739 logloss:0.254433\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:290) done accuracy:0.899457 logloss:0.2542\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.899457 logloss:0.253619\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.899457 logloss:0.253619\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpionwhq0m\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13140 node(s), and 91 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9348\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 59%|█████▉    | 19/32 [01:04<00:41,  3.18s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.120582 min:7.20293e-05 max:1 sd:0.193928\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.138164 min:7.14336e-05 max:1 sd:0.211573\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.102562 min:2.30324e-07 max:1 sd:0.181395\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.162527 min:0 max:1 sd:0.179682\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.00589183 min:0 max:0.0453877 sd:0.00763527\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.151611 min:0 max:1 sd:0.172575\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0770298 min:0 max:1 sd:0.19389\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0891883 min:0 max:1 sd:0.212405\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:346 (94.0217%) mean:0.127983 min:0 max:1 sd:0.233266\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.186656 min:0 max:1 sd:0.156045\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.0622966 min:0 max:1 sd:0.168663\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.126783 min:0 max:1 sd:0.195667\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0543685 min:0 max:1 sd:0.154056\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0943236 min:0 max:1 sd:0.201711\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0958891 min:0 max:0.917609 sd:0.196879\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.0901772 min:0.000690433 max:1 sd:0.194566\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.109642 min:0 max:1 sd:0.161927\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.516131 min:0.0152442 max:1 sd:0.183023\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.480333 min:0 max:1 sd:0.188691\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:69 (18.75%) mean:0.461399 min:0 max:1 sd:0.192047\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.490863 min:0.0995208 max:0.973154 sd:0.181338\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.502326 min:0.0305007 max:1 sd:0.187439\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:11 (2.98913%) mean:0.48566 min:0.0266211 max:1 sd:0.189396\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.439161 min:0.0639947 max:1 sd:0.176245\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.436242 min:0.0587585 max:1 sd:0.201542\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:94 (25.5435%) mean:0.402256 min:0 max:0.836502 sd:0.190504\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:12 (3.26087%) mean:0.569747 min:0.0286664 max:1 sd:0.176051\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:40 (10.8696%) mean:0.518205 min:0 max:1 sd:0.185847\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:84 (22.8261%) mean:0.502524 min:0 max:1 sd:0.192061\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:110 (29.8913%) mean:0.478946 min:0 max:1 sd:0.196204\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:131 (35.5978%) mean:0.517726 min:0 max:1 sd:0.197468\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:305 (82.8804%) mean:0.426542 min:0 max:0.933891 sd:0.199894\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:98 (26.6304%) mean:0.407144 min:0 max:1 sd:0.200085\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:121 (32.8804%) mean:0.420085 min:0 max:1 sd:0.220013\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:296 (80.4348%) mean:0.367703 min:0 max:0.84848 sd:0.182142\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:326 (88.587%) mean:0.205452 min:0 max:1 sd:0.254623\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.201169 min:0 max:1 sd:0.260138\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.192076 min:0.00113829 max:0.96449 sd:0.236931\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:326 (88.587%) mean:0.206112 min:0 max:1 sd:0.253424\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.21064 min:0 max:1 sd:0.257607\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.196206 min:0 max:0.99507 sd:0.242812\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:326 (88.587%) mean:0.202183 min:0.00172566 max:1 sd:0.240752\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.204664 min:0 max:1 sd:0.246132\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.190933 min:0.00273806 max:1 sd:0.219045\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.60983 min:0 max:1 sd:0.317618\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.692648 min:0 max:1 sd:0.271344\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.469624 min:0 max:1 sd:0.276821\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.541373 min:0 max:1 sd:0.357179\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.641779 min:0 max:1 sd:0.313264\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.407373 min:0 max:1 sd:0.323814\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:28 (7.6087%) mean:0.428375 min:0 max:1 sd:0.321614\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:28 (7.6087%) mean:0.584933 min:0 max:1 sd:0.256774\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:28 (7.6087%) mean:0.345622 min:0 max:0.985907 sd:0.278801\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.512487 min:0.0105506 max:1 sd:0.231011\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.517776 min:0 max:1 sd:0.243344\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.515666 min:0.0816971 max:1 sd:0.171583\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:26 (7.06522%) mean:0.468053 min:0 max:1 sd:0.18277\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.451067 min:0 max:0.988268 sd:0.189137\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.517261 min:0.0435796 max:1 sd:0.196657\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.455906 min:0.0163507 max:1 sd:0.181615\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.45093 min:0.00266063 max:0.989602 sd:0.194645\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.461925 min:0 max:1 sd:0.192568\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.431499 min:0.05674 max:1 sd:0.20112\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:63 (17.1196%) mean:0.435507 min:0 max:1 sd:0.249557\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.566861 min:0.024159 max:1 sd:0.172615\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.523826 min:0 max:1 sd:0.180441\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:79 (21.4674%) mean:0.479233 min:0 max:0.988906 sd:0.194766\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.510975 min:0 max:1 sd:0.205544\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.53617 min:0.00422152 max:1 sd:0.188313\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:272 (73.913%) mean:0.44528 min:0 max:1 sd:0.222468\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:104 (28.2609%) mean:0.4403 min:0 max:1 sd:0.214289\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:120 (32.6087%) mean:0.454039 min:0.00566975 max:1 sd:0.204613\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:258 (70.1087%) mean:0.345252 min:0 max:1 sd:0.256495\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.0285402 min:0 max:1 sd:0.152591\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0453162 min:0 max:1 sd:0.153718\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0286397 min:1.40628e-05 max:1 sd:0.152482\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:326 (88.587%) mean:0.405237 min:0.0312225 max:1 sd:0.21431\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.390485 min:0 max:1 sd:0.219607\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.522259 min:0.223379 max:1 sd:0.176322\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0975274 min:0 max:1 sd:0.193475\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.1131 min:0 max:1 sd:0.217969\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0872475 min:0 max:1 sd:0.179735\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.152736 min:0.0100233 max:1 sd:0.145885\n",
      "\t83: \"var_index\" NUMERICAL num-nas:116 (31.5217%) mean:0.0820897 min:0 max:1 sd:0.139658\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:33 (8.96739%) mean:0.760989 min:0 max:1 sd:0.268681\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:33 (8.96739%) mean:0.813562 min:0 max:1 sd:0.23345\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:33 (8.96739%) mean:0.0256735 min:0 max:1 sd:0.0940098\n",
      "\t87: \"var_max\" NUMERICAL num-nas:116 (31.5217%) mean:0.0119131 min:0 max:1 sd:0.066507\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:116 (31.5217%) mean:0.0478045 min:0 max:1 sd:0.116497\n",
      "\t89: \"var_min\" NUMERICAL num-nas:116 (31.5217%) mean:0.0397833 min:0 max:1 sd:0.108364\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.434098 min:0.0066253 max:1 sd:0.171456\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:116 (31.5217%) mean:0.00816813 min:0 max:1 sd:0.0654361\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:0) done accuracy:0.80292 logloss:7.10349\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.868852 logloss:1.38707\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.891304 logloss:0.347759\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:34) done accuracy:0.88587 logloss:0.343476\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.894022 logloss:0.349559\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:48) done accuracy:0.896739 logloss:0.344191\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:58) done accuracy:0.896739 logloss:0.345336\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.899457 logloss:0.25615\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.891304 logloss:0.256808\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.896739 logloss:0.25878\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.899457 logloss:0.256113\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.896739 logloss:0.256402\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.902174 logloss:0.25425\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.907609 logloss:0.254665\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.904891 logloss:0.25446\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.899457 logloss:0.254864\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.904891 logloss:0.253526\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.902174 logloss:0.251352\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:179) done accuracy:0.910326 logloss:0.252965\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:191) done accuracy:0.904891 logloss:0.252883\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:203) done accuracy:0.902174 logloss:0.249465\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.904891 logloss:0.249538\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:218) done accuracy:0.910326 logloss:0.249712\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:228) done accuracy:0.910326 logloss:0.250128\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:238) done accuracy:0.915761 logloss:0.251361\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.910326 logloss:0.250544\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:258) done accuracy:0.907609 logloss:0.250829\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:269) done accuracy:0.907609 logloss:0.250009\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.904891 logloss:0.249178\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.907609 logloss:0.247481\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:296) done accuracy:0.907609 logloss:0.247695\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.907609 logloss:0.247695\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpz35j4__7\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12614 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.8804\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 62%|██████▎   | 20/32 [01:08<00:41,  3.44s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:320 (86.9565%) mean:0.104539 min:0 max:1 sd:0.180533\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.12 min:0 max:1 sd:0.193299\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0892127 min:0 max:1 sd:0.170628\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:320 (86.9565%) mean:0.169259 min:0 max:1 sd:0.195555\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0261969 min:0 max:1 sd:0.142208\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.149855 min:0 max:1 sd:0.161616\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0617676 min:0 max:1 sd:0.170853\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0808234 min:0 max:1 sd:0.217138\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.090121 min:0 max:1 sd:0.200951\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.199748 min:0 max:1 sd:0.152918\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:320 (86.9565%) mean:0.0880984 min:0.000481551 max:1 sd:0.237118\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.128166 min:0.00182679 max:1 sd:0.190371\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.054735 min:0.000412191 max:1 sd:0.150272\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.082303 min:0 max:1 sd:0.188562\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0893159 min:0 max:1 sd:0.207251\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0783237 min:0 max:1 sd:0.177206\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.105935 min:0 max:1 sd:0.15265\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.524929 min:0 max:1 sd:0.184975\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:31 (8.42391%) mean:0.48661 min:0 max:1 sd:0.189559\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:67 (18.2065%) mean:0.470034 min:0.0451185 max:1 sd:0.190855\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.498023 min:0 max:1 sd:0.184422\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.507 min:0 max:1 sd:0.188553\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:12 (3.26087%) mean:0.493734 min:0 max:1 sd:0.188562\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:24 (6.52174%) mean:0.443882 min:0 max:1 sd:0.183523\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:28 (7.6087%) mean:0.437993 min:0 max:1 sd:0.204293\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.407936 min:0 max:1 sd:0.188995\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.578963 min:0 max:1 sd:0.176095\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.52815 min:0 max:1 sd:0.182178\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.510059 min:0 max:1 sd:0.191638\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.491348 min:0 max:1 sd:0.196399\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:138 (37.5%) mean:0.526595 min:0.0265645 max:1 sd:0.199266\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:299 (81.25%) mean:0.433122 min:0 max:1 sd:0.207454\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:97 (26.3587%) mean:0.418359 min:0 max:1 sd:0.202436\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:130 (35.3261%) mean:0.431701 min:0.00700149 max:1 sd:0.219231\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:291 (79.0761%) mean:0.370918 min:0 max:1 sd:0.197176\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:320 (86.9565%) mean:0.192834 min:0 max:1 sd:0.25602\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.187558 min:0 max:1 sd:0.25619\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.183749 min:0 max:1 sd:0.248795\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:320 (86.9565%) mean:0.195359 min:0 max:1 sd:0.256028\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.198186 min:0 max:1 sd:0.256728\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.187232 min:0 max:1 sd:0.249635\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:320 (86.9565%) mean:0.193008 min:0 max:1 sd:0.247588\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.194368 min:0 max:1 sd:0.249161\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.186225 min:0 max:1 sd:0.235518\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:19 (5.16304%) mean:0.61051 min:0 max:1 sd:0.316908\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.688734 min:0.0483153 max:1 sd:0.273791\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.475351 min:0 max:1 sd:0.278232\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.559147 min:0 max:1 sd:0.359333\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.654244 min:0.0102696 max:1 sd:0.310564\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.421855 min:0 max:1 sd:0.323206\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:30 (8.15217%) mean:0.437563 min:0 max:1 sd:0.324695\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:30 (8.15217%) mean:0.595356 min:0.0466496 max:1 sd:0.252754\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:30 (8.15217%) mean:0.356741 min:0 max:1 sd:0.283163\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:111 (30.163%) mean:0.509308 min:0.0105506 max:1 sd:0.232014\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:111 (30.163%) mean:0.521632 min:0 max:1 sd:0.238518\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.524332 min:0 max:1 sd:0.172389\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.476857 min:0.0902793 max:1 sd:0.184245\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:58 (15.7609%) mean:0.460655 min:0 max:1 sd:0.188975\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.522588 min:0 max:1 sd:0.197889\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.462988 min:0 max:1 sd:0.185288\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.460325 min:0 max:1 sd:0.196192\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.469074 min:0 max:1 sd:0.200848\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.433477 min:0 max:1 sd:0.204893\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:63 (17.1196%) mean:0.439193 min:0.0327717 max:1 sd:0.244493\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.577032 min:0 max:1 sd:0.169742\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:35 (9.51087%) mean:0.530632 min:0 max:1 sd:0.182423\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:73 (19.837%) mean:0.492206 min:0.0401454 max:1 sd:0.191345\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:111 (30.163%) mean:0.526268 min:0 max:1 sd:0.204282\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:137 (37.2283%) mean:0.547945 min:0 max:1 sd:0.188893\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:266 (72.2826%) mean:0.451772 min:0 max:0.971545 sd:0.213839\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:103 (27.9891%) mean:0.456426 min:0.000368284 max:1 sd:0.216288\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.465135 min:0 max:1 sd:0.205619\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:254 (69.0217%) mean:0.349248 min:0 max:1 sd:0.250161\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:320 (86.9565%) mean:0.0253094 min:0 max:1 sd:0.143007\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0399536 min:0 max:1 sd:0.144177\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0255319 min:0 max:1 sd:0.142896\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:320 (86.9565%) mean:0.383896 min:0 max:0.891234 sd:0.207721\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.372379 min:0 max:0.896264 sd:0.206522\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.503088 min:0 max:0.911156 sd:0.179437\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0814137 min:0 max:1 sd:0.169324\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.103445 min:0 max:1 sd:0.218619\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0676578 min:0 max:1 sd:0.155245\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.142677 min:0 max:1 sd:0.13883\n",
      "\t83: \"var_index\" NUMERICAL num-nas:111 (30.163%) mean:0.0777082 min:0 max:1 sd:0.135466\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:29 (7.88043%) mean:0.76486 min:0 max:1 sd:0.263476\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:29 (7.88043%) mean:0.816366 min:0 max:1 sd:0.22838\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:29 (7.88043%) mean:0.0236227 min:0 max:1 sd:0.0899245\n",
      "\t87: \"var_max\" NUMERICAL num-nas:111 (30.163%) mean:0.0120747 min:1.72134e-05 max:1 sd:0.0660106\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:111 (30.163%) mean:0.0490954 min:7.9609e-05 max:1 sd:0.117502\n",
      "\t89: \"var_min\" NUMERICAL num-nas:111 (30.163%) mean:0.0404741 min:2.4978e-05 max:1 sd:0.107315\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:111 (30.163%) mean:0.425565 min:0 max:1 sd:0.165577\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:111 (30.163%) mean:0.0083639 min:9.36969e-06 max:1 sd:0.0651181\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.911765 logloss:3.18032\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.871935 logloss:1.10551\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.888587 logloss:0.45073\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.907609 logloss:0.441996\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.913043 logloss:0.343915\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.915761 logloss:0.252182\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:57) done accuracy:0.910326 logloss:0.25334\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:69) done accuracy:0.907609 logloss:0.25184\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.923913 logloss:0.248785\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:92) done accuracy:0.913043 logloss:0.248991\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.92663 logloss:0.243777\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:109) done accuracy:0.929348 logloss:0.242611\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.92663 logloss:0.239496\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:131) done accuracy:0.923913 logloss:0.240984\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:143) done accuracy:0.92663 logloss:0.241709\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.932065 logloss:0.240724\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:159) done accuracy:0.932065 logloss:0.240758\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.92663 logloss:0.240577\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:177) done accuracy:0.92663 logloss:0.241641\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.934783 logloss:0.242354\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.929348 logloss:0.241322\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.92663 logloss:0.241493\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:221) done accuracy:0.929348 logloss:0.242479\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:231) done accuracy:0.92663 logloss:0.244694\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.929348 logloss:0.245301\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:234) done accuracy:0.932065 logloss:0.245901\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.934783 logloss:0.244434\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.932065 logloss:0.244989\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:281) done accuracy:0.92663 logloss:0.245237\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.929348 logloss:0.244769\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.932065 logloss:0.243672\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.932065 logloss:0.243672\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpynb07yke\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12964 node(s), and 92 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8696\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 66%|██████▌   | 21/32 [01:12<00:38,  3.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:318 (86.413%) mean:0.0989615 min:0 max:1 sd:0.177794\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.118972 min:0 max:1 sd:0.199269\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.0809309 min:0 max:1 sd:0.163593\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:318 (86.413%) mean:0.176231 min:0 max:1 sd:0.205742\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0256598 min:0 max:1 sd:0.13938\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.155488 min:0 max:1 sd:0.172114\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:318 (86.413%) mean:0.068291 min:0 max:1 sd:0.17721\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0879178 min:0 max:1 sd:0.22203\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:339 (92.1196%) mean:0.0944592 min:0 max:1 sd:0.201545\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:318 (86.413%) mean:0.186219 min:0 max:1 sd:0.150816\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:318 (86.413%) mean:0.0949084 min:0 max:1 sd:0.241359\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.124487 min:0 max:1 sd:0.189429\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.0567161 min:0 max:1 sd:0.149895\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:318 (86.413%) mean:0.0910052 min:0 max:1 sd:0.198897\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.0970182 min:0 max:1 sd:0.213847\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0870119 min:0 max:1 sd:0.187866\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:318 (86.413%) mean:0.102807 min:0 max:1 sd:0.150572\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.520103 min:0.0152442 max:1 sd:0.181501\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.480761 min:0 max:0.989319 sd:0.188218\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:70 (19.0217%) mean:0.468101 min:0 max:1 sd:0.185771\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.493548 min:0.0995208 max:1 sd:0.181117\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.504797 min:0.0305007 max:0.989925 sd:0.18395\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.490268 min:0.0266211 max:1 sd:0.18458\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:23 (6.25%) mean:0.441013 min:0.0181182 max:0.931378 sd:0.178322\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:29 (7.88043%) mean:0.436117 min:0 max:0.987476 sd:0.200634\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:90 (24.4565%) mean:0.391704 min:0 max:1 sd:0.19416\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.573197 min:0.0549214 max:1 sd:0.173871\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:42 (11.413%) mean:0.519928 min:0 max:0.990984 sd:0.184805\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.50725 min:0 max:1 sd:0.188292\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.491263 min:0 max:0.939857 sd:0.192559\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.52082 min:0 max:0.99344 sd:0.196747\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.432257 min:0 max:1 sd:0.207444\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:103 (27.9891%) mean:0.41644 min:0 max:0.92548 sd:0.199844\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:126 (34.2391%) mean:0.422636 min:0 max:0.988705 sd:0.217118\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:301 (81.7935%) mean:0.377101 min:0 max:1 sd:0.194028\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:318 (86.413%) mean:0.169263 min:0 max:1 sd:0.232515\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.16597 min:0 max:1 sd:0.237119\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.15815 min:0 max:1 sd:0.21913\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:318 (86.413%) mean:0.170067 min:0 max:0.988614 sd:0.2284\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.173769 min:0 max:0.992443 sd:0.230201\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.161959 min:0 max:1 sd:0.222108\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:318 (86.413%) mean:0.16667 min:0 max:0.94107 sd:0.214999\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.168539 min:0 max:0.930383 sd:0.218032\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.158118 min:0 max:0.955403 sd:0.196945\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:19 (5.16304%) mean:0.621942 min:0 max:1 sd:0.313673\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.697251 min:0 max:1 sd:0.274323\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.483071 min:0 max:1 sd:0.274671\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:25 (6.79348%) mean:0.557138 min:0 max:1 sd:0.357128\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:25 (6.79348%) mean:0.652284 min:0 max:1 sd:0.312359\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:25 (6.79348%) mean:0.421763 min:0 max:1 sd:0.325689\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:31 (8.42391%) mean:0.433984 min:0 max:1 sd:0.322651\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:31 (8.42391%) mean:0.588597 min:0 max:1 sd:0.256749\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:31 (8.42391%) mean:0.358102 min:0 max:1 sd:0.284039\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.512172 min:0.0105506 max:1 sd:0.224737\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.513201 min:0 max:1 sd:0.233064\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.519517 min:0.100042 max:0.95634 sd:0.168208\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.470716 min:0 max:0.951877 sd:0.181586\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:61 (16.5761%) mean:0.45769 min:0 max:1 sd:0.184184\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.516901 min:0.0278547 max:0.948048 sd:0.193451\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.458342 min:0.0163507 max:0.947944 sd:0.180464\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.457449 min:0.00266063 max:1 sd:0.191409\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.467322 min:0.00394213 max:0.990302 sd:0.197166\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:23 (6.25%) mean:0.431211 min:0 max:0.973811 sd:0.200687\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:61 (16.5761%) mean:0.426773 min:0 max:1 sd:0.245588\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.571391 min:0.024159 max:0.965585 sd:0.169535\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:39 (10.5978%) mean:0.527223 min:0 max:0.961149 sd:0.179199\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.488125 min:0 max:1 sd:0.18859\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.525673 min:0 max:0.995568 sd:0.205429\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.540048 min:0.00422152 max:0.983341 sd:0.188935\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:266 (72.2826%) mean:0.441677 min:0 max:1 sd:0.220825\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.452327 min:0.000368284 max:0.991934 sd:0.218058\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.456706 min:0.00566975 max:0.975678 sd:0.202695\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:255 (69.2935%) mean:0.342899 min:0.0115886 max:1 sd:0.245657\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:318 (86.413%) mean:0.0220702 min:0 max:1 sd:0.139739\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0178382 min:0 max:0.10961 sd:0.0251112\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.0223464 min:0 max:1 sd:0.139717\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:318 (86.413%) mean:0.392181 min:0 max:1 sd:0.224861\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.382886 min:0 max:1 sd:0.223652\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:318 (86.413%) mean:0.508174 min:0 max:1 sd:0.192616\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:318 (86.413%) mean:0.0867833 min:0 max:1 sd:0.173053\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:318 (86.413%) mean:0.109893 min:0 max:1 sd:0.222327\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0722004 min:0 max:1 sd:0.157667\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:318 (86.413%) mean:0.139077 min:0 max:1 sd:0.139145\n",
      "\t83: \"var_index\" NUMERICAL num-nas:119 (32.337%) mean:0.0839299 min:0 max:1 sd:0.149636\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.746168 min:0 max:1 sd:0.27584\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.800857 min:0 max:1 sd:0.23992\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.0203048 min:0 max:0.389902 sd:0.0719435\n",
      "\t87: \"var_max\" NUMERICAL num-nas:119 (32.337%) mean:0.0110231 min:1.72134e-05 max:1 sd:0.06563\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:119 (32.337%) mean:0.0441242 min:7.9609e-05 max:0.535582 sd:0.0965582\n",
      "\t89: \"var_min\" NUMERICAL num-nas:119 (32.337%) mean:0.0350836 min:2.4978e-05 max:0.533537 sd:0.0842512\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.428284 min:0 max:1 sd:0.175099\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:119 (32.337%) mean:0.00803647 min:9.36969e-06 max:1 sd:0.0654704\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.860294 logloss:5.03551\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.86921 logloss:1.3755\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.877717 logloss:0.445765\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.907609 logloss:0.352258\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.907609 logloss:0.356972\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.907609 logloss:0.256548\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.907609 logloss:0.249185\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.910326 logloss:0.252697\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:77) done accuracy:0.907609 logloss:0.251708\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.907609 logloss:0.250097\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.915761 logloss:0.250037\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.915761 logloss:0.251201\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:99) done accuracy:0.92663 logloss:0.247524\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:132) done accuracy:0.923913 logloss:0.248445\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:142) done accuracy:0.915761 logloss:0.248629\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.918478 logloss:0.244571\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:159) done accuracy:0.923913 logloss:0.246493\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.929348 logloss:0.24683\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.923913 logloss:0.247256\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.921196 logloss:0.247962\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:200) done accuracy:0.923913 logloss:0.249119\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:208) done accuracy:0.92663 logloss:0.250592\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.923913 logloss:0.250333\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:231) done accuracy:0.921196 logloss:0.249312\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.923913 logloss:0.248426\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.918478 logloss:0.247214\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.915761 logloss:0.247511\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:269) done accuracy:0.918478 logloss:0.245863\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:279) done accuracy:0.923913 logloss:0.246047\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.923913 logloss:0.245577\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.921196 logloss:0.24587\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.921196 logloss:0.24587\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpb2qxhqaz\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12940 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9130\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 69%|██████▉   | 22/32 [01:15<00:34,  3.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.0749618 min:0 max:0.395994 sd:0.117204\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0906347 min:0 max:0.603673 sd:0.143474\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0611231 min:0 max:0.388463 sd:0.100864\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.19487 min:0.00335387 max:1 sd:0.217282\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0301156 min:0.000195345 max:1 sd:0.151667\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.169119 min:0.000481116 max:1 sd:0.180535\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0674649 min:0 max:0.496254 sd:0.141833\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0932493 min:0 max:0.978189 sd:0.209085\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:343 (93.2065%) mean:0.082918 min:0 max:0.427298 sd:0.128693\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.1872 min:0.0344311 max:1 sd:0.159918\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:326 (88.587%) mean:0.108589 min:0 max:1 sd:0.260822\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:330 (89.6739%) mean:0.1444 min:0 max:1 sd:0.217637\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0623723 min:0 max:1 sd:0.1624\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0936804 min:5.72011e-11 max:0.726902 sd:0.173869\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.102404 min:0 max:1 sd:0.204282\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.0851651 min:0.000690433 max:0.58012 sd:0.150191\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.0885961 min:0.0140926 max:0.570059 sd:0.0837804\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.516503 min:0 max:0.988978 sd:0.182098\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:31 (8.42391%) mean:0.478989 min:0 max:1 sd:0.183674\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:72 (19.5652%) mean:0.463728 min:0 max:0.980907 sd:0.187309\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.492547 min:0 max:1 sd:0.179152\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.500559 min:0 max:1 sd:0.183465\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:9 (2.44565%) mean:0.4846 min:0 max:0.980704 sd:0.186811\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.436268 min:0 max:1 sd:0.176478\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.430712 min:0 max:1 sd:0.194817\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:91 (24.7283%) mean:0.400344 min:0.0521682 max:1 sd:0.194468\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.570502 min:0 max:0.990661 sd:0.173608\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.517506 min:0.0378418 max:1 sd:0.18011\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:85 (23.0978%) mean:0.507756 min:0 max:0.985639 sd:0.185459\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:112 (30.4348%) mean:0.482552 min:0 max:1 sd:0.187393\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.505061 min:0 max:1 sd:0.194763\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:311 (84.5109%) mean:0.445046 min:0.0665289 max:1 sd:0.197052\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.409645 min:0.0091239 max:1 sd:0.19346\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:119 (32.337%) mean:0.409761 min:0 max:1 sd:0.211806\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:303 (82.337%) mean:0.38982 min:0 max:1 sd:0.198162\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:326 (88.587%) mean:0.183875 min:0 max:0.949443 sd:0.258528\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.180881 min:0 max:1 sd:0.262095\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.172199 min:0 max:1 sd:0.247601\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:326 (88.587%) mean:0.186637 min:0 max:1 sd:0.261912\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.190522 min:0 max:1 sd:0.263823\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.179021 min:0 max:1 sd:0.257638\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:326 (88.587%) mean:0.181256 min:0 max:1 sd:0.251406\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.183112 min:0 max:1 sd:0.253359\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.175121 min:0 max:1 sd:0.243654\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.622298 min:0 max:1 sd:0.31336\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.703243 min:0 max:1 sd:0.265849\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.477754 min:0 max:0.993699 sd:0.274495\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:19 (5.16304%) mean:0.552823 min:0 max:1 sd:0.360184\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.65456 min:0 max:1 sd:0.310299\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.421381 min:0 max:0.99189 sd:0.323591\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:26 (7.06522%) mean:0.417242 min:0 max:1 sd:0.319208\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:26 (7.06522%) mean:0.587427 min:0 max:1 sd:0.248892\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:26 (7.06522%) mean:0.340172 min:0 max:1 sd:0.282361\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.508211 min:0.0105506 max:1 sd:0.225652\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.510311 min:0.00905979 max:1 sd:0.23709\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:3 (0.815217%) mean:0.514305 min:0 max:1 sd:0.167445\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:26 (7.06522%) mean:0.467234 min:0 max:1 sd:0.177734\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.453179 min:0 max:1 sd:0.185855\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.516936 min:0 max:1 sd:0.194757\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.454784 min:0 max:1 sd:0.17854\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:2 (0.543478%) mean:0.452247 min:0 max:1 sd:0.193666\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.460652 min:0 max:1 sd:0.192448\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:18 (4.8913%) mean:0.427576 min:0 max:1 sd:0.19505\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:63 (17.1196%) mean:0.434643 min:0 max:0.963645 sd:0.251216\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:7 (1.90217%) mean:0.563974 min:0 max:1 sd:0.170031\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.522629 min:0 max:1 sd:0.175545\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.482394 min:0 max:1 sd:0.189852\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.515928 min:0 max:1 sd:0.196932\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:127 (34.5109%) mean:0.525554 min:0 max:1 sd:0.187381\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:271 (73.6413%) mean:0.431733 min:0 max:1 sd:0.208422\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:107 (29.0761%) mean:0.443463 min:0 max:1 sd:0.209379\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:119 (32.337%) mean:0.445443 min:0 max:1 sd:0.198555\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:259 (70.3804%) mean:0.338668 min:0 max:0.949324 sd:0.24977\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:326 (88.587%) mean:0.00465915 min:0 max:0.107496 sd:0.0164126\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0438981 min:0 max:1 sd:0.152389\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.00476216 min:0 max:0.100884 sd:0.0155957\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:326 (88.587%) mean:0.385238 min:0 max:1 sd:0.232138\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.381577 min:0 max:1 sd:0.230698\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.498205 min:0 max:1 sd:0.200359\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:326 (88.587%) mean:0.0888627 min:0 max:0.531611 sd:0.140704\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.119001 min:0 max:0.974137 sd:0.213693\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0694089 min:0.000337785 max:0.426528 sd:0.106684\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:326 (88.587%) mean:0.144245 min:0 max:1 sd:0.146188\n",
      "\t83: \"var_index\" NUMERICAL num-nas:117 (31.7935%) mean:0.0796524 min:0 max:1 sd:0.138671\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:36 (9.78261%) mean:0.74781 min:0 max:1 sd:0.278141\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:36 (9.78261%) mean:0.803209 min:0 max:1 sd:0.241319\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:36 (9.78261%) mean:0.0243124 min:0 max:1 sd:0.0909161\n",
      "\t87: \"var_max\" NUMERICAL num-nas:117 (31.7935%) mean:0.0115738 min:0 max:1 sd:0.0666799\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:117 (31.7935%) mean:0.0438818 min:0 max:1 sd:0.111824\n",
      "\t89: \"var_min\" NUMERICAL num-nas:117 (31.7935%) mean:0.0350077 min:0 max:1 sd:0.10047\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:117 (31.7935%) mean:0.42709 min:0 max:1 sd:0.172003\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:117 (31.7935%) mean:0.00841876 min:0 max:1 sd:0.0658381\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.889706 logloss:3.9754\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.839237 logloss:1.32342\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.866848 logloss:0.294393\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:34) done accuracy:0.872283 logloss:0.280948\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.880435 logloss:0.282307\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:51) done accuracy:0.880435 logloss:0.27339\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:58) done accuracy:0.877717 logloss:0.271819\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:72) done accuracy:0.877717 logloss:0.269781\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.877717 logloss:0.270732\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.88587 logloss:0.270488\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:98) done accuracy:0.883152 logloss:0.267519\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:114) done accuracy:0.888587 logloss:0.266277\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:122) done accuracy:0.888587 logloss:0.263063\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:132) done accuracy:0.888587 logloss:0.264697\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:142) done accuracy:0.88587 logloss:0.265622\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:152) done accuracy:0.88587 logloss:0.263024\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.888587 logloss:0.263512\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.888587 logloss:0.263716\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.883152 logloss:0.267278\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:188) done accuracy:0.880435 logloss:0.266609\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:193) done accuracy:0.88587 logloss:0.266532\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.88587 logloss:0.264846\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:220) done accuracy:0.888587 logloss:0.264802\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:230) done accuracy:0.894022 logloss:0.265333\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:238) done accuracy:0.896739 logloss:0.265219\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.894022 logloss:0.264868\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:258) done accuracy:0.894022 logloss:0.265904\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.894022 logloss:0.265224\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.896739 logloss:0.265705\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.896739 logloss:0.264624\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.891304 logloss:0.265038\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.891304 logloss:0.265038\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpo4gmruao\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13460 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9946\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9022\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 72%|███████▏  | 23/32 [01:18<00:30,  3.40s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:320 (86.9565%) mean:0.115301 min:0 max:1 sd:0.184569\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.135188 min:0 max:1 sd:0.204482\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0965076 min:0 max:1 sd:0.171516\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:320 (86.9565%) mean:0.173929 min:0 max:1 sd:0.202335\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0263636 min:0 max:1 sd:0.142196\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.153595 min:0 max:1 sd:0.168203\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0739984 min:0 max:1 sd:0.186252\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0942673 min:0 max:1 sd:0.232101\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:340 (92.3913%) mean:0.103117 min:0.00246435 max:1 sd:0.209736\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.190537 min:0.0344311 max:1 sd:0.148588\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:320 (86.9565%) mean:0.0783371 min:0 max:1 sd:0.207707\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.126323 min:0 max:1 sd:0.18829\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0509826 min:0 max:1 sd:0.144503\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.0959447 min:0 max:1 sd:0.205946\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.101777 min:0 max:1 sd:0.220816\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0924033 min:0.000690433 max:1 sd:0.194539\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.106501 min:0.0140926 max:1 sd:0.152591\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.524573 min:0.0423187 max:1 sd:0.182115\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:31 (8.42391%) mean:0.484388 min:0.0158986 max:1 sd:0.188377\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:68 (18.4783%) mean:0.468745 min:0 max:1 sd:0.188362\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.497652 min:0.0995208 max:1 sd:0.181924\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.505655 min:0.0305007 max:1 sd:0.187733\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:13 (3.53261%) mean:0.492303 min:0.0266211 max:1 sd:0.187441\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:24 (6.52174%) mean:0.441135 min:0.0181182 max:1 sd:0.181354\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:26 (7.06522%) mean:0.439414 min:0 max:1 sd:0.204195\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:95 (25.8152%) mean:0.407381 min:0 max:1 sd:0.191492\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.578779 min:0.0899915 max:1 sd:0.170344\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:41 (11.1413%) mean:0.523175 min:0.0677501 max:1 sd:0.182354\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:82 (22.2826%) mean:0.511013 min:0.000319932 max:1 sd:0.185338\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:116 (31.5217%) mean:0.48857 min:0 max:1 sd:0.200545\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:138 (37.5%) mean:0.534072 min:0.0604775 max:1 sd:0.192205\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:300 (81.5217%) mean:0.433514 min:0 max:1 sd:0.209736\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.417144 min:0 max:1 sd:0.204315\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.436401 min:0.00700149 max:1 sd:0.216949\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:292 (79.3478%) mean:0.38121 min:0 max:1 sd:0.196856\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:320 (86.9565%) mean:0.210967 min:0 max:1 sd:0.266639\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.20487 min:0 max:1 sd:0.2657\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.199587 min:0 max:1 sd:0.256039\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:320 (86.9565%) mean:0.213507 min:0.000264866 max:1 sd:0.268065\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.217711 min:0.000264511 max:1 sd:0.270243\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.204134 min:0.00023666 max:1 sd:0.260644\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:320 (86.9565%) mean:0.208546 min:0 max:1 sd:0.255093\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.210875 min:0.000269833 max:1 sd:0.258218\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.19873 min:0 max:1 sd:0.238556\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:20 (5.43478%) mean:0.61337 min:0 max:1 sd:0.323353\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.690477 min:0 max:1 sd:0.278517\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.472876 min:0 max:1 sd:0.280716\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:22 (5.97826%) mean:0.544254 min:0 max:1 sd:0.36346\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:22 (5.97826%) mean:0.641544 min:0 max:1 sd:0.317296\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:22 (5.97826%) mean:0.411592 min:0 max:1 sd:0.326069\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:30 (8.15217%) mean:0.423347 min:0 max:1 sd:0.324092\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:30 (8.15217%) mean:0.58351 min:0 max:1 sd:0.256913\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:30 (8.15217%) mean:0.343602 min:0 max:1 sd:0.279435\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.512687 min:0 max:1 sd:0.230559\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.517176 min:0 max:1 sd:0.240498\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.523498 min:0.0816971 max:1 sd:0.171356\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.474527 min:0.0902793 max:1 sd:0.182403\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:65 (17.663%) mean:0.459255 min:0 max:1 sd:0.187413\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.522504 min:0.0278547 max:1 sd:0.195905\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:8 (2.17391%) mean:0.460798 min:0.0448893 max:1 sd:0.182789\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.455776 min:0.00266063 max:1 sd:0.195258\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:18 (4.8913%) mean:0.464703 min:0 max:1 sd:0.197892\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:20 (5.43478%) mean:0.434917 min:0 max:1 sd:0.203603\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:63 (17.1196%) mean:0.438583 min:0 max:1 sd:0.247241\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.575912 min:0.0743731 max:1 sd:0.167269\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.527189 min:0 max:1 sd:0.180372\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:79 (21.4674%) mean:0.490181 min:0 max:1 sd:0.189712\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:119 (32.337%) mean:0.522254 min:0 max:1 sd:0.210108\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:137 (37.2283%) mean:0.552608 min:0.102958 max:1 sd:0.184298\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:262 (71.1957%) mean:0.458233 min:0 max:1 sd:0.219583\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:112 (30.4348%) mean:0.452407 min:0 max:1 sd:0.218857\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:126 (34.2391%) mean:0.468321 min:0.0788239 max:1 sd:0.201982\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:249 (67.663%) mean:0.358637 min:0 max:1 sd:0.25643\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:320 (86.9565%) mean:0.0255121 min:0 max:1 sd:0.142973\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0436818 min:0 max:1 sd:0.144231\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0256998 min:0 max:1 sd:0.142868\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:320 (86.9565%) mean:0.399993 min:0 max:1 sd:0.226162\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.388517 min:0 max:1 sd:0.224516\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.516071 min:0 max:1 sd:0.194173\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:320 (86.9565%) mean:0.093389 min:0 max:1 sd:0.182857\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.11697 min:0 max:1 sd:0.232896\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0787134 min:0 max:1 sd:0.166296\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:320 (86.9565%) mean:0.141924 min:0 max:1 sd:0.138413\n",
      "\t83: \"var_index\" NUMERICAL num-nas:120 (32.6087%) mean:0.0809081 min:0 max:1 sd:0.146689\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:34 (9.23913%) mean:0.764359 min:0 max:1 sd:0.273032\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:34 (9.23913%) mean:0.813717 min:0 max:1 sd:0.23715\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:34 (9.23913%) mean:0.0269664 min:0 max:1 sd:0.0948415\n",
      "\t87: \"var_max\" NUMERICAL num-nas:120 (32.6087%) mean:0.00841693 min:0 max:0.233918 sd:0.0237654\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:120 (32.6087%) mean:0.0485518 min:0 max:1 sd:0.115528\n",
      "\t89: \"var_min\" NUMERICAL num-nas:120 (32.6087%) mean:0.0410228 min:0 max:1 sd:0.108312\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.423619 min:0 max:1 sd:0.174554\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:120 (32.6087%) mean:0.00470915 min:0 max:0.226755 sd:0.0204158\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.845588 logloss:5.56556\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:7) done accuracy:0.855586 logloss:1.49118\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.904891 logloss:0.449997\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.894022 logloss:0.355494\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:39) done accuracy:0.907609 logloss:0.347346\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:51) done accuracy:0.899457 logloss:0.340863\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.915761 logloss:0.339096\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.913043 logloss:0.249374\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:81) done accuracy:0.915761 logloss:0.253566\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.918478 logloss:0.25368\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.910326 logloss:0.25361\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.913043 logloss:0.254879\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.915761 logloss:0.253747\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:133) done accuracy:0.910326 logloss:0.252763\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:139) done accuracy:0.915761 logloss:0.250988\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.910326 logloss:0.250626\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.913043 logloss:0.249973\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:171) done accuracy:0.910326 logloss:0.249074\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:181) done accuracy:0.910326 logloss:0.250845\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:185) done accuracy:0.907609 logloss:0.253126\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:202) done accuracy:0.910326 logloss:0.253389\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:208) done accuracy:0.907609 logloss:0.253114\n",
      "[INFO random_forest.cc:578] Training of tree  222/300 (tree index:222) done accuracy:0.907609 logloss:0.253451\n",
      "[INFO random_forest.cc:578] Training of tree  232/300 (tree index:234) done accuracy:0.907609 logloss:0.254038\n",
      "[INFO random_forest.cc:578] Training of tree  242/300 (tree index:243) done accuracy:0.913043 logloss:0.253915\n",
      "[INFO random_forest.cc:578] Training of tree  252/300 (tree index:251) done accuracy:0.907609 logloss:0.254552\n",
      "[INFO random_forest.cc:578] Training of tree  262/300 (tree index:262) done accuracy:0.907609 logloss:0.255133\n",
      "[INFO random_forest.cc:578] Training of tree  272/300 (tree index:272) done accuracy:0.907609 logloss:0.256548\n",
      "[INFO random_forest.cc:578] Training of tree  282/300 (tree index:281) done accuracy:0.907609 logloss:0.25737\n",
      "[INFO random_forest.cc:578] Training of tree  292/300 (tree index:291) done accuracy:0.902174 logloss:0.257488\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.902174 logloss:0.256805\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.902174 logloss:0.256805\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpg8u3fyvf\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13084 node(s), and 91 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8913\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 75%|███████▌  | 24/32 [01:22<00:27,  3.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0978326 min:0 max:1 sd:0.179753\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.111922 min:0 max:1 sd:0.195249\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0839325 min:0 max:1 sd:0.169915\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.176203 min:0 max:1 sd:0.20503\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0273289 min:0 max:1 sd:0.145178\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.155883 min:0 max:1 sd:0.169511\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0731475 min:0 max:1 sd:0.184235\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.0936376 min:0 max:1 sd:0.230847\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.104514 min:0 max:1 sd:0.210937\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.199102 min:0 max:1 sd:0.155424\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:322 (87.5%) mean:0.0799118 min:0 max:1 sd:0.211673\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.109748 min:0 max:0.696288 sd:0.136645\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0525086 min:0 max:1 sd:0.1472\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0955473 min:0 max:1 sd:0.206893\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.101861 min:0 max:1 sd:0.222414\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0920158 min:0 max:1 sd:0.195798\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.105923 min:0 max:1 sd:0.155706\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.521495 min:0 max:1 sd:0.182179\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.48213 min:0 max:1 sd:0.186262\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.462616 min:0 max:1 sd:0.19105\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.495701 min:0 max:1 sd:0.181598\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.504964 min:0 max:1 sd:0.185049\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.489798 min:0 max:1 sd:0.187167\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:24 (6.52174%) mean:0.439137 min:0 max:1 sd:0.180185\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:27 (7.33696%) mean:0.436353 min:0 max:1 sd:0.200694\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:93 (25.2717%) mean:0.402522 min:0 max:1 sd:0.194858\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.574148 min:0 max:1 sd:0.175069\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:40 (10.8696%) mean:0.521487 min:0.0677501 max:1 sd:0.181781\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.505114 min:0 max:1 sd:0.191388\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:112 (30.4348%) mean:0.484655 min:0 max:1 sd:0.194481\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.521192 min:0.0265645 max:1 sd:0.194851\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.443239 min:0.0665289 max:1 sd:0.206763\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:102 (27.7174%) mean:0.412267 min:0 max:1 sd:0.200694\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.423479 min:0.00774026 max:1 sd:0.215806\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:298 (80.9783%) mean:0.380274 min:0 max:1 sd:0.199106\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:322 (87.5%) mean:0.199817 min:0 max:1 sd:0.26996\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.194634 min:0 max:1 sd:0.269846\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.188514 min:0 max:1 sd:0.258287\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:322 (87.5%) mean:0.201671 min:0 max:1 sd:0.270357\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.20558 min:0 max:1 sd:0.272777\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.192931 min:0 max:1 sd:0.262501\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:322 (87.5%) mean:0.196313 min:0 max:1 sd:0.256283\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.198403 min:0 max:1 sd:0.259657\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.186463 min:0 max:1 sd:0.238686\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:21 (5.70652%) mean:0.621301 min:0 max:1 sd:0.310932\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.700607 min:0 max:1 sd:0.26605\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.482659 min:0 max:1 sd:0.275906\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:24 (6.52174%) mean:0.551809 min:0 max:1 sd:0.358743\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:24 (6.52174%) mean:0.649618 min:0 max:1 sd:0.312697\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:24 (6.52174%) mean:0.423012 min:0 max:1 sd:0.325439\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:32 (8.69565%) mean:0.425545 min:0 max:1 sd:0.321151\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:32 (8.69565%) mean:0.58529 min:0 max:1 sd:0.25466\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:32 (8.69565%) mean:0.347824 min:0 max:1 sd:0.281642\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.513824 min:0.0105506 max:1 sd:0.233348\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.514099 min:0.00905979 max:1 sd:0.24127\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.519165 min:0 max:1 sd:0.171773\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:26 (7.06522%) mean:0.4719 min:0.0902793 max:1 sd:0.181572\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:56 (15.2174%) mean:0.456078 min:0 max:1 sd:0.187567\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.518573 min:0 max:1 sd:0.19779\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.458651 min:0 max:1 sd:0.182956\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.458014 min:0 max:1 sd:0.194893\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:19 (5.16304%) mean:0.462735 min:0 max:1 sd:0.197709\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.432011 min:0 max:1 sd:0.20068\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.435331 min:0 max:1 sd:0.249514\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.571992 min:0 max:1 sd:0.170756\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:36 (9.78261%) mean:0.526339 min:0 max:1 sd:0.180717\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:69 (18.75%) mean:0.481723 min:0 max:1 sd:0.195132\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.517215 min:0 max:1 sd:0.204599\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:132 (35.8696%) mean:0.538837 min:0 max:1 sd:0.188271\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:266 (72.2826%) mean:0.443964 min:0 max:1 sd:0.225999\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.444852 min:0 max:1 sd:0.217283\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:126 (34.2391%) mean:0.457687 min:0 max:1 sd:0.202671\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:256 (69.5652%) mean:0.344335 min:0 max:1 sd:0.258512\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:322 (87.5%) mean:0.0261361 min:0 max:1 sd:0.146023\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0399384 min:0 max:1 sd:0.147086\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0262986 min:0 max:1 sd:0.145916\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:322 (87.5%) mean:0.381834 min:0 max:1 sd:0.211949\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.370178 min:0 max:1 sd:0.209466\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.501396 min:0 max:1 sd:0.183664\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:322 (87.5%) mean:0.0914617 min:0 max:1 sd:0.180483\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:322 (87.5%) mean:0.115682 min:0 max:1 sd:0.231572\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:323 (87.7717%) mean:0.0764706 min:0 max:1 sd:0.16472\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:322 (87.5%) mean:0.147345 min:0 max:1 sd:0.142089\n",
      "\t83: \"var_index\" NUMERICAL num-nas:116 (31.5217%) mean:0.0847064 min:0 max:1 sd:0.147336\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:33 (8.96739%) mean:0.758974 min:0 max:1 sd:0.271308\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:33 (8.96739%) mean:0.811105 min:0 max:1 sd:0.234987\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:33 (8.96739%) mean:0.0215642 min:0 max:1 sd:0.0858774\n",
      "\t87: \"var_max\" NUMERICAL num-nas:116 (31.5217%) mean:0.0118042 min:0 max:1 sd:0.0665412\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:116 (31.5217%) mean:0.0475784 min:0 max:1 sd:0.11437\n",
      "\t89: \"var_min\" NUMERICAL num-nas:116 (31.5217%) mean:0.0385153 min:0 max:1 sd:0.102921\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.433537 min:0 max:1 sd:0.171406\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:116 (31.5217%) mean:0.00827324 min:9.36969e-06 max:1 sd:0.0656484\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.882353 logloss:4.24043\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.882834 logloss:1.27947\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.883152 logloss:0.451303\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:29) done accuracy:0.894022 logloss:0.445397\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:43) done accuracy:0.888587 logloss:0.246658\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:52) done accuracy:0.899457 logloss:0.251324\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.894022 logloss:0.248021\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:71) done accuracy:0.902174 logloss:0.246807\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.899457 logloss:0.250074\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.899457 logloss:0.254344\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.894022 logloss:0.25208\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.902174 logloss:0.250535\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.907609 logloss:0.248541\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:129) done accuracy:0.904891 logloss:0.249289\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.907609 logloss:0.248869\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.904891 logloss:0.245517\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.904891 logloss:0.247693\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.907609 logloss:0.247713\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:181) done accuracy:0.902174 logloss:0.248525\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.904891 logloss:0.248924\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:199) done accuracy:0.904891 logloss:0.251554\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.910326 logloss:0.250934\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:222) done accuracy:0.904891 logloss:0.249898\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:232) done accuracy:0.904891 logloss:0.250797\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.904891 logloss:0.249774\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:253) done accuracy:0.904891 logloss:0.249166\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:258) done accuracy:0.899457 logloss:0.247972\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:266) done accuracy:0.899457 logloss:0.247183\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:282) done accuracy:0.902174 logloss:0.246499\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.904891 logloss:0.246566\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:298) done accuracy:0.907609 logloss:0.246291\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.907609 logloss:0.246291\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpkjv18tdm\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13118 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9022\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 78%|███████▊  | 25/32 [01:26<00:25,  3.68s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0927953 min:7.20293e-05 max:0.451509 sd:0.127715\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.116027 min:7.14336e-05 max:0.603673 sd:0.162371\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0713175 min:2.30324e-07 max:0.369222 sd:0.100154\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.163716 min:0.00335387 max:1 sd:0.1838\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.00598546 min:0.000195345 max:0.0453877 sd:0.00772511\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.15085 min:0.000481116 max:1 sd:0.175573\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0667391 min:0 max:1 sd:0.181251\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0770424 min:1.82725e-05 max:1 sd:0.195008\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:343 (93.2065%) mean:0.100247 min:0 max:1 sd:0.215778\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.186534 min:0 max:1 sd:0.161735\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.0818395 min:0 max:1 sd:0.218707\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.133201 min:0 max:1 sd:0.212057\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0587227 min:0 max:1 sd:0.160713\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0847611 min:5.72011e-11 max:1 sd:0.189656\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0845368 min:0 max:0.917609 sd:0.183082\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.0813826 min:0 max:1 sd:0.18526\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.0867694 min:0 max:0.570059 sd:0.0833303\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.51907 min:0 max:1 sd:0.183029\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.480888 min:0 max:0.989319 sd:0.187059\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:66 (17.9348%) mean:0.460205 min:0 max:1 sd:0.191162\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.492497 min:0 max:0.973154 sd:0.182944\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.503594 min:0 max:0.989925 sd:0.186489\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:8 (2.17391%) mean:0.485981 min:0 max:1 sd:0.187898\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:27 (7.33696%) mean:0.440695 min:0 max:0.953386 sd:0.178578\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:26 (7.06522%) mean:0.441446 min:0 max:0.961047 sd:0.198649\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:99 (26.9022%) mean:0.402728 min:0 max:0.836502 sd:0.193231\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.569785 min:0 max:1 sd:0.177217\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:42 (11.413%) mean:0.520576 min:0 max:0.990382 sd:0.182331\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:80 (21.7391%) mean:0.501518 min:0 max:1 sd:0.189923\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:118 (32.0652%) mean:0.490681 min:0 max:0.955238 sd:0.190769\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.510612 min:0 max:0.971789 sd:0.200553\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:305 (82.8804%) mean:0.413755 min:0 max:0.933891 sd:0.195319\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.418414 min:0 max:0.947005 sd:0.196888\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:118 (32.0652%) mean:0.419178 min:0 max:0.9598 sd:0.217571\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:297 (80.7065%) mean:0.358427 min:0 max:0.84848 sd:0.184337\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:325 (88.3152%) mean:0.172123 min:0 max:1 sd:0.233189\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.171065 min:0 max:1 sd:0.243688\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.15676 min:0.00113829 max:0.96449 sd:0.21019\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:325 (88.3152%) mean:0.171438 min:0 max:0.979026 sd:0.223878\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.176436 min:0 max:0.992443 sd:0.229247\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.160941 min:0 max:0.907555 sd:0.211099\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:325 (88.3152%) mean:0.167084 min:0.00172566 max:0.903265 sd:0.209524\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.170032 min:0 max:0.930383 sd:0.216176\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.155532 min:0.00273806 max:0.703256 sd:0.182474\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:21 (5.70652%) mean:0.623896 min:0 max:1 sd:0.307797\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.700633 min:0 max:1 sd:0.26941\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.477737 min:0 max:1 sd:0.268553\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:23 (6.25%) mean:0.541861 min:0 max:1 sd:0.350567\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:23 (6.25%) mean:0.642893 min:0 max:1 sd:0.307763\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:23 (6.25%) mean:0.406056 min:0 max:1 sd:0.316399\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:31 (8.42391%) mean:0.409885 min:0 max:1 sd:0.31704\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:31 (8.42391%) mean:0.56945 min:0 max:1 sd:0.250443\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:31 (8.42391%) mean:0.334096 min:0 max:0.961272 sd:0.277985\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.490827 min:0 max:1 sd:0.220477\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.498334 min:0 max:1 sd:0.234678\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.519582 min:0 max:0.957751 sd:0.171057\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:29 (7.88043%) mean:0.47195 min:0 max:0.940867 sd:0.181389\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:58 (15.7609%) mean:0.449571 min:0 max:0.988268 sd:0.189042\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.519088 min:0 max:0.952412 sd:0.199659\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.457806 min:0 max:0.939857 sd:0.182966\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.455045 min:0 max:0.989602 sd:0.193165\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:19 (5.16304%) mean:0.465366 min:0 max:1 sd:0.198614\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.436859 min:0 max:0.94676 sd:0.198991\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:68 (18.4783%) mean:0.440764 min:0 max:1 sd:0.253262\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.571488 min:0 max:0.964719 sd:0.169651\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:40 (10.8696%) mean:0.529062 min:0 max:0.949076 sd:0.17586\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:73 (19.837%) mean:0.479043 min:0 max:0.988906 sd:0.192169\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:120 (32.6087%) mean:0.526638 min:0 max:1 sd:0.203356\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.532673 min:0 max:0.957854 sd:0.191635\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:268 (72.8261%) mean:0.430104 min:0 max:1 sd:0.21352\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:110 (29.8913%) mean:0.452351 min:0.000368284 max:1 sd:0.216744\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:116 (31.5217%) mean:0.452119 min:0 max:0.94535 sd:0.203979\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:257 (69.837%) mean:0.34172 min:0 max:1 sd:0.249006\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0276313 min:0 max:1 sd:0.150901\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0404093 min:0 max:1 sd:0.151525\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0276972 min:1.40628e-05 max:1 sd:0.150793\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:325 (88.3152%) mean:0.409646 min:0.0312225 max:1 sd:0.229307\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.395817 min:0 max:1 sd:0.230452\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.525601 min:0.223379 max:1 sd:0.190893\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0871065 min:0 max:1 sd:0.178991\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.100635 min:0 max:1 sd:0.198153\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0782632 min:0.000337785 max:1 sd:0.169441\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.143373 min:0.0100233 max:1 sd:0.145467\n",
      "\t83: \"var_index\" NUMERICAL num-nas:114 (30.9783%) mean:0.071344 min:0 max:0.978261 sd:0.126836\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:33 (8.96739%) mean:0.750342 min:0 max:1 sd:0.274796\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:33 (8.96739%) mean:0.804431 min:0 max:1 sd:0.239484\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:33 (8.96739%) mean:0.0195926 min:0 max:0.389902 sd:0.0716335\n",
      "\t87: \"var_max\" NUMERICAL num-nas:114 (30.9783%) mean:0.0074241 min:1.72134e-05 max:0.233918 sd:0.0218421\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:114 (30.9783%) mean:0.0420781 min:7.9609e-05 max:0.623456 sd:0.0943101\n",
      "\t89: \"var_min\" NUMERICAL num-nas:114 (30.9783%) mean:0.0364 min:2.4978e-05 max:0.54179 sd:0.0896219\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.42126 min:0.0221895 max:0.99369 sd:0.163172\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:114 (30.9783%) mean:0.00388927 min:9.36969e-06 max:0.226755 sd:0.0183777\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:3) done accuracy:0.857143 logloss:5.14909\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.858696 logloss:1.19975\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:17) done accuracy:0.896739 logloss:0.25126\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.902174 logloss:0.245106\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.910326 logloss:0.239302\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:49) done accuracy:0.913043 logloss:0.245104\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:58) done accuracy:0.910326 logloss:0.242122\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.910326 logloss:0.242748\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:79) done accuracy:0.921196 logloss:0.241413\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.904891 logloss:0.245261\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:101) done accuracy:0.907609 logloss:0.244685\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.904891 logloss:0.246357\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.907609 logloss:0.2442\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:127) done accuracy:0.907609 logloss:0.24442\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:139) done accuracy:0.907609 logloss:0.242824\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:151) done accuracy:0.907609 logloss:0.241474\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:157) done accuracy:0.896739 logloss:0.244957\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:172) done accuracy:0.907609 logloss:0.24471\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.904891 logloss:0.243979\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.907609 logloss:0.243806\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.907609 logloss:0.244044\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:213) done accuracy:0.907609 logloss:0.244707\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:223) done accuracy:0.913043 logloss:0.243483\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:229) done accuracy:0.910326 logloss:0.24286\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.915761 logloss:0.244478\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:251) done accuracy:0.918478 logloss:0.243112\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:261) done accuracy:0.915761 logloss:0.243381\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:273) done accuracy:0.915761 logloss:0.243146\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.915761 logloss:0.242691\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:290) done accuracy:0.921196 logloss:0.241918\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:291) done accuracy:0.918478 logloss:0.241187\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.918478 logloss:0.241187\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpcp8elu4x\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12574 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 0.9022\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 81%|████████▏ | 26/32 [01:30<00:22,  3.81s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.0998713 min:0 max:1 sd:0.184781\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.121674 min:0 max:1 sd:0.208043\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0805162 min:0 max:1 sd:0.168764\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.186633 min:0 max:1 sd:0.215599\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0287687 min:0 max:1 sd:0.148308\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.162182 min:0 max:1 sd:0.179692\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0646538 min:0 max:0.496254 sd:0.13889\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0896354 min:0 max:0.978189 sd:0.204875\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.0794326 min:0 max:0.427298 sd:0.126574\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.184234 min:0 max:1 sd:0.159084\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:324 (88.0435%) mean:0.106166 min:0 max:1 sd:0.255272\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.147245 min:0 max:1 sd:0.215872\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0621571 min:0 max:1 sd:0.15898\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0895015 min:0 max:0.726902 sd:0.17066\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0994153 min:0 max:1 sd:0.200037\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:327 (88.8587%) mean:0.082823 min:0 max:0.58012 sd:0.148488\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.105753 min:0 max:1 sd:0.159325\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.515291 min:0 max:0.988978 sd:0.181213\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:31 (8.42391%) mean:0.481866 min:0 max:1 sd:0.181636\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:72 (19.5652%) mean:0.46485 min:0 max:0.976207 sd:0.183597\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.491334 min:0 max:1 sd:0.178621\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:4 (1.08696%) mean:0.501538 min:0 max:1 sd:0.183966\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:9 (2.44565%) mean:0.48499 min:0 max:0.980105 sd:0.185797\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.435016 min:0 max:1 sd:0.180155\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:22 (5.97826%) mean:0.430696 min:0 max:1 sd:0.200155\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:97 (26.3587%) mean:0.405216 min:0 max:1 sd:0.190759\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:13 (3.53261%) mean:0.569811 min:0 max:0.990661 sd:0.173956\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:42 (11.413%) mean:0.519077 min:0 max:1 sd:0.180522\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:87 (23.6413%) mean:0.506757 min:0 max:0.978192 sd:0.184008\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.478834 min:0 max:1 sd:0.196815\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.513753 min:0 max:1 sd:0.196156\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.436116 min:0.0665289 max:1 sd:0.186418\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.407525 min:0 max:1 sd:0.199982\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.41743 min:0 max:1 sd:0.215794\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:300 (81.5217%) mean:0.369465 min:0 max:1 sd:0.182431\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:324 (88.0435%) mean:0.163243 min:0 max:0.899502 sd:0.224202\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.162433 min:0 max:1 sd:0.235095\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.149633 min:0 max:0.920431 sd:0.205702\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:324 (88.0435%) mean:0.164865 min:0 max:1 sd:0.224992\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.169559 min:0 max:1 sd:0.229026\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.156112 min:0 max:0.99507 sd:0.218157\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:324 (88.0435%) mean:0.162897 min:0 max:1 sd:0.217454\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.165484 min:0 max:1 sd:0.22137\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.156109 min:0 max:1 sd:0.206888\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:19 (5.16304%) mean:0.622085 min:0 max:1 sd:0.313391\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.704498 min:0 max:1 sd:0.268346\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.480138 min:0 max:0.993699 sd:0.276801\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:19 (5.16304%) mean:0.556861 min:0 max:1 sd:0.357561\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:19 (5.16304%) mean:0.657069 min:0 max:1 sd:0.310156\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:19 (5.16304%) mean:0.42371 min:0 max:0.99189 sd:0.325447\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:26 (7.06522%) mean:0.427118 min:0 max:1 sd:0.327068\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:26 (7.06522%) mean:0.589561 min:0 max:1 sd:0.257625\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:26 (7.06522%) mean:0.342022 min:0 max:0.961272 sd:0.279823\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.515477 min:0 max:1 sd:0.22926\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.51418 min:0.00905979 max:1 sd:0.24095\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.514289 min:0 max:1 sd:0.168689\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.468998 min:0 max:1 sd:0.178369\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.452724 min:0 max:0.948533 sd:0.183068\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.513475 min:0 max:1 sd:0.195699\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:5 (1.3587%) mean:0.454407 min:0 max:1 sd:0.17989\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.452215 min:0 max:0.95392 sd:0.19171\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.459245 min:0 max:1 sd:0.195761\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:17 (4.61957%) mean:0.425948 min:0 max:1 sd:0.199739\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:64 (17.3913%) mean:0.432239 min:0 max:1 sd:0.248525\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.567523 min:0 max:1 sd:0.169569\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:38 (10.3261%) mean:0.524727 min:0 max:1 sd:0.175757\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.485424 min:0 max:0.952271 sd:0.185649\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.51015 min:0 max:1 sd:0.206741\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.533825 min:0 max:1 sd:0.188656\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:274 (74.4565%) mean:0.440524 min:0 max:1 sd:0.211046\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.440896 min:0 max:1 sd:0.215123\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:123 (33.4239%) mean:0.451322 min:0 max:1 sd:0.201403\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:264 (71.7391%) mean:0.341612 min:0 max:1 sd:0.244503\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:324 (88.0435%) mean:0.00437975 min:0 max:0.107496 sd:0.0159859\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0418891 min:0 max:1 sd:0.148824\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.00439539 min:0 max:0.100884 sd:0.0151173\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:324 (88.0435%) mean:0.389009 min:0 max:1 sd:0.233957\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.386916 min:0 max:1 sd:0.235697\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.500058 min:0 max:1 sd:0.1988\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:324 (88.0435%) mean:0.0849336 min:0 max:0.531611 sd:0.138275\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:324 (88.0435%) mean:0.114181 min:0 max:0.974137 sd:0.20991\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0658175 min:0 max:0.426528 sd:0.104567\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:324 (88.0435%) mean:0.140528 min:0 max:1 sd:0.146326\n",
      "\t83: \"var_index\" NUMERICAL num-nas:118 (32.0652%) mean:0.0795217 min:0 max:1 sd:0.140737\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:31 (8.42391%) mean:0.759261 min:0 max:1 sd:0.272147\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:31 (8.42391%) mean:0.807976 min:0 max:1 sd:0.23717\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:31 (8.42391%) mean:0.0216016 min:0 max:0.389902 sd:0.0751744\n",
      "\t87: \"var_max\" NUMERICAL num-nas:118 (32.0652%) mean:0.0107381 min:0 max:1 sd:0.0656588\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:118 (32.0652%) mean:0.0434485 min:0 max:1 sd:0.10991\n",
      "\t89: \"var_min\" NUMERICAL num-nas:118 (32.0652%) mean:0.0356525 min:0 max:1 sd:0.100912\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:118 (32.0652%) mean:0.430424 min:0 max:1 sd:0.174378\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:118 (32.0652%) mean:0.00759296 min:0 max:1 sd:0.0650502\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:5) done accuracy:0.787879 logloss:7.64562\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.858696 logloss:1.11514\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:22) done accuracy:0.866848 logloss:0.470838\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:29) done accuracy:0.888587 logloss:0.357272\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:40) done accuracy:0.883152 logloss:0.265759\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.877717 logloss:0.268425\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.894022 logloss:0.267717\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:72) done accuracy:0.891304 logloss:0.26992\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.904891 logloss:0.266498\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.899457 logloss:0.266681\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:101) done accuracy:0.904891 logloss:0.262169\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.899457 logloss:0.265086\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.894022 logloss:0.261876\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:132) done accuracy:0.899457 logloss:0.261106\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.902174 logloss:0.258877\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:153) done accuracy:0.902174 logloss:0.257671\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.894022 logloss:0.256974\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:129) done accuracy:0.899457 logloss:0.254811\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:181) done accuracy:0.896739 logloss:0.254789\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:193) done accuracy:0.896739 logloss:0.256584\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.891304 logloss:0.25749\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.899457 logloss:0.256168\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:223) done accuracy:0.902174 logloss:0.255875\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:233) done accuracy:0.899457 logloss:0.256414\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:241) done accuracy:0.899457 logloss:0.254902\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:253) done accuracy:0.899457 logloss:0.255343\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:263) done accuracy:0.899457 logloss:0.254651\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:272) done accuracy:0.894022 logloss:0.254565\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:279) done accuracy:0.894022 logloss:0.255169\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.902174 logloss:0.255316\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.899457 logloss:0.25479\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.899457 logloss:0.25479\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpklymc3hd\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12928 node(s), and 92 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8804\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 84%|████████▍ | 27/32 [01:34<00:18,  3.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 9ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0967146 min:0 max:1 sd:0.184042\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.105343 min:0 max:1 sd:0.189694\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0860851 min:0 max:1 sd:0.177321\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.178085 min:0 max:0.946182 sd:0.17547\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0286383 min:0 max:1 sd:0.149958\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.155001 min:0 max:0.586641 sd:0.125375\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0773963 min:1.03904e-10 max:1 sd:0.18843\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0991524 min:0 max:1 sd:0.235539\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:343 (93.2065%) mean:0.107193 min:0.00655816 max:1 sd:0.213006\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.171333 min:0 max:0.449374 sd:0.100456\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.0868072 min:0.00124501 max:1 sd:0.217814\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.141823 min:0.00469141 max:1 sd:0.198071\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0424994 min:0.00113785 max:0.398003 sd:0.0695236\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.102373 min:0 max:1 sd:0.210987\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.108658 min:0 max:1 sd:0.226061\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.099301 min:0 max:1 sd:0.200139\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.0944014 min:0 max:1 sd:0.144882\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.514618 min:0 max:1 sd:0.184783\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.478116 min:0 max:1 sd:0.185686\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:63 (17.1196%) mean:0.460887 min:0 max:1 sd:0.18921\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.491036 min:0 max:1 sd:0.183744\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.498172 min:0 max:1 sd:0.187416\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:10 (2.71739%) mean:0.487655 min:0 max:1 sd:0.186766\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:25 (6.79348%) mean:0.435273 min:0 max:1 sd:0.177083\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:27 (7.33696%) mean:0.430437 min:0 max:1 sd:0.195638\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:91 (24.7283%) mean:0.404346 min:0 max:1 sd:0.197655\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.567841 min:0 max:1 sd:0.176029\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:40 (10.8696%) mean:0.515624 min:0 max:1 sd:0.182119\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.501878 min:0 max:1 sd:0.188757\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:116 (31.5217%) mean:0.477133 min:0 max:1 sd:0.194819\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:135 (36.6848%) mean:0.504469 min:0 max:1 sd:0.197624\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:310 (84.2391%) mean:0.442871 min:0 max:1 sd:0.210652\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.407095 min:0.0091239 max:1 sd:0.197224\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.407898 min:0 max:1 sd:0.21467\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:305 (82.8804%) mean:0.385981 min:0 max:1 sd:0.204905\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:325 (88.3152%) mean:0.189656 min:0.000411857 max:1 sd:0.256144\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.17626 min:0.00028293 max:0.928857 sd:0.235679\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.187687 min:0 max:1 sd:0.254243\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:325 (88.3152%) mean:0.199841 min:0 max:1 sd:0.266422\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.203264 min:0 max:1 sd:0.267694\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.192113 min:0 max:1 sd:0.260743\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:325 (88.3152%) mean:0.193133 min:0 max:1 sd:0.252658\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.194763 min:0 max:1 sd:0.255056\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.184004 min:0 max:1 sd:0.236352\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:17 (4.61957%) mean:0.632805 min:0 max:1 sd:0.314245\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:17 (4.61957%) mean:0.712735 min:0.0642085 max:1 sd:0.265153\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:17 (4.61957%) mean:0.485823 min:0 max:1 sd:0.27202\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:20 (5.43478%) mean:0.562615 min:0 max:1 sd:0.358525\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.664498 min:0.0358922 max:1 sd:0.306424\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.422618 min:0 max:1 sd:0.325365\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:28 (7.6087%) mean:0.42325 min:0 max:1 sd:0.326266\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:28 (7.6087%) mean:0.590868 min:0.0466496 max:1 sd:0.25437\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:28 (7.6087%) mean:0.340901 min:0 max:1 sd:0.283171\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:124 (33.6957%) mean:0.502433 min:0 max:0.999799 sd:0.233041\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:124 (33.6957%) mean:0.499217 min:0 max:0.999094 sd:0.238014\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.511939 min:0 max:1 sd:0.171366\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:27 (7.33696%) mean:0.466518 min:0 max:1 sd:0.180117\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:60 (16.3043%) mean:0.455498 min:0 max:1 sd:0.184124\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.515806 min:0 max:1 sd:0.199949\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.45285 min:0 max:1 sd:0.181719\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:1 (0.271739%) mean:0.453766 min:0 max:1 sd:0.193869\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:17 (4.61957%) mean:0.457474 min:0 max:0.990302 sd:0.194632\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:20 (5.43478%) mean:0.425033 min:0 max:1 sd:0.197161\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:63 (17.1196%) mean:0.438488 min:0 max:1 sd:0.252725\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:8 (2.17391%) mean:0.56224 min:0 max:1 sd:0.172579\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.522156 min:0 max:1 sd:0.17597\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:73 (19.837%) mean:0.480735 min:0 max:1 sd:0.191304\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:118 (32.0652%) mean:0.509265 min:0 max:0.995568 sd:0.204792\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.524567 min:0 max:1 sd:0.190471\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:276 (75%) mean:0.45003 min:0 max:0.971545 sd:0.227231\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.439367 min:0 max:0.991934 sd:0.213633\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.444792 min:0 max:1 sd:0.201095\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:264 (71.7391%) mean:0.345278 min:0 max:1 sd:0.260847\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0255531 min:4.38688e-06 max:1 sd:0.150403\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.0199371 min:4.1493e-05 max:0.117754 sd:0.0294477\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0259159 min:0 max:1 sd:0.15037\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:325 (88.3152%) mean:0.364051 min:0 max:0.756816 sd:0.193553\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.353084 min:0.0823497 max:0.777114 sd:0.188156\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.48584 min:0 max:0.795659 sd:0.171594\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0962389 min:0.00234924 max:1 sd:0.184618\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.121534 min:0.00353616 max:1 sd:0.235343\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.078443 min:0 max:1 sd:0.167396\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.121429 min:0 max:0.273193 sd:0.0629415\n",
      "\t83: \"var_index\" NUMERICAL num-nas:124 (33.6957%) mean:0.0758048 min:0 max:1 sd:0.135445\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:35 (9.51087%) mean:0.745026 min:0 max:1 sd:0.282702\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:35 (9.51087%) mean:0.796274 min:0 max:1 sd:0.249385\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:35 (9.51087%) mean:0.0239385 min:0 max:1 sd:0.0906612\n",
      "\t87: \"var_max\" NUMERICAL num-nas:124 (33.6957%) mean:0.0112382 min:0 max:1 sd:0.0660958\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:124 (33.6957%) mean:0.0461073 min:0 max:1 sd:0.113484\n",
      "\t89: \"var_min\" NUMERICAL num-nas:124 (33.6957%) mean:0.0380676 min:0 max:1 sd:0.104257\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:124 (33.6957%) mean:0.426703 min:0 max:1 sd:0.170339\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:124 (33.6957%) mean:0.0077362 min:0 max:1 sd:0.0653075\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.860294 logloss:5.03551\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.866485 logloss:2.0684\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.875 logloss:0.547263\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:29) done accuracy:0.880435 logloss:0.549476\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:39) done accuracy:0.896739 logloss:0.268517\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.904891 logloss:0.253775\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.899457 logloss:0.253448\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.902174 logloss:0.252704\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:80) done accuracy:0.907609 logloss:0.249988\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:93) done accuracy:0.904891 logloss:0.250517\n",
      "[INFO random_forest.cc:578] Training of tree  102/300 (tree index:104) done accuracy:0.910326 logloss:0.250757\n",
      "[INFO random_forest.cc:578] Training of tree  112/300 (tree index:113) done accuracy:0.910326 logloss:0.249435\n",
      "[INFO random_forest.cc:578] Training of tree  122/300 (tree index:119) done accuracy:0.910326 logloss:0.249627\n",
      "[INFO random_forest.cc:578] Training of tree  132/300 (tree index:133) done accuracy:0.907609 logloss:0.249466\n",
      "[INFO random_forest.cc:578] Training of tree  142/300 (tree index:143) done accuracy:0.907609 logloss:0.249633\n",
      "[INFO random_forest.cc:578] Training of tree  152/300 (tree index:154) done accuracy:0.915761 logloss:0.24772\n",
      "[INFO random_forest.cc:578] Training of tree  162/300 (tree index:165) done accuracy:0.907609 logloss:0.24706\n",
      "[INFO random_forest.cc:578] Training of tree  172/300 (tree index:174) done accuracy:0.904891 logloss:0.24764\n",
      "[INFO random_forest.cc:578] Training of tree  182/300 (tree index:183) done accuracy:0.904891 logloss:0.247776\n",
      "[INFO random_forest.cc:578] Training of tree  192/300 (tree index:192) done accuracy:0.896739 logloss:0.246074\n",
      "[INFO random_forest.cc:578] Training of tree  202/300 (tree index:203) done accuracy:0.913043 logloss:0.247271\n",
      "[INFO random_forest.cc:578] Training of tree  212/300 (tree index:212) done accuracy:0.907609 logloss:0.247922\n",
      "[INFO random_forest.cc:578] Training of tree  222/300 (tree index:222) done accuracy:0.915761 logloss:0.247839\n",
      "[INFO random_forest.cc:578] Training of tree  232/300 (tree index:233) done accuracy:0.904891 logloss:0.247471\n",
      "[INFO random_forest.cc:578] Training of tree  242/300 (tree index:238) done accuracy:0.902174 logloss:0.249491\n",
      "[INFO random_forest.cc:578] Training of tree  252/300 (tree index:251) done accuracy:0.902174 logloss:0.24838\n",
      "[INFO random_forest.cc:578] Training of tree  262/300 (tree index:261) done accuracy:0.904891 logloss:0.249122\n",
      "[INFO random_forest.cc:578] Training of tree  272/300 (tree index:271) done accuracy:0.907609 logloss:0.249102\n",
      "[INFO random_forest.cc:578] Training of tree  282/300 (tree index:282) done accuracy:0.902174 logloss:0.249017\n",
      "[INFO random_forest.cc:578] Training of tree  292/300 (tree index:292) done accuracy:0.902174 logloss:0.248332\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.902174 logloss:0.248699\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.902174 logloss:0.248699\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpf7rem7w9\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12954 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9946\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9239\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 88%|████████▊ | 28/32 [01:38<00:15,  3.82s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:321 (87.2283%) mean:0.107688 min:0 max:1 sd:0.184763\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.124839 min:0 max:1 sd:0.20302\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0913218 min:0 max:1 sd:0.172797\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:321 (87.2283%) mean:0.183537 min:0 max:1 sd:0.210036\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.027206 min:0 max:1 sd:0.143623\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.160699 min:0 max:1 sd:0.174879\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:321 (87.2283%) mean:0.0616008 min:0 max:0.496254 sd:0.135206\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0846935 min:0 max:0.978189 sd:0.199245\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.0790266 min:0.00246435 max:0.427298 sd:0.124505\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:321 (87.2283%) mean:0.197831 min:0.0344311 max:1 sd:0.155065\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:321 (87.2283%) mean:0.101233 min:0 max:1 sd:0.247757\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.144259 min:0 max:1 sd:0.209624\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0600988 min:0 max:1 sd:0.15408\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:321 (87.2283%) mean:0.0856721 min:0 max:0.726902 sd:0.166079\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0944523 min:0 max:1 sd:0.194584\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:324 (88.0435%) mean:0.0795305 min:0 max:0.58012 sd:0.144376\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:321 (87.2283%) mean:0.109096 min:0.0140926 max:1 sd:0.153753\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.51815 min:0 max:0.988978 sd:0.18284\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:30 (8.15217%) mean:0.478972 min:0 max:1 sd:0.185116\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:70 (19.0217%) mean:0.46568 min:0.0451185 max:0.980907 sd:0.183651\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.491749 min:0 max:1 sd:0.181459\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.500324 min:0 max:1 sd:0.185163\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:12 (3.26087%) mean:0.487194 min:0 max:0.980704 sd:0.18521\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:22 (5.97826%) mean:0.436757 min:0 max:1 sd:0.177832\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:23 (6.25%) mean:0.429999 min:0.0587585 max:1 sd:0.200862\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:95 (25.8152%) mean:0.398904 min:0 max:1 sd:0.197025\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.569481 min:0 max:0.990661 sd:0.177579\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.518853 min:0 max:1 sd:0.181182\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:83 (22.5543%) mean:0.505575 min:0.000319932 max:0.985639 sd:0.186475\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:114 (30.9783%) mean:0.485258 min:0 max:1 sd:0.1944\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:135 (36.6848%) mean:0.514195 min:0 max:1 sd:0.201516\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:304 (82.6087%) mean:0.455289 min:0.020997 max:1 sd:0.20038\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:105 (28.5326%) mean:0.410732 min:0 max:1 sd:0.200855\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:127 (34.5109%) mean:0.415497 min:0 max:1 sd:0.222114\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:298 (80.9783%) mean:0.393756 min:0.0423683 max:1 sd:0.191047\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:321 (87.2283%) mean:0.190003 min:0 max:0.949443 sd:0.245134\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.185566 min:0 max:1 sd:0.248294\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.179209 min:0 max:1 sd:0.234832\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:321 (87.2283%) mean:0.193303 min:0 max:1 sd:0.24813\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.196758 min:0 max:1 sd:0.250172\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.185931 min:0 max:1 sd:0.243688\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:321 (87.2283%) mean:0.189778 min:0 max:1 sd:0.238497\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.191579 min:0 max:1 sd:0.240361\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.183971 min:0 max:1 sd:0.231247\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:18 (4.8913%) mean:0.623058 min:0 max:1 sd:0.315004\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.700117 min:0 max:1 sd:0.27397\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.481258 min:0 max:0.993699 sd:0.275008\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:18 (4.8913%) mean:0.560729 min:0 max:1 sd:0.361578\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.6575 min:0 max:1 sd:0.315333\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.424138 min:0 max:0.99189 sd:0.327581\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:26 (7.06522%) mean:0.433799 min:0 max:1 sd:0.330663\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:26 (7.06522%) mean:0.591544 min:0 max:1 sd:0.258476\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:26 (7.06522%) mean:0.35366 min:0 max:1 sd:0.289905\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.504451 min:0 max:1 sd:0.218961\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.513004 min:0.00905979 max:1 sd:0.23206\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.515326 min:0 max:1 sd:0.170342\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.467653 min:0 max:1 sd:0.178507\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.453043 min:0 max:1 sd:0.181928\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.514752 min:0 max:1 sd:0.195389\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:7 (1.90217%) mean:0.453842 min:0 max:1 sd:0.178925\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.451918 min:0 max:1 sd:0.190362\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.45894 min:0 max:1 sd:0.193342\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:16 (4.34783%) mean:0.423762 min:0.05674 max:1 sd:0.199888\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:68 (18.4783%) mean:0.428245 min:0 max:1 sd:0.253339\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.567805 min:0 max:1 sd:0.170988\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:38 (10.3261%) mean:0.523188 min:0 max:1 sd:0.176386\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:76 (20.6522%) mean:0.482606 min:0.0401454 max:1 sd:0.186149\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.515082 min:0 max:1 sd:0.204254\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:136 (36.9565%) mean:0.534587 min:0 max:1 sd:0.19253\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:266 (72.2826%) mean:0.449851 min:0 max:1 sd:0.222712\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.440482 min:0.000368284 max:1 sd:0.214623\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:126 (34.2391%) mean:0.448348 min:0 max:1 sd:0.206439\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:257 (69.837%) mean:0.35263 min:0 max:1 sd:0.254634\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:321 (87.2283%) mean:0.00464905 min:0 max:0.107496 sd:0.0155625\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0428094 min:0 max:1 sd:0.14437\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.00481967 min:0 max:0.100884 sd:0.0148104\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:321 (87.2283%) mean:0.382745 min:0 max:1 sd:0.223224\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.375802 min:0 max:1 sd:0.223387\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.498613 min:0 max:1 sd:0.191452\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:321 (87.2283%) mean:0.0817801 min:0 max:0.531611 sd:0.134721\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:321 (87.2283%) mean:0.108801 min:0 max:0.974137 sd:0.204253\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:322 (87.5%) mean:0.0641512 min:0 max:0.426528 sd:0.102021\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:321 (87.2283%) mean:0.147513 min:0 max:1 sd:0.141423\n",
      "\t83: \"var_index\" NUMERICAL num-nas:119 (32.337%) mean:0.0799066 min:0 max:1 sd:0.144431\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:37 (10.0543%) mean:0.746582 min:0 max:1 sd:0.274278\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:37 (10.0543%) mean:0.799859 min:0 max:1 sd:0.240294\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:37 (10.0543%) mean:0.0262365 min:0 max:1 sd:0.0950169\n",
      "\t87: \"var_max\" NUMERICAL num-nas:119 (32.337%) mean:0.0109662 min:3.11037e-05 max:1 sd:0.0659707\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:119 (32.337%) mean:0.0462937 min:7.9609e-05 max:1 sd:0.116713\n",
      "\t89: \"var_min\" NUMERICAL num-nas:119 (32.337%) mean:0.0378377 min:2.4978e-05 max:1 sd:0.105597\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:119 (32.337%) mean:0.427388 min:0 max:1 sd:0.173238\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:119 (32.337%) mean:0.00761604 min:0 max:1 sd:0.0653971\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:1) done accuracy:0.838462 logloss:5.82244\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:9) done accuracy:0.850543 logloss:1.02077\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:21) done accuracy:0.880435 logloss:0.460119\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:32) done accuracy:0.899457 logloss:0.368079\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.904891 logloss:0.350374\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.910326 logloss:0.260976\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.907609 logloss:0.261724\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:69) done accuracy:0.899457 logloss:0.266255\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:78) done accuracy:0.904891 logloss:0.265762\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.907609 logloss:0.266844\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.910326 logloss:0.265904\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:111) done accuracy:0.910326 logloss:0.264185\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.902174 logloss:0.260209\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:133) done accuracy:0.902174 logloss:0.260122\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.899457 logloss:0.26127\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:144) done accuracy:0.915761 logloss:0.258281\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.907609 logloss:0.258734\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.904891 logloss:0.257593\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:176) done accuracy:0.910326 logloss:0.259178\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:191) done accuracy:0.915761 logloss:0.256598\n",
      "[INFO random_forest.cc:578] Training of tree  202/300 (tree index:202) done accuracy:0.913043 logloss:0.257654\n",
      "[INFO random_forest.cc:578] Training of tree  212/300 (tree index:213) done accuracy:0.918478 logloss:0.256415\n",
      "[INFO random_forest.cc:578] Training of tree  222/300 (tree index:223) done accuracy:0.918478 logloss:0.257965\n",
      "[INFO random_forest.cc:578] Training of tree  232/300 (tree index:233) done accuracy:0.921196 logloss:0.25715\n",
      "[INFO random_forest.cc:578] Training of tree  242/300 (tree index:243) done accuracy:0.923913 logloss:0.256177\n",
      "[INFO random_forest.cc:578] Training of tree  252/300 (tree index:253) done accuracy:0.921196 logloss:0.258007\n",
      "[INFO random_forest.cc:578] Training of tree  262/300 (tree index:265) done accuracy:0.918478 logloss:0.257721\n",
      "[INFO random_forest.cc:578] Training of tree  272/300 (tree index:272) done accuracy:0.918478 logloss:0.257351\n",
      "[INFO random_forest.cc:578] Training of tree  282/300 (tree index:282) done accuracy:0.915761 logloss:0.256414\n",
      "[INFO random_forest.cc:578] Training of tree  292/300 (tree index:292) done accuracy:0.921196 logloss:0.254819\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.918478 logloss:0.253792\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.918478 logloss:0.253792\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpil63dfb1\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13200 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 0.9946\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9348\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 91%|█████████ | 29/32 [01:41<00:11,  3.81s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0986014 min:0 max:1 sd:0.181478\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.117647 min:0 max:1 sd:0.197769\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0807319 min:0 max:1 sd:0.168473\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.179536 min:0 max:1 sd:0.213167\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0289877 min:0 max:1 sd:0.15002\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.15683 min:0 max:1 sd:0.17659\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0667339 min:1.74113e-10 max:0.496254 sd:0.140219\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0915167 min:0 max:0.978189 sd:0.206953\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:342 (92.9348%) mean:0.0815152 min:0 max:0.427298 sd:0.126185\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.189395 min:0 max:1 sd:0.159237\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.0843319 min:0.000481551 max:1 sd:0.218535\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:328 (89.1304%) mean:0.131475 min:0.00182679 max:1 sd:0.200459\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0541178 min:0.000412191 max:1 sd:0.152272\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0909507 min:0 max:0.726902 sd:0.172349\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.100501 min:0 max:1 sd:0.202136\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.0848987 min:0 max:0.58012 sd:0.149924\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.109684 min:0 max:1 sd:0.16048\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.526628 min:0 max:0.988978 sd:0.181441\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:26 (7.06522%) mean:0.490286 min:0 max:1 sd:0.185462\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:64 (17.3913%) mean:0.474395 min:0 max:0.980907 sd:0.185199\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.500511 min:0 max:1 sd:0.180471\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:3 (0.815217%) mean:0.512508 min:0 max:1 sd:0.184509\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:9 (2.44565%) mean:0.496297 min:0 max:0.980704 sd:0.186954\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:15 (4.07609%) mean:0.438263 min:0 max:1 sd:0.180118\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:21 (5.70652%) mean:0.438884 min:0.0587585 max:1 sd:0.200014\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:91 (24.7283%) mean:0.407686 min:0.0521682 max:1 sd:0.191471\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.57852 min:0 max:0.990661 sd:0.173309\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:34 (9.23913%) mean:0.526871 min:0 max:1 sd:0.181198\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:75 (20.3804%) mean:0.512961 min:0 max:0.985639 sd:0.185758\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:117 (31.7935%) mean:0.492647 min:0.0458262 max:1 sd:0.192124\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:135 (36.6848%) mean:0.5246 min:0 max:1 sd:0.197687\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:304 (82.6087%) mean:0.421839 min:0 max:1 sd:0.197999\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.418696 min:0 max:1 sd:0.200582\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.427092 min:0 max:1 sd:0.218661\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:296 (80.4348%) mean:0.3674 min:0 max:1 sd:0.188916\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:325 (88.3152%) mean:0.185977 min:0.000411857 max:0.949443 sd:0.249559\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.182982 min:0.00028293 max:1 sd:0.254249\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.173429 min:0 max:1 sd:0.237746\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:325 (88.3152%) mean:0.188081 min:0 max:1 sd:0.252138\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.192386 min:0 max:1 sd:0.254248\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.17963 min:0 max:1 sd:0.247672\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:325 (88.3152%) mean:0.185054 min:0 max:1 sd:0.241578\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.187124 min:0 max:1 sd:0.243701\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.178711 min:0 max:1 sd:0.233616\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:14 (3.80435%) mean:0.636365 min:0 max:1 sd:0.315431\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:14 (3.80435%) mean:0.711307 min:0.0483153 max:1 sd:0.270977\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:14 (3.80435%) mean:0.498319 min:0 max:0.993699 sd:0.27936\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:21 (5.70652%) mean:0.557501 min:0 max:1 sd:0.354909\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:21 (5.70652%) mean:0.654 min:0.0102696 max:1 sd:0.311552\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:21 (5.70652%) mean:0.428376 min:0 max:0.99189 sd:0.325134\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:25 (6.79348%) mean:0.413399 min:0 max:1 sd:0.321498\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:25 (6.79348%) mean:0.577377 min:0 max:1 sd:0.252582\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:25 (6.79348%) mean:0.333956 min:0 max:1 sd:0.278852\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.509622 min:0 max:1 sd:0.224066\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.504512 min:0 max:1 sd:0.236424\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:4 (1.08696%) mean:0.523575 min:0 max:1 sd:0.168169\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:21 (5.70652%) mean:0.475563 min:0 max:1 sd:0.179874\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:55 (14.9457%) mean:0.459071 min:0.0410427 max:1 sd:0.184783\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.524915 min:0 max:1 sd:0.195488\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:3 (0.815217%) mean:0.464899 min:0 max:1 sd:0.178658\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.463585 min:0 max:1 sd:0.190834\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:12 (3.26087%) mean:0.463492 min:0.0334198 max:1 sd:0.195731\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:19 (5.16304%) mean:0.435702 min:0.05674 max:1 sd:0.199841\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:65 (17.663%) mean:0.443027 min:0 max:1 sd:0.250922\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.574853 min:0 max:1 sd:0.168958\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:32 (8.69565%) mean:0.530443 min:0.0234328 max:1 sd:0.177625\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:70 (19.0217%) mean:0.488101 min:0 max:1 sd:0.190802\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:120 (32.6087%) mean:0.526337 min:0.0111018 max:1 sd:0.201783\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:136 (36.9565%) mean:0.545276 min:0 max:1 sd:0.189161\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:272 (73.913%) mean:0.449592 min:0 max:1 sd:0.212838\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:110 (29.8913%) mean:0.452248 min:0 max:1 sd:0.216169\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:124 (33.6957%) mean:0.459903 min:0 max:1 sd:0.20475\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:260 (70.6522%) mean:0.350282 min:0.00939159 max:1 sd:0.248394\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.00482481 min:4.38688e-06 max:0.107496 sd:0.0162353\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0451009 min:4.1493e-05 max:1 sd:0.150617\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.00493695 min:0 max:0.100884 sd:0.0154383\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:325 (88.3152%) mean:0.392581 min:0 max:0.891234 sd:0.214166\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.387708 min:0 max:0.896264 sd:0.216177\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.505134 min:0 max:0.911156 sd:0.183457\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0868423 min:0 max:0.531611 sd:0.139788\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.115745 min:0 max:0.974137 sd:0.212203\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.068221 min:0 max:0.426528 sd:0.105897\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.144002 min:0 max:1 sd:0.145117\n",
      "\t83: \"var_index\" NUMERICAL num-nas:116 (31.5217%) mean:0.0828661 min:0 max:1 sd:0.147404\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:32 (8.69565%) mean:0.769333 min:0 max:1 sd:0.269244\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:32 (8.69565%) mean:0.814814 min:0 max:1 sd:0.237869\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:32 (8.69565%) mean:0.026532 min:0 max:1 sd:0.0945034\n",
      "\t87: \"var_max\" NUMERICAL num-nas:116 (31.5217%) mean:0.0111909 min:0 max:1 sd:0.0655297\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:116 (31.5217%) mean:0.0460476 min:0 max:1 sd:0.110793\n",
      "\t89: \"var_min\" NUMERICAL num-nas:116 (31.5217%) mean:0.0369395 min:0 max:1 sd:0.0988533\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:116 (31.5217%) mean:0.429194 min:0 max:1 sd:0.174295\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:116 (31.5217%) mean:0.0081063 min:0 max:1 sd:0.0651261\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.911765 logloss:3.18032\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:12) done accuracy:0.882834 logloss:1.18328\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.896739 logloss:0.432427\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.896739 logloss:0.35262\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:39) done accuracy:0.907609 logloss:0.255822\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.915761 logloss:0.242279\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.915761 logloss:0.239937\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.929348 logloss:0.238004\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:83) done accuracy:0.921196 logloss:0.238333\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:92) done accuracy:0.918478 logloss:0.242007\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.913043 logloss:0.244786\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.913043 logloss:0.243321\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:119) done accuracy:0.915761 logloss:0.241352\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:127) done accuracy:0.92663 logloss:0.241305\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:139) done accuracy:0.923913 logloss:0.241671\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:147) done accuracy:0.92663 logloss:0.239692\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:161) done accuracy:0.918478 logloss:0.240964\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:169) done accuracy:0.918478 logloss:0.241607\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:178) done accuracy:0.918478 logloss:0.241884\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.910326 logloss:0.241995\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:199) done accuracy:0.904891 logloss:0.243467\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:208) done accuracy:0.904891 logloss:0.243282\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:220) done accuracy:0.902174 logloss:0.243579\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:231) done accuracy:0.902174 logloss:0.242231\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:241) done accuracy:0.899457 logloss:0.243248\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:249) done accuracy:0.896739 logloss:0.244596\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.902174 logloss:0.244419\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:272) done accuracy:0.907609 logloss:0.244059\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:279) done accuracy:0.904891 logloss:0.24471\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.904891 logloss:0.244895\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.904891 logloss:0.245187\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.904891 logloss:0.245187\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpncvdtiym\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 12982 node(s), and 91 input feature(s).\n",
      "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9918\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9239\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 94%|█████████▍| 30/32 [01:46<00:07,  3.88s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:319 (86.6848%) mean:0.0753006 min:0 max:0.451509 sd:0.116792\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0896445 min:0 max:0.510512 sd:0.135048\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0613688 min:0 max:0.388463 sd:0.100983\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:319 (86.6848%) mean:0.183339 min:0.00885266 max:1 sd:0.205173\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0263239 min:0.000428072 max:1 sd:0.140725\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.161401 min:0.00396921 max:1 sd:0.170987\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:319 (86.6848%) mean:0.06948 min:0 max:1 sd:0.17813\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0892126 min:0 max:1 sd:0.222522\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.101278 min:0 max:1 sd:0.206461\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:319 (86.6848%) mean:0.185404 min:0.0344311 max:1 sd:0.152689\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:319 (86.6848%) mean:0.0969269 min:0.000481551 max:1 sd:0.243281\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:323 (87.7717%) mean:0.136302 min:0.00182679 max:1 sd:0.203454\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0574491 min:0.000412191 max:1 sd:0.151004\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:319 (86.6848%) mean:0.0927773 min:5.72011e-11 max:1 sd:0.199672\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0973505 min:0 max:1 sd:0.214149\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:321 (87.2283%) mean:0.0869996 min:0 max:1 sd:0.187401\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:319 (86.6848%) mean:0.0833913 min:0.0140926 max:0.570059 sd:0.0785485\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.522283 min:0 max:1 sd:0.184886\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:32 (8.69565%) mean:0.485708 min:0 max:0.989319 sd:0.187929\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:68 (18.4783%) mean:0.469782 min:0 max:1 sd:0.188983\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.497053 min:0 max:1 sd:0.183082\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.504767 min:0 max:0.989925 sd:0.188085\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:13 (3.53261%) mean:0.491339 min:0 max:1 sd:0.189276\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:23 (6.25%) mean:0.439915 min:0 max:0.953386 sd:0.178355\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:24 (6.52174%) mean:0.440141 min:0 max:0.987476 sd:0.197793\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:89 (24.1848%) mean:0.406574 min:0 max:1 sd:0.191711\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:10 (2.71739%) mean:0.574858 min:0 max:1 sd:0.178066\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:43 (11.6848%) mean:0.525758 min:0 max:0.990984 sd:0.184127\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:80 (21.7391%) mean:0.509985 min:0 max:1 sd:0.190185\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:113 (30.7065%) mean:0.485538 min:0 max:0.955238 sd:0.195697\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:129 (35.0543%) mean:0.515859 min:0 max:0.99344 sd:0.198405\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:298 (80.9783%) mean:0.43118 min:0.020997 max:1 sd:0.197294\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:101 (27.4457%) mean:0.412534 min:0 max:0.947005 sd:0.199673\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:118 (32.0652%) mean:0.419658 min:0 max:0.988705 sd:0.216475\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:290 (78.8043%) mean:0.372847 min:0 max:1 sd:0.195067\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:319 (86.6848%) mean:0.178122 min:0 max:1 sd:0.247582\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.174501 min:0 max:1 sd:0.250593\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.166502 min:0 max:1 sd:0.233372\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:319 (86.6848%) mean:0.178863 min:0 max:0.988614 sd:0.241859\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.182839 min:0 max:0.992443 sd:0.244672\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.16999 min:0 max:1 sd:0.233106\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:319 (86.6848%) mean:0.172871 min:0 max:0.94107 sd:0.227198\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.175017 min:0 max:0.930383 sd:0.230921\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.163348 min:0 max:0.955403 sd:0.207405\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:17 (4.61957%) mean:0.619571 min:0 max:1 sd:0.319983\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:17 (4.61957%) mean:0.697271 min:0.0483153 max:1 sd:0.275118\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:17 (4.61957%) mean:0.479292 min:0 max:1 sd:0.279961\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:18 (4.8913%) mean:0.549931 min:0 max:1 sd:0.359768\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:18 (4.8913%) mean:0.648731 min:0.0102696 max:1 sd:0.312556\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:18 (4.8913%) mean:0.413398 min:0 max:1 sd:0.324042\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:25 (6.79348%) mean:0.415463 min:0 max:1 sd:0.320289\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:25 (6.79348%) mean:0.579465 min:0 max:1 sd:0.249931\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:25 (6.79348%) mean:0.339383 min:0 max:1 sd:0.281666\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.5061 min:0 max:1 sd:0.225494\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.514053 min:0.00905979 max:1 sd:0.233226\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:5 (1.3587%) mean:0.522121 min:0 max:0.957751 sd:0.17282\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:28 (7.6087%) mean:0.476175 min:0 max:0.951877 sd:0.180444\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:62 (16.8478%) mean:0.459107 min:0 max:1 sd:0.18709\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.522985 min:0 max:0.952412 sd:0.19858\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:6 (1.63043%) mean:0.460779 min:0 max:0.947944 sd:0.182379\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:3 (0.815217%) mean:0.457272 min:0 max:1 sd:0.195323\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:16 (4.34783%) mean:0.465823 min:0 max:1 sd:0.196855\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:17 (4.61957%) mean:0.433705 min:0 max:0.973811 sd:0.198314\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:60 (16.3043%) mean:0.438645 min:0 max:1 sd:0.2519\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.573505 min:0 max:0.965585 sd:0.171282\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:35 (9.51087%) mean:0.528476 min:0 max:0.961149 sd:0.179923\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:78 (21.1957%) mean:0.489984 min:0 max:1 sd:0.191213\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.522296 min:0 max:1 sd:0.206622\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:128 (34.7826%) mean:0.534882 min:0 max:0.983341 sd:0.190878\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:264 (71.7391%) mean:0.460744 min:0 max:1 sd:0.210965\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:106 (28.8043%) mean:0.450128 min:0 max:1 sd:0.217929\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:118 (32.0652%) mean:0.455505 min:0 max:0.975678 sd:0.200792\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:252 (68.4783%) mean:0.360994 min:0 max:1 sd:0.254855\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:319 (86.6848%) mean:0.024522 min:0 max:1 sd:0.14162\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0377837 min:0 max:1 sd:0.142825\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.0246595 min:0 max:1 sd:0.141518\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:319 (86.6848%) mean:0.380767 min:0 max:0.891234 sd:0.216412\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.370717 min:0 max:0.896264 sd:0.213293\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:319 (86.6848%) mean:0.499061 min:0 max:0.911156 sd:0.187543\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:319 (86.6848%) mean:0.0890369 min:0 max:1 sd:0.174818\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:319 (86.6848%) mean:0.111948 min:0 max:1 sd:0.22262\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:320 (86.9565%) mean:0.0743146 min:0.000337785 max:1 sd:0.159687\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:319 (86.6848%) mean:0.137662 min:0 max:1 sd:0.136039\n",
      "\t83: \"var_index\" NUMERICAL num-nas:114 (30.9783%) mean:0.0761939 min:0 max:1 sd:0.135644\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:29 (7.88043%) mean:0.758358 min:0 max:1 sd:0.271852\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:29 (7.88043%) mean:0.810272 min:0 max:1 sd:0.237018\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:29 (7.88043%) mean:0.0270865 min:0 max:1 sd:0.0962144\n",
      "\t87: \"var_max\" NUMERICAL num-nas:114 (30.9783%) mean:0.007737 min:0 max:0.233918 sd:0.0224724\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:114 (30.9783%) mean:0.0439135 min:0 max:0.623456 sd:0.098498\n",
      "\t89: \"var_min\" NUMERICAL num-nas:114 (30.9783%) mean:0.0372436 min:0 max:0.54179 sd:0.090669\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:114 (30.9783%) mean:0.422012 min:0 max:1 sd:0.171785\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:114 (30.9783%) mean:0.00430962 min:0 max:0.226755 sd:0.0197426\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:1) done accuracy:0.869231 logloss:4.7134\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.852861 logloss:1.5793\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:20) done accuracy:0.883152 logloss:0.633999\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:28) done accuracy:0.894022 logloss:0.254679\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:37) done accuracy:0.88587 logloss:0.260442\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:49) done accuracy:0.891304 logloss:0.258898\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:62) done accuracy:0.899457 logloss:0.259746\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.902174 logloss:0.255099\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:78) done accuracy:0.899457 logloss:0.25824\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.899457 logloss:0.261012\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.899457 logloss:0.259597\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.891304 logloss:0.25847\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:119) done accuracy:0.888587 logloss:0.254368\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:131) done accuracy:0.88587 logloss:0.253457\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.891304 logloss:0.254297\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.899457 logloss:0.251793\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:159) done accuracy:0.904891 logloss:0.253832\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.902174 logloss:0.25627\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.907609 logloss:0.255661\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:193) done accuracy:0.910326 logloss:0.2532\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.913043 logloss:0.253988\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.910326 logloss:0.252768\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.902174 logloss:0.252209\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:232) done accuracy:0.902174 logloss:0.254129\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:239) done accuracy:0.907609 logloss:0.254858\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.907609 logloss:0.25284\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:259) done accuracy:0.910326 logloss:0.253118\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.913043 logloss:0.251964\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.915761 logloss:0.250808\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:292) done accuracy:0.913043 logloss:0.248864\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.913043 logloss:0.249107\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.913043 logloss:0.249107\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmph14_40_y\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13006 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9973\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9565\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 97%|█████████▋| 31/32 [01:48<00:03,  3.60s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 6\n",
      "[INFO kernel.cc:393] Number of examples: 368\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 368\n",
      "Number of columns: 93\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 92 (98.9247%)\n",
      "\tCATEGORICAL: 1 (1.07527%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 92 (98.9247%)\n",
      "\t0: \"bb_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.106659 min:0 max:1 sd:0.182417\n",
      "\t1: \"bb_ampl_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.127306 min:0 max:1 sd:0.203837\n",
      "\t2: \"bb_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0878951 min:0 max:1 sd:0.169403\n",
      "\t3: \"bb_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.18728 min:0 max:1 sd:0.217406\n",
      "\t4: \"bb_kt_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0293184 min:0 max:1 sd:0.149978\n",
      "\t5: \"bb_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.162186 min:0 max:1 sd:0.180511\n",
      "\t6: \"bb_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.0892108 min:0 max:1 sd:0.198248\n",
      "\t7: \"bb_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.114535 min:1.82725e-05 max:1 sd:0.247564\n",
      "\t8: \"bb_nh_lolim\" NUMERICAL num-nas:341 (92.663%) mean:0.113667 min:0.00246435 max:1 sd:0.213566\n",
      "\t9: \"bb_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.177549 min:0 max:1 sd:0.160485\n",
      "\t10: \"brems_kt\" NUMERICAL num-nas:325 (88.3152%) mean:0.10316 min:0 max:1 sd:0.258656\n",
      "\t11: \"brems_kt_hilim\" NUMERICAL num-nas:329 (89.4022%) mean:0.129456 min:0 max:1 sd:0.210205\n",
      "\t12: \"brems_kt_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0580029 min:0 max:1 sd:0.160402\n",
      "\t13: \"brems_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.114013 min:0 max:1 sd:0.219631\n",
      "\t14: \"brems_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.122163 min:0 max:1 sd:0.235988\n",
      "\t15: \"brems_nh_lolim\" NUMERICAL num-nas:328 (89.1304%) mean:0.109192 min:0.000690433 max:1 sd:0.206638\n",
      "\t16: \"brems_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.107054 min:0 max:1 sd:0.161306\n",
      "\t17: \"flux_aper\" NUMERICAL mean:0.514207 min:0.0152442 max:1 sd:0.178728\n",
      "\t18: \"flux_aper_b\" NUMERICAL num-nas:26 (7.06522%) mean:0.475827 min:0 max:1 sd:0.184861\n",
      "\t19: \"flux_aper_h\" NUMERICAL num-nas:70 (19.0217%) mean:0.462043 min:0 max:1 sd:0.185942\n",
      "\t20: \"flux_aper_hilim\" NUMERICAL mean:0.489921 min:0.0995208 max:1 sd:0.180207\n",
      "\t21: \"flux_aper_hilim_b\" NUMERICAL num-nas:2 (0.543478%) mean:0.500704 min:0.0514989 max:1 sd:0.181705\n",
      "\t22: \"flux_aper_hilim_h\" NUMERICAL num-nas:11 (2.98913%) mean:0.484805 min:0.0266211 max:1 sd:0.185919\n",
      "\t23: \"flux_aper_hilim_m\" NUMERICAL num-nas:20 (5.43478%) mean:0.431344 min:0.0639947 max:1 sd:0.173957\n",
      "\t24: \"flux_aper_hilim_s\" NUMERICAL num-nas:23 (6.25%) mean:0.429659 min:0.0587585 max:1 sd:0.194457\n",
      "\t25: \"flux_aper_hilim_u\" NUMERICAL num-nas:90 (24.4565%) mean:0.400497 min:0 max:1 sd:0.197026\n",
      "\t26: \"flux_aper_lolim\" NUMERICAL num-nas:9 (2.44565%) mean:0.564883 min:0.0286664 max:1 sd:0.173534\n",
      "\t27: \"flux_aper_lolim_b\" NUMERICAL num-nas:37 (10.0543%) mean:0.513158 min:0 max:1 sd:0.181872\n",
      "\t28: \"flux_aper_lolim_h\" NUMERICAL num-nas:81 (22.0109%) mean:0.498881 min:0 max:1 sd:0.189192\n",
      "\t29: \"flux_aper_lolim_m\" NUMERICAL num-nas:115 (31.25%) mean:0.474101 min:0 max:1 sd:0.192571\n",
      "\t30: \"flux_aper_lolim_s\" NUMERICAL num-nas:133 (36.1413%) mean:0.504182 min:0 max:1 sd:0.195192\n",
      "\t31: \"flux_aper_lolim_u\" NUMERICAL num-nas:307 (83.4239%) mean:0.41786 min:0 max:1 sd:0.206748\n",
      "\t32: \"flux_aper_m\" NUMERICAL num-nas:104 (28.2609%) mean:0.402888 min:0 max:1 sd:0.195435\n",
      "\t33: \"flux_aper_s\" NUMERICAL num-nas:125 (33.9674%) mean:0.407476 min:0 max:1 sd:0.215276\n",
      "\t34: \"flux_aper_u\" NUMERICAL num-nas:299 (81.25%) mean:0.361764 min:0 max:1 sd:0.195807\n",
      "\t35: \"flux_bb\" NUMERICAL num-nas:325 (88.3152%) mean:0.184904 min:0 max:1 sd:0.256219\n",
      "\t36: \"flux_bb_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.182805 min:0 max:1 sd:0.261528\n",
      "\t37: \"flux_bb_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.170061 min:0 max:0.96449 sd:0.238184\n",
      "\t38: \"flux_brems\" NUMERICAL num-nas:325 (88.3152%) mean:0.184635 min:0 max:1 sd:0.255057\n",
      "\t39: \"flux_brems_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.189744 min:0 max:1 sd:0.259322\n",
      "\t40: \"flux_brems_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.174303 min:0 max:0.99507 sd:0.244343\n",
      "\t41: \"flux_powlaw\" NUMERICAL num-nas:325 (88.3152%) mean:0.180809 min:0 max:1 sd:0.242945\n",
      "\t42: \"flux_powlaw_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.184171 min:0 max:1 sd:0.248218\n",
      "\t43: \"flux_powlaw_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.169199 min:0 max:1 sd:0.22089\n",
      "\t44: \"hard_hm\" NUMERICAL num-nas:16 (4.34783%) mean:0.634024 min:0 max:1 sd:0.317277\n",
      "\t45: \"hard_hm_hilim\" NUMERICAL num-nas:16 (4.34783%) mean:0.710315 min:0 max:1 sd:0.274766\n",
      "\t46: \"hard_hm_lolim\" NUMERICAL num-nas:16 (4.34783%) mean:0.488835 min:0 max:1 sd:0.278141\n",
      "\t47: \"hard_hs\" NUMERICAL num-nas:20 (5.43478%) mean:0.55134 min:0 max:1 sd:0.360168\n",
      "\t48: \"hard_hs_hilim\" NUMERICAL num-nas:20 (5.43478%) mean:0.652886 min:0 max:1 sd:0.31305\n",
      "\t49: \"hard_hs_lolim\" NUMERICAL num-nas:20 (5.43478%) mean:0.418622 min:0 max:1 sd:0.324607\n",
      "\t50: \"hard_ms\" NUMERICAL num-nas:27 (7.33696%) mean:0.411291 min:0 max:1 sd:0.326018\n",
      "\t51: \"hard_ms_hilim\" NUMERICAL num-nas:27 (7.33696%) mean:0.58123 min:0.0466496 max:1 sd:0.255605\n",
      "\t52: \"hard_ms_lolim\" NUMERICAL num-nas:27 (7.33696%) mean:0.335028 min:0 max:0.985907 sd:0.284423\n",
      "\t53: \"kp_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.515365 min:0.0105506 max:1 sd:0.221962\n",
      "\t54: \"ks_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.516583 min:0 max:1 sd:0.240874\n",
      "\t55: \"photflux_aper\" NUMERICAL num-nas:6 (1.63043%) mean:0.513745 min:0.0816971 max:1 sd:0.166287\n",
      "\t56: \"photflux_aper_b\" NUMERICAL num-nas:25 (6.79348%) mean:0.464495 min:0 max:1 sd:0.1765\n",
      "\t57: \"photflux_aper_h\" NUMERICAL num-nas:61 (16.5761%) mean:0.447732 min:0 max:0.988268 sd:0.184808\n",
      "\t58: \"photflux_aper_hilim\" NUMERICAL mean:0.516843 min:0.0435796 max:1 sd:0.195373\n",
      "\t59: \"photflux_aper_hilim_b\" NUMERICAL num-nas:3 (0.815217%) mean:0.45256 min:0.0163507 max:1 sd:0.175543\n",
      "\t60: \"photflux_aper_hilim_h\" NUMERICAL num-nas:4 (1.08696%) mean:0.450441 min:0.00266063 max:0.989602 sd:0.191132\n",
      "\t61: \"photflux_aper_hilim_m\" NUMERICAL num-nas:14 (3.80435%) mean:0.453526 min:0 max:1 sd:0.190656\n",
      "\t62: \"photflux_aper_hilim_s\" NUMERICAL num-nas:18 (4.8913%) mean:0.425707 min:0.05674 max:1 sd:0.194702\n",
      "\t63: \"photflux_aper_hilim_u\" NUMERICAL num-nas:59 (16.0326%) mean:0.433608 min:0 max:1 sd:0.253934\n",
      "\t64: \"photflux_aper_lolim\" NUMERICAL num-nas:11 (2.98913%) mean:0.565404 min:0.024159 max:1 sd:0.165844\n",
      "\t65: \"photflux_aper_lolim_b\" NUMERICAL num-nas:35 (9.51087%) mean:0.519664 min:0.0234328 max:1 sd:0.173932\n",
      "\t66: \"photflux_aper_lolim_h\" NUMERICAL num-nas:77 (20.9239%) mean:0.475427 min:0 max:0.988906 sd:0.191461\n",
      "\t67: \"photflux_aper_lolim_m\" NUMERICAL num-nas:118 (32.0652%) mean:0.507181 min:0 max:1 sd:0.200802\n",
      "\t68: \"photflux_aper_lolim_s\" NUMERICAL num-nas:134 (36.413%) mean:0.526774 min:0.00422152 max:1 sd:0.186387\n",
      "\t69: \"photflux_aper_lolim_u\" NUMERICAL num-nas:270 (73.3696%) mean:0.436751 min:0 max:0.971545 sd:0.208116\n",
      "\t70: \"photflux_aper_m\" NUMERICAL num-nas:109 (29.6196%) mean:0.43497 min:0 max:1 sd:0.210918\n",
      "\t71: \"photflux_aper_s\" NUMERICAL num-nas:123 (33.4239%) mean:0.442725 min:0.00566975 max:1 sd:0.200571\n",
      "\t72: \"photflux_aper_u\" NUMERICAL num-nas:256 (69.5652%) mean:0.339907 min:0 max:1 sd:0.253976\n",
      "\t73: \"powlaw_ampl\" NUMERICAL num-nas:325 (88.3152%) mean:0.0277182 min:0 max:1 sd:0.150889\n",
      "\t74: \"powlaw_ampl_hilim\" NUMERICAL num-nas:326 (88.587%) mean:0.043658 min:0 max:1 sd:0.151911\n",
      "\t75: \"powlaw_ampl_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.0277407 min:0 max:1 sd:0.150793\n",
      "\t76: \"powlaw_gamma\" NUMERICAL num-nas:325 (88.3152%) mean:0.401659 min:0 max:1 sd:0.23011\n",
      "\t77: \"powlaw_gamma_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.397248 min:0 max:1 sd:0.22686\n",
      "\t78: \"powlaw_gamma_lolim\" NUMERICAL num-nas:325 (88.3152%) mean:0.511675 min:0 max:1 sd:0.199452\n",
      "\t79: \"powlaw_nh\" NUMERICAL num-nas:325 (88.3152%) mean:0.109302 min:0 max:1 sd:0.19551\n",
      "\t80: \"powlaw_nh_hilim\" NUMERICAL num-nas:325 (88.3152%) mean:0.138958 min:0 max:1 sd:0.249633\n",
      "\t81: \"powlaw_nh_lolim\" NUMERICAL num-nas:326 (88.587%) mean:0.0905604 min:0 max:1 sd:0.176704\n",
      "\t82: \"powlaw_stat\" NUMERICAL num-nas:325 (88.3152%) mean:0.145698 min:0 max:1 sd:0.147919\n",
      "\t83: \"var_index\" NUMERICAL num-nas:120 (32.6087%) mean:0.0755683 min:0 max:0.978261 sd:0.122436\n",
      "\t84: \"var_inter_index\" NUMERICAL num-nas:35 (9.51087%) mean:0.754148 min:0 max:1 sd:0.274238\n",
      "\t85: \"var_inter_prob\" NUMERICAL num-nas:35 (9.51087%) mean:0.806018 min:0 max:1 sd:0.236593\n",
      "\t86: \"var_inter_sigma\" NUMERICAL num-nas:35 (9.51087%) mean:0.025999 min:0 max:1 sd:0.0942444\n",
      "\t87: \"var_max\" NUMERICAL num-nas:120 (32.6087%) mean:0.0114017 min:0 max:1 sd:0.0669013\n",
      "\t88: \"var_mean\" NUMERICAL num-nas:120 (32.6087%) mean:0.0444697 min:0 max:1 sd:0.113065\n",
      "\t89: \"var_min\" NUMERICAL num-nas:120 (32.6087%) mean:0.0372497 min:0 max:1 sd:0.104619\n",
      "\t90: \"var_prob\" NUMERICAL num-nas:120 (32.6087%) mean:0.427703 min:0 max:0.99369 sd:0.163904\n",
      "\t91: \"var_sigma\" NUMERICAL num-nas:120 (32.6087%) mean:0.0077953 min:0 max:1 sd:0.0657995\n",
      "\n",
      "CATEGORICAL: 1 (1.07527%)\n",
      "\t92: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bb_ampl\"\n",
      "features: \"bb_ampl_hilim\"\n",
      "features: \"bb_ampl_lolim\"\n",
      "features: \"bb_kt\"\n",
      "features: \"bb_kt_hilim\"\n",
      "features: \"bb_kt_lolim\"\n",
      "features: \"bb_nh\"\n",
      "features: \"bb_nh_hilim\"\n",
      "features: \"bb_nh_lolim\"\n",
      "features: \"bb_stat\"\n",
      "features: \"brems_kt\"\n",
      "features: \"brems_kt_hilim\"\n",
      "features: \"brems_kt_lolim\"\n",
      "features: \"brems_nh\"\n",
      "features: \"brems_nh_hilim\"\n",
      "features: \"brems_nh_lolim\"\n",
      "features: \"brems_stat\"\n",
      "features: \"flux_aper\"\n",
      "features: \"flux_aper_b\"\n",
      "features: \"flux_aper_h\"\n",
      "features: \"flux_aper_hilim\"\n",
      "features: \"flux_aper_hilim_b\"\n",
      "features: \"flux_aper_hilim_h\"\n",
      "features: \"flux_aper_hilim_m\"\n",
      "features: \"flux_aper_hilim_s\"\n",
      "features: \"flux_aper_hilim_u\"\n",
      "features: \"flux_aper_lolim\"\n",
      "features: \"flux_aper_lolim_b\"\n",
      "features: \"flux_aper_lolim_h\"\n",
      "features: \"flux_aper_lolim_m\"\n",
      "features: \"flux_aper_lolim_s\"\n",
      "features: \"flux_aper_lolim_u\"\n",
      "features: \"flux_aper_m\"\n",
      "features: \"flux_aper_s\"\n",
      "features: \"flux_aper_u\"\n",
      "features: \"flux_bb\"\n",
      "features: \"flux_bb_hilim\"\n",
      "features: \"flux_bb_lolim\"\n",
      "features: \"flux_brems\"\n",
      "features: \"flux_brems_hilim\"\n",
      "features: \"flux_brems_lolim\"\n",
      "features: \"flux_powlaw\"\n",
      "features: \"flux_powlaw_hilim\"\n",
      "features: \"flux_powlaw_lolim\"\n",
      "features: \"hard_hm\"\n",
      "features: \"hard_hm_hilim\"\n",
      "features: \"hard_hm_lolim\"\n",
      "features: \"hard_hs\"\n",
      "features: \"hard_hs_hilim\"\n",
      "features: \"hard_hs_lolim\"\n",
      "features: \"hard_ms\"\n",
      "features: \"hard_ms_hilim\"\n",
      "features: \"hard_ms_lolim\"\n",
      "features: \"kp_prob\"\n",
      "features: \"ks_prob\"\n",
      "features: \"photflux_aper\"\n",
      "features: \"photflux_aper_b\"\n",
      "features: \"photflux_aper_h\"\n",
      "features: \"photflux_aper_hilim\"\n",
      "features: \"photflux_aper_hilim_b\"\n",
      "features: \"photflux_aper_hilim_h\"\n",
      "features: \"photflux_aper_hilim_m\"\n",
      "features: \"photflux_aper_hilim_s\"\n",
      "features: \"photflux_aper_hilim_u\"\n",
      "features: \"photflux_aper_lolim\"\n",
      "features: \"photflux_aper_lolim_b\"\n",
      "features: \"photflux_aper_lolim_h\"\n",
      "features: \"photflux_aper_lolim_m\"\n",
      "features: \"photflux_aper_lolim_s\"\n",
      "features: \"photflux_aper_lolim_u\"\n",
      "features: \"photflux_aper_m\"\n",
      "features: \"photflux_aper_s\"\n",
      "features: \"photflux_aper_u\"\n",
      "features: \"powlaw_ampl\"\n",
      "features: \"powlaw_ampl_hilim\"\n",
      "features: \"powlaw_ampl_lolim\"\n",
      "features: \"powlaw_gamma\"\n",
      "features: \"powlaw_gamma_hilim\"\n",
      "features: \"powlaw_gamma_lolim\"\n",
      "features: \"powlaw_nh\"\n",
      "features: \"powlaw_nh_hilim\"\n",
      "features: \"powlaw_nh_lolim\"\n",
      "features: \"powlaw_stat\"\n",
      "features: \"var_index\"\n",
      "features: \"var_inter_index\"\n",
      "features: \"var_inter_prob\"\n",
      "features: \"var_inter_sigma\"\n",
      "features: \"var_max\"\n",
      "features: \"var_mean\"\n",
      "features: \"var_min\"\n",
      "features: \"var_prob\"\n",
      "features: \"var_sigma\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "num_threads: 6\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 368 example(s) and 92 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:3) done accuracy:0.865079 logloss:4.86303\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done accuracy:0.861413 logloss:1.48433\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.883152 logloss:0.451804\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:29) done accuracy:0.902174 logloss:0.353646\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:35) done accuracy:0.891304 logloss:0.260735\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:50) done accuracy:0.907609 logloss:0.258836\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:58) done accuracy:0.899457 logloss:0.259564\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:72) done accuracy:0.902174 logloss:0.261657\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:81) done accuracy:0.910326 logloss:0.259344\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.907609 logloss:0.260795\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:99) done accuracy:0.904891 logloss:0.259453\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.902174 logloss:0.259881\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:121) done accuracy:0.899457 logloss:0.256176\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.910326 logloss:0.255936\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:141) done accuracy:0.894022 logloss:0.259462\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.902174 logloss:0.252727\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.902174 logloss:0.252685\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:169) done accuracy:0.907609 logloss:0.255077\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:185) done accuracy:0.907609 logloss:0.256837\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:190) done accuracy:0.910326 logloss:0.257188\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:199) done accuracy:0.910326 logloss:0.25915\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.907609 logloss:0.258983\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:219) done accuracy:0.904891 logloss:0.258162\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:233) done accuracy:0.904891 logloss:0.256558\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:238) done accuracy:0.904891 logloss:0.257355\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:249) done accuracy:0.904891 logloss:0.25878\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:258) done accuracy:0.907609 logloss:0.258091\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:271) done accuracy:0.902174 logloss:0.258301\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.907609 logloss:0.255935\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.904891 logloss:0.255266\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:283) done accuracy:0.904891 logloss:0.254521\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.904891 logloss:0.254521\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp0mcfeocj\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:988] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 13052 node(s), and 92 input feature(s).\n",
      "[INFO kernel.cc:848] Use fast generic engine\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9946\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.9239\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 32/32 [01:52<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "acc_norm_nan_rf.to_csv('result/acc_rf_norm_no_impute')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "acc_norm_rf = mc_validation(gen_model_rf , data_norm , obs_split ,model_name = 'RF' , d_type='Normalized')\n",
    "acc_std_rf = mc_validation(gen_model_rf , data_std , obs_split, model_name = 'RF' , d_type = 'Standardized')\n",
    "acc_og_rf = mc_validation(gen_model_rf , data_og  , obs_split ,  model_name = 'RF' , d_type = 'None')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "acc_data_rf = pd.concat([acc_norm_rf , acc_std_rf ,  acc_og_rf]).reset_index(drop=True)\n",
    "display(acc_data_rf)\n",
    "acc_data_rf.to_csv('result/acc_rf_all_zero')\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "    model data_processing   acc_type  accuracy\n",
       "0      RF      Normalized  Train_acc  0.994565\n",
       "1      RF      Normalized  Train_acc  0.991848\n",
       "2      RF      Normalized  Train_acc  0.994565\n",
       "3      RF      Normalized  Train_acc  0.991848\n",
       "4      RF      Normalized  Train_acc  0.991848\n",
       "..    ...             ...        ...       ...\n",
       "187    RF            None   Test_acc  0.902174\n",
       "188    RF            None   Test_acc  0.923913\n",
       "189    RF            None   Test_acc  0.891304\n",
       "190    RF            None   Test_acc  0.869565\n",
       "191    RF            None   Test_acc  0.869565\n",
       "\n",
       "[192 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_processing</th>\n",
       "      <th>acc_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.994565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.994565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>RF</td>\n",
       "      <td>None</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>RF</td>\n",
       "      <td>None</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>RF</td>\n",
       "      <td>None</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>RF</td>\n",
       "      <td>None</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>RF</td>\n",
       "      <td>None</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import seaborn as sns \n",
    "acc_prev =  pd.read_csv('result/acc_cnn_fc_all_zero').reset_index(drop=True)\n",
    "acc_prev_rf =  pd.read_csv('result/acc_rf_all_zero').reset_index(drop=True)\n",
    "acc_all = pd.concat([acc_prev ,  acc_prev_rf]).reset_index(drop=True)\n",
    "sns.set_style('whitegrid')\n",
    "sns.catplot(data = acc_all , y='accuracy' , x = 'data_processing' ,\n",
    "            hue= 'acc_type'  , kind='box' ,  col ='model' , \n",
    "            palette = 'crest' , height=6 , aspect=8/6\n",
    "            )\n",
    "plt.savefig('result/model_var_rf.jpg')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1810.12x432 with 3 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"423.126562pt\" version=\"1.1\" viewBox=\"0 0 1805.849967 423.126562\" width=\"1805.849967pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-10-11T00:18:57.014204</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 423.126562 \nL 1805.849967 423.126562 \nL 1805.849967 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 385.292187 \nL 594.079801 385.292187 \nL 594.079801 20.798437 \nL 50.14375 20.798437 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"text_1\">\n      <!-- Normalized -->\n      <g style=\"fill:#262626;\" transform=\"translate(112.44429 399.890625)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n        <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n        <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n        <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n        <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n        <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n        <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n        <path d=\"M 5.515625 54.6875 \nL 48.1875 54.6875 \nL 48.1875 46.484375 \nL 14.40625 7.171875 \nL 48.1875 7.171875 \nL 48.1875 0 \nL 4.296875 0 \nL 4.296875 8.203125 \nL 38.09375 47.515625 \nL 5.515625 47.515625 \nz\n\" id=\"DejaVuSans-122\"/>\n        <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n        <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"175.349609\" xlink:href=\"#DejaVuSans-109\"/>\n       <use x=\"272.761719\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"334.041016\" xlink:href=\"#DejaVuSans-108\"/>\n       <use x=\"361.824219\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"389.607422\" xlink:href=\"#DejaVuSans-122\"/>\n       <use x=\"442.097656\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"503.621094\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"text_2\">\n      <!-- Standardized -->\n      <g style=\"fill:#262626;\" transform=\"translate(289.100057 399.890625)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n        <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n        <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-83\"/>\n       <use x=\"63.476562\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"102.685547\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"163.964844\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"227.34375\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"290.820312\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"352.099609\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"391.462891\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"454.939453\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"482.722656\" xlink:href=\"#DejaVuSans-122\"/>\n       <use x=\"535.212891\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"596.736328\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"text_3\">\n      <!-- None -->\n      <g style=\"fill:#262626;\" transform=\"translate(490.37848 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"199.365234\" xlink:href=\"#DejaVuSans-101\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_4\">\n     <!-- data_processing -->\n     <g style=\"fill:#262626;\" transform=\"translate(281.405526 413.56875)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"124.755859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"163.964844\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"225.244141\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"275.244141\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"338.720703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"377.583984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"438.765625\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"493.746094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"555.269531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"607.369141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"659.46875\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"687.251953\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"750.630859\" xlink:href=\"#DejaVuSans-103\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 376.087777 \nL 594.079801 376.087777 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.60 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 379.886996)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 333.747597 \nL 594.079801 333.747597 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.65 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 337.546816)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 291.407417 \nL 594.079801 291.407417 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.70 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 295.206636)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 249.067237 \nL 594.079801 249.067237 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.75 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 252.866455)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 206.727056 \nL 594.079801 206.727056 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.80 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 210.526275)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 164.386876 \nL 594.079801 164.386876 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.85 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 168.186095)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 122.046696 \nL 594.079801 122.046696 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.90 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 125.845915)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 79.706516 \nL 594.079801 79.706516 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.95 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 83.505734)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 50.14375 37.366335 \nL 594.079801 37.366335 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.00 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 41.165554)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- accuracy -->\n     <g style=\"fill:#262626;\" transform=\"translate(14.798438 225.604687)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 69.0002 89.141019 \nL 140.07451 89.141019 \nL 140.07451 60.377323 \nL 69.0002 60.377323 \nL 69.0002 89.141019 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 141.525007 166.227773 \nL 212.599317 166.227773 \nL 212.599317 138.614568 \nL 141.525007 138.614568 \nL 141.525007 166.227773 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 250.312217 62.678406 \nL 321.386528 62.678406 \nL 321.386528 48.871804 \nL 250.312217 48.871804 \nL 250.312217 62.678406 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 322.837024 186.937639 \nL 393.911334 186.937639 \nL 393.911334 154.722292 \nL 322.837024 154.722292 \nL 322.837024 186.937639 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 431.624234 242.739206 \nL 502.698545 242.739206 \nL 502.698545 207.64748 \nL 431.624234 207.64748 \nL 431.624234 242.739206 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 504.149041 288.185872 \nL 575.223351 288.185872 \nL 575.223351 246.76614 \nL 504.149041 246.76614 \nL 504.149041 288.185872 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 140.799759 884.169941 \nL 140.799759 884.169941 \nL 140.799759 884.169941 \nL 140.799759 884.169941 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 140.799759 884.169941 \nL 140.799759 884.169941 \nL 140.799759 884.169941 \nL 140.799759 884.169941 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"line2d_10\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 104.537355 89.141019 \nL 104.537355 104.098163 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 104.537355 60.377323 \nL 104.537355 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 86.768777 104.098163 \nL 122.305933 104.098163 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 86.768777 41.968553 \nL 122.305933 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\"/>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 177.062162 166.227773 \nL 177.062162 193.840928 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 177.062162 138.614568 \nL 177.062162 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 159.293584 193.840928 \nL 194.83074 193.840928 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 159.293584 111.001414 \nL 194.83074 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\"/>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 285.849372 62.678406 \nL 285.849372 83.388259 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 285.849372 48.871804 \nL 285.849372 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 268.080795 83.388259 \nL 303.61795 83.388259 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 268.080795 41.968553 \nL 303.61795 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_24\"/>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 358.374179 186.937639 \nL 358.374179 221.454082 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 358.374179 154.722292 \nL 358.374179 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 340.605601 221.454082 \nL 376.142757 221.454082 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 340.605601 111.001414 \nL 376.142757 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <defs>\n     <path d=\"M -0 3.535534 \nL 2.12132 0 \nL -0 -3.535534 \nL -2.12132 -0 \nz\n\" id=\"m4351f6c29f\" style=\"stroke:#323232;stroke-linejoin:miter;\"/>\n    </defs>\n    <g clip-path=\"url(#pcc1cc20a31)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"358.374179\" xlink:href=\"#m4351f6c29f\" y=\"276.680391\"/>\n    </g>\n   </g>\n   <g id=\"line2d_30\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 467.161389 242.739206 \nL 467.161389 269.77709 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 467.161389 207.64748 \nL 467.161389 170.82994 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 449.392812 269.77709 \nL 484.929967 269.77709 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 449.392812 170.82994 \nL 484.929967 170.82994 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_34\"/>\n   <g id=\"line2d_35\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 539.686196 288.185872 \nL 539.686196 331.9067 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 539.686196 246.76614 \nL 539.686196 184.636543 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 521.917618 331.9067 \nL 557.454774 331.9067 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 521.917618 184.636543 \nL 557.454774 184.636543 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <g clip-path=\"url(#pcc1cc20a31)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"539.686196\" xlink:href=\"#m4351f6c29f\" y=\"368.72429\"/>\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"539.686196\" xlink:href=\"#m4351f6c29f\" y=\"359.519905\"/>\n    </g>\n   </g>\n   <g id=\"line2d_40\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 69.0002 67.280573 \nL 140.07451 67.280573 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 141.525007 152.421196 \nL 212.599317 152.421196 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 250.312217 56.925647 \nL 321.386528 56.925647 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 322.837024 175.432158 \nL 393.911334 175.432158 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 431.624234 226.056275 \nL 502.698545 226.056275 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path clip-path=\"url(#pcc1cc20a31)\" d=\"M 504.149041 267.476006 \nL 575.223351 267.476006 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 50.14375 385.292187 \nL 50.14375 20.798437 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 50.14375 385.292187 \nL 594.079801 385.292187 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- model = CNN -->\n    <g style=\"fill:#262626;\" transform=\"translate(288.201619 14.798437)scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"426.953125\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"458.740234\" xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"528.564453\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"603.369141\" xlink:href=\"#DejaVuSans-78\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_13\">\n    <path d=\"M 604.815708 385.292187 \nL 1148.751759 385.292187 \nL 1148.751759 20.798437 \nL 604.815708 20.798437 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_4\">\n     <g id=\"text_16\">\n      <!-- Normalized -->\n      <g style=\"fill:#262626;\" transform=\"translate(667.116248 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"175.349609\" xlink:href=\"#DejaVuSans-109\"/>\n       <use x=\"272.761719\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"334.041016\" xlink:href=\"#DejaVuSans-108\"/>\n       <use x=\"361.824219\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"389.607422\" xlink:href=\"#DejaVuSans-122\"/>\n       <use x=\"442.097656\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"503.621094\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"text_17\">\n      <!-- Standardized -->\n      <g style=\"fill:#262626;\" transform=\"translate(843.772015 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-83\"/>\n       <use x=\"63.476562\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"102.685547\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"163.964844\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"227.34375\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"290.820312\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"352.099609\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"391.462891\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"454.939453\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"482.722656\" xlink:href=\"#DejaVuSans-122\"/>\n       <use x=\"535.212891\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"596.736328\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"text_18\">\n      <!-- None -->\n      <g style=\"fill:#262626;\" transform=\"translate(1045.050438 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"199.365234\" xlink:href=\"#DejaVuSans-101\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- data_processing -->\n     <g style=\"fill:#262626;\" transform=\"translate(836.077484 413.56875)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"124.755859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"163.964844\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"225.244141\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"275.244141\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"338.720703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"377.583984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"438.765625\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"493.746094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"555.269531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"607.369141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"659.46875\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"687.251953\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"750.630859\" xlink:href=\"#DejaVuSans-103\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_10\">\n     <g id=\"line2d_46\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 376.087777 \nL 1148.751759 376.087777 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_47\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 333.747597 \nL 1148.751759 333.747597 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_48\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 291.407417 \nL 1148.751759 291.407417 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_49\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 249.067237 \nL 1148.751759 249.067237 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_50\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 206.727056 \nL 1148.751759 206.727056 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"line2d_51\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 164.386876 \nL 1148.751759 164.386876 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_52\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 122.046696 \nL 1148.751759 122.046696 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_17\">\n     <g id=\"line2d_53\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 79.706516 \nL 1148.751759 79.706516 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_54\">\n      <path clip-path=\"url(#p00149dcdd1)\" d=\"M 604.815708 37.366335 \nL 1148.751759 37.366335 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 623.672158 58.651472 \nL 694.746469 58.651472 \nL 694.746469 51.172938 \nL 623.672158 51.172938 \nL 623.672158 58.651472 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 696.196965 177.733254 \nL 767.271275 177.733254 \nL 767.271275 147.819004 \nL 696.196965 147.819004 \nL 696.196965 177.733254 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 804.984175 37.366335 \nL 876.058486 37.366335 \nL 876.058486 37.366335 \nL 804.984175 37.366335 \nL 804.984175 37.366335 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 877.508982 157.023388 \nL 948.583292 157.023388 \nL 948.583292 127.109087 \nL 877.508982 127.109087 \nL 877.508982 157.023388 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 986.296192 97.194862 \nL 1057.370503 97.194862 \nL 1057.370503 71.30752 \nL 986.296192 71.30752 \nL 986.296192 97.194862 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1058.820999 232.959563 \nL 1129.89531 232.959563 \nL 1129.89531 193.840928 \nL 1058.820999 193.840928 \nL 1058.820999 232.959563 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 695.471717 884.169941 \nL 695.471717 884.169941 \nL 695.471717 884.169941 \nL 695.471717 884.169941 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 695.471717 884.169941 \nL 695.471717 884.169941 \nL 695.471717 884.169941 \nL 695.471717 884.169941 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 659.209313 58.651472 \nL 659.209313 67.280573 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 659.209313 51.172938 \nL 659.209313 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 641.440736 67.280573 \nL 676.977891 67.280573 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 641.440736 41.968553 \nL 676.977891 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <g clip-path=\"url(#p00149dcdd1)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"659.209313\" xlink:href=\"#m4351f6c29f\" y=\"81.087176\"/>\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"659.209313\" xlink:href=\"#m4351f6c29f\" y=\"71.882791\"/>\n    </g>\n   </g>\n   <g id=\"line2d_60\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 731.73412 177.733254 \nL 731.73412 212.249697 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 731.73412 147.819004 \nL 731.73412 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 713.965542 212.249697 \nL 749.502698 212.249697 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 713.965542 111.001414 \nL 749.502698 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_64\"/>\n   <g id=\"line2d_65\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 840.52133 37.366335 \nL 840.52133 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 840.52133 37.366335 \nL 840.52133 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 822.752753 37.366335 \nL 858.289908 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 822.752753 37.366335 \nL 858.289908 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <g clip-path=\"url(#p00149dcdd1)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"840.52133\" xlink:href=\"#m4351f6c29f\" y=\"39.667419\"/>\n    </g>\n   </g>\n   <g id=\"line2d_70\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 913.046137 157.023388 \nL 913.046137 193.840928 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 913.046137 127.109087 \nL 913.046137 83.388259 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 895.277559 193.840928 \nL 930.814715 193.840928 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 895.277559 83.388259 \nL 930.814715 83.388259 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_74\"/>\n   <g id=\"line2d_75\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1021.833347 97.194862 \nL 1021.833347 129.410183 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1021.833347 71.30752 \nL 1021.833347 60.377323 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1004.06477 129.410183 \nL 1039.601925 129.410183 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1004.06477 60.377323 \nL 1039.601925 60.377323 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_79\"/>\n   <g id=\"line2d_80\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1094.358154 232.959563 \nL 1094.358154 285.884776 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1094.358154 193.840928 \nL 1094.358154 147.819004 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1076.589577 285.884776 \nL 1112.126732 285.884776 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1076.589577 147.819004 \nL 1112.126732 147.819004 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_84\"/>\n   <g id=\"line2d_85\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 623.672158 53.474021 \nL 694.746469 53.474021 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 696.196965 166.227773 \nL 767.271275 166.227773 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 804.984175 37.366335 \nL 876.058486 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 877.508982 138.614568 \nL 948.583292 138.614568 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 986.296192 86.83991 \nL 1057.370503 86.83991 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path clip-path=\"url(#p00149dcdd1)\" d=\"M 1058.820999 212.249697 \nL 1129.89531 212.249697 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 604.815708 385.292187 \nL 604.815708 20.798437 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 604.815708 385.292187 \nL 1148.751759 385.292187 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- model = FC -->\n    <g style=\"fill:#262626;\" transform=\"translate(847.479046 14.798437)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 51.703125 72.90625 \nL 51.703125 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.109375 \nL 48.578125 43.109375 \nL 48.578125 34.8125 \nL 19.671875 34.8125 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-70\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"426.953125\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"458.740234\" xlink:href=\"#DejaVuSans-70\"/>\n     <use x=\"516.259766\" xlink:href=\"#DejaVuSans-67\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_24\">\n    <path d=\"M 1159.487666 385.292187 \nL 1703.423717 385.292187 \nL 1703.423717 20.798437 \nL 1159.487666 20.798437 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_7\">\n     <g id=\"text_21\">\n      <!-- Normalized -->\n      <g style=\"fill:#262626;\" transform=\"translate(1221.788206 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"175.349609\" xlink:href=\"#DejaVuSans-109\"/>\n       <use x=\"272.761719\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"334.041016\" xlink:href=\"#DejaVuSans-108\"/>\n       <use x=\"361.824219\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"389.607422\" xlink:href=\"#DejaVuSans-122\"/>\n       <use x=\"442.097656\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"503.621094\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"text_22\">\n      <!-- Standardized -->\n      <g style=\"fill:#262626;\" transform=\"translate(1398.443973 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-83\"/>\n       <use x=\"63.476562\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"102.685547\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"163.964844\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"227.34375\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"290.820312\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"352.099609\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"391.462891\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"454.939453\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"482.722656\" xlink:href=\"#DejaVuSans-122\"/>\n       <use x=\"535.212891\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"596.736328\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"text_23\">\n      <!-- None -->\n      <g style=\"fill:#262626;\" transform=\"translate(1599.722396 399.890625)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"199.365234\" xlink:href=\"#DejaVuSans-101\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_24\">\n     <!-- data_processing -->\n     <g style=\"fill:#262626;\" transform=\"translate(1390.749442 413.56875)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"124.755859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"163.964844\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"225.244141\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"275.244141\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"338.720703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"377.583984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"438.765625\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"493.746094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"555.269531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"607.369141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"659.46875\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"687.251953\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"750.630859\" xlink:href=\"#DejaVuSans-103\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_19\">\n     <g id=\"line2d_91\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 376.087777 \nL 1703.423717 376.087777 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_20\">\n     <g id=\"line2d_92\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 333.747597 \nL 1703.423717 333.747597 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_21\">\n     <g id=\"line2d_93\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 291.407417 \nL 1703.423717 291.407417 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_22\">\n     <g id=\"line2d_94\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 249.067237 \nL 1703.423717 249.067237 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_23\">\n     <g id=\"line2d_95\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 206.727056 \nL 1703.423717 206.727056 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_24\">\n     <g id=\"line2d_96\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 164.386876 \nL 1703.423717 164.386876 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_25\">\n     <g id=\"line2d_97\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 122.046696 \nL 1703.423717 122.046696 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_26\">\n     <g id=\"line2d_98\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 79.706516 \nL 1703.423717 79.706516 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n    <g id=\"ytick_27\">\n     <g id=\"line2d_99\">\n      <path clip-path=\"url(#p1357368455)\" d=\"M 1159.487666 37.366335 \nL 1703.423717 37.366335 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1178.344116 44.269636 \nL 1249.418427 44.269636 \nL 1249.418427 41.968553 \nL 1178.344116 41.968553 \nL 1178.344116 44.269636 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1250.868923 129.410183 \nL 1321.943234 129.410183 \nL 1321.943234 90.291548 \nL 1250.868923 90.291548 \nL 1250.868923 129.410183 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1359.656133 42.543824 \nL 1430.730444 42.543824 \nL 1430.730444 39.667419 \nL 1359.656133 39.667419 \nL 1359.656133 42.543824 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1432.18094 129.410183 \nL 1503.255251 129.410183 \nL 1503.255251 92.592644 \nL 1432.18094 92.592644 \nL 1432.18094 129.410183 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1540.96815 41.968553 \nL 1612.042461 41.968553 \nL 1612.042461 39.667419 \nL 1540.96815 39.667419 \nL 1540.96815 41.968553 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1613.492957 129.410183 \nL 1684.567268 129.410183 \nL 1684.567268 101.797029 \nL 1613.492957 101.797029 \nL 1613.492957 129.410183 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1250.143675 884.169941 \nL 1250.143675 884.169941 \nL 1250.143675 884.169941 \nL 1250.143675 884.169941 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1250.143675 884.169941 \nL 1250.143675 884.169941 \nL 1250.143675 884.169941 \nL 1250.143675 884.169941 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1213.881271 44.269636 \nL 1213.881271 46.57072 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1213.881271 41.968553 \nL 1213.881271 39.667419 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1196.112694 46.57072 \nL 1231.649849 46.57072 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1196.112694 39.667419 \nL 1231.649849 39.667419 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <g clip-path=\"url(#p1357368455)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"1213.881271\" xlink:href=\"#m4351f6c29f\" y=\"37.366335\"/>\n    </g>\n   </g>\n   <g id=\"line2d_105\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1286.406078 129.410183 \nL 1286.406078 184.636543 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1286.406078 90.291548 \nL 1286.406078 64.97949 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1268.637501 184.636543 \nL 1304.174656 184.636543 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1268.637501 64.97949 \nL 1304.174656 64.97949 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_109\"/>\n   <g id=\"line2d_110\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1395.193288 42.543824 \nL 1395.193288 46.57072 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1395.193288 39.667419 \nL 1395.193288 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1377.424711 46.57072 \nL 1412.961866 46.57072 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1377.424711 37.366335 \nL 1412.961866 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_114\"/>\n   <g id=\"line2d_115\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1467.718095 129.410183 \nL 1467.718095 175.432158 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1467.718095 92.592644 \nL 1467.718095 74.183875 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1449.949518 175.432158 \nL 1485.486673 175.432158 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1449.949518 74.183875 \nL 1485.486673 74.183875 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <g clip-path=\"url(#p1357368455)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"1467.718095\" xlink:href=\"#m4351f6c29f\" y=\"184.636543\"/>\n    </g>\n   </g>\n   <g id=\"line2d_120\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1576.505306 41.968553 \nL 1576.505306 44.269636 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1576.505306 39.667419 \nL 1576.505306 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1558.736728 44.269636 \nL 1594.273883 44.269636 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1558.736728 37.366335 \nL 1594.273883 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <g clip-path=\"url(#p1357368455)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"1576.505306\" xlink:href=\"#m4351f6c29f\" y=\"48.871804\"/>\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"1576.505306\" xlink:href=\"#m4351f6c29f\" y=\"46.57072\"/>\n    </g>\n   </g>\n   <g id=\"line2d_125\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1649.030112 129.410183 \nL 1649.030112 147.819004 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1649.030112 101.797029 \nL 1649.030112 64.97949 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_127\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1631.261535 147.819004 \nL 1666.79869 147.819004 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_128\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1631.261535 64.97949 \nL 1666.79869 64.97949 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_129\">\n    <g clip-path=\"url(#p1357368455)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"1649.030112\" xlink:href=\"#m4351f6c29f\" y=\"175.432158\"/>\n    </g>\n   </g>\n   <g id=\"line2d_130\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1178.344116 41.968553 \nL 1249.418427 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_131\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1250.868923 101.797029 \nL 1321.943234 101.797029 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_132\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1359.656133 39.667419 \nL 1430.730444 39.667419 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_133\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1432.18094 101.797029 \nL 1503.255251 101.797029 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_134\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1540.96815 41.968553 \nL 1612.042461 41.968553 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_135\">\n    <path clip-path=\"url(#p1357368455)\" d=\"M 1613.492957 111.001414 \nL 1684.567268 111.001414 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 1159.487666 385.292187 \nL 1159.487666 20.798437 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 1159.487666 385.292187 \nL 1703.423717 385.292187 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_25\">\n    <!-- model = RF -->\n    <g style=\"fill:#262626;\" transform=\"translate(1402.168192 14.798437)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"426.953125\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"458.740234\" xlink:href=\"#DejaVuSans-82\"/>\n     <use x=\"528.222656\" xlink:href=\"#DejaVuSans-70\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"legend_1\">\n   <g id=\"text_26\">\n    <!-- acc_type -->\n    <g style=\"fill:#262626;\" transform=\"translate(1737.560905 199.227344)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"171.240234\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"221.240234\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"260.449219\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"319.628906\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"383.105469\" xlink:href=\"#DejaVuSans-101\"/>\n    </g>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 1722.737467 214.183594 \nL 1742.737467 214.183594 \nL 1742.737467 207.183594 \nL 1722.737467 207.183594 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"text_27\">\n    <!-- Train_acc -->\n    <g style=\"fill:#262626;\" transform=\"translate(1750.737467 214.183594)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"239.888672\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"289.888672\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"351.167969\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"406.148438\" xlink:href=\"#DejaVuSans-99\"/>\n    </g>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 1722.737467 229.139844 \nL 1742.737467 229.139844 \nL 1742.737467 222.139844 \nL 1722.737467 222.139844 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"text_28\">\n    <!-- Test_acc -->\n    <g style=\"fill:#262626;\" transform=\"translate(1750.737467 229.139844)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"196.916016\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"246.916016\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"308.195312\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"363.175781\" xlink:href=\"#DejaVuSans-99\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pcc1cc20a31\">\n   <rect height=\"364.49375\" width=\"543.936051\" x=\"50.14375\" y=\"20.798437\"/>\n  </clipPath>\n  <clipPath id=\"p00149dcdd1\">\n   <rect height=\"364.49375\" width=\"543.936051\" x=\"604.815708\" y=\"20.798437\"/>\n  </clipPath>\n  <clipPath id=\"p1357368455\">\n   <rect height=\"364.49375\" width=\"543.936051\" x=\"1159.487666\" y=\"20.798437\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "data_og.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       significance  flux_aper_hilim_s  flux_aper_hilim_u  flux_aper_hilim_m  \\\n",
       "count    460.000000         460.000000         460.000000         460.000000   \n",
       "mean      70.680500         -13.665727         -10.585485         -13.672153   \n",
       "std      109.946267           3.758502           6.281784           3.562725   \n",
       "min        2.110000         -16.403623         -16.286762         -16.438660   \n",
       "25%       11.120000         -15.157782         -14.772950         -15.097236   \n",
       "50%       23.470000         -14.736025         -13.558464         -14.643783   \n",
       "75%       49.260000         -13.884391           0.000000         -13.880179   \n",
       "max      376.060000           0.000000           0.000000           0.000000   \n",
       "\n",
       "       flux_aper_hilim_h  flux_aper_hilim_b  flux_aper_lolim_s  \\\n",
       "count         460.000000         460.000000         460.000000   \n",
       "mean          -13.524028         -13.598865          -9.545423   \n",
       "std             2.445021           1.872480           7.192002   \n",
       "min           -16.050805         -16.001523         -17.513428   \n",
       "25%           -14.486419         -14.402365         -15.235153   \n",
       "50%           -13.813854         -13.795609         -14.031779   \n",
       "75%           -13.312095         -13.246092           0.000000   \n",
       "max             0.000000           0.000000           0.000000   \n",
       "\n",
       "       flux_aper_lolim_u  flux_aper_lolim_m  flux_aper_lolim_h  ...  \\\n",
       "count         460.000000         460.000000         460.000000  ...   \n",
       "mean           -2.479007         -10.270777         -11.095915  ...   \n",
       "std             5.508112           6.885564           5.952367  ...   \n",
       "min           -16.808549         -17.283162         -16.795609  ...   \n",
       "25%             0.000000         -15.289121         -14.680062  ...   \n",
       "50%             0.000000         -14.179348         -13.784101  ...   \n",
       "75%             0.000000           0.000000         -12.544880  ...   \n",
       "max             0.000000           0.000000           0.000000  ...   \n",
       "\n",
       "         flux_brems  flux_brems_lolim  flux_brems_hilim    brems_kt  \\\n",
       "count  4.600000e+02      4.600000e+02      4.600000e+02  460.000000   \n",
       "mean   3.976932e-14      3.684994e-14      4.187235e-14    1.109605   \n",
       "std    1.828352e-13      1.716889e-13      1.908868e-13    8.512305   \n",
       "min    0.000000e+00      0.000000e+00      0.000000e+00    0.000000   \n",
       "25%    0.000000e+00      0.000000e+00      0.000000e+00    0.000000   \n",
       "50%    0.000000e+00      0.000000e+00      0.000000e+00    0.000000   \n",
       "75%    0.000000e+00      0.000000e+00      0.000000e+00    0.000000   \n",
       "max    1.674000e-12      1.627000e-12      1.726000e-12  100.000000   \n",
       "\n",
       "       brems_kt_hilim  brems_kt_lolim     brems_nh  brems_nh_hilim  \\\n",
       "count      460.000000      460.000000   460.000000      460.000000   \n",
       "mean         0.566298        0.565308    16.913367       20.985130   \n",
       "std          2.798337        4.297048   110.659935      138.121021   \n",
       "min          0.000000        0.000000     0.000000        0.000000   \n",
       "25%          0.000000        0.000000     0.000000        0.000000   \n",
       "50%          0.000000        0.000000     0.000000        0.000000   \n",
       "75%          0.000000        0.000000     0.000000        0.000000   \n",
       "max         35.720000       81.320000  1472.000000     1712.000000   \n",
       "\n",
       "       brems_nh_lolim  brems_stat  \n",
       "count      460.000000  460.000000  \n",
       "mean        14.195144    0.158613  \n",
       "std         94.621092    0.603954  \n",
       "min          0.000000    0.000000  \n",
       "25%          0.000000    0.000000  \n",
       "50%          0.000000    0.000000  \n",
       "75%          0.000000    0.000000  \n",
       "max       1380.000000    9.074000  \n",
       "\n",
       "[8 rows x 93 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>significance</th>\n",
       "      <th>flux_aper_hilim_s</th>\n",
       "      <th>flux_aper_hilim_u</th>\n",
       "      <th>flux_aper_hilim_m</th>\n",
       "      <th>flux_aper_hilim_h</th>\n",
       "      <th>flux_aper_hilim_b</th>\n",
       "      <th>flux_aper_lolim_s</th>\n",
       "      <th>flux_aper_lolim_u</th>\n",
       "      <th>flux_aper_lolim_m</th>\n",
       "      <th>flux_aper_lolim_h</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_brems</th>\n",
       "      <th>flux_brems_lolim</th>\n",
       "      <th>flux_brems_hilim</th>\n",
       "      <th>brems_kt</th>\n",
       "      <th>brems_kt_hilim</th>\n",
       "      <th>brems_kt_lolim</th>\n",
       "      <th>brems_nh</th>\n",
       "      <th>brems_nh_hilim</th>\n",
       "      <th>brems_nh_lolim</th>\n",
       "      <th>brems_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.680500</td>\n",
       "      <td>-13.665727</td>\n",
       "      <td>-10.585485</td>\n",
       "      <td>-13.672153</td>\n",
       "      <td>-13.524028</td>\n",
       "      <td>-13.598865</td>\n",
       "      <td>-9.545423</td>\n",
       "      <td>-2.479007</td>\n",
       "      <td>-10.270777</td>\n",
       "      <td>-11.095915</td>\n",
       "      <td>...</td>\n",
       "      <td>3.976932e-14</td>\n",
       "      <td>3.684994e-14</td>\n",
       "      <td>4.187235e-14</td>\n",
       "      <td>1.109605</td>\n",
       "      <td>0.566298</td>\n",
       "      <td>0.565308</td>\n",
       "      <td>16.913367</td>\n",
       "      <td>20.985130</td>\n",
       "      <td>14.195144</td>\n",
       "      <td>0.158613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>109.946267</td>\n",
       "      <td>3.758502</td>\n",
       "      <td>6.281784</td>\n",
       "      <td>3.562725</td>\n",
       "      <td>2.445021</td>\n",
       "      <td>1.872480</td>\n",
       "      <td>7.192002</td>\n",
       "      <td>5.508112</td>\n",
       "      <td>6.885564</td>\n",
       "      <td>5.952367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.828352e-13</td>\n",
       "      <td>1.716889e-13</td>\n",
       "      <td>1.908868e-13</td>\n",
       "      <td>8.512305</td>\n",
       "      <td>2.798337</td>\n",
       "      <td>4.297048</td>\n",
       "      <td>110.659935</td>\n",
       "      <td>138.121021</td>\n",
       "      <td>94.621092</td>\n",
       "      <td>0.603954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.110000</td>\n",
       "      <td>-16.403623</td>\n",
       "      <td>-16.286762</td>\n",
       "      <td>-16.438660</td>\n",
       "      <td>-16.050805</td>\n",
       "      <td>-16.001523</td>\n",
       "      <td>-17.513428</td>\n",
       "      <td>-16.808549</td>\n",
       "      <td>-17.283162</td>\n",
       "      <td>-16.795609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.120000</td>\n",
       "      <td>-15.157782</td>\n",
       "      <td>-14.772950</td>\n",
       "      <td>-15.097236</td>\n",
       "      <td>-14.486419</td>\n",
       "      <td>-14.402365</td>\n",
       "      <td>-15.235153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.289121</td>\n",
       "      <td>-14.680062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.470000</td>\n",
       "      <td>-14.736025</td>\n",
       "      <td>-13.558464</td>\n",
       "      <td>-14.643783</td>\n",
       "      <td>-13.813854</td>\n",
       "      <td>-13.795609</td>\n",
       "      <td>-14.031779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.179348</td>\n",
       "      <td>-13.784101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.260000</td>\n",
       "      <td>-13.884391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.880179</td>\n",
       "      <td>-13.312095</td>\n",
       "      <td>-13.246092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.544880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>376.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.674000e-12</td>\n",
       "      <td>1.627000e-12</td>\n",
       "      <td>1.726000e-12</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.720000</td>\n",
       "      <td>81.320000</td>\n",
       "      <td>1472.000000</td>\n",
       "      <td>1712.000000</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>9.074000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 93 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "with open(\"plot.html\", \"w\") as f:\n",
    "    f.write(tfdf.model_plotter.plot_model(\n",
    "        model ,\n",
    "        tree_idx = 250 ,\n",
    "        max_depth = 20\n",
    "        ))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison across Imputation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "data_corr = pd.read_csv('processed_data/train_norm_corr' , index_col=0).reset_index(drop=True)\n",
    "data_zero = pd.read_csv('processed_data/train_norm_zero' , index_col=0).reset_index(drop=True)\n",
    "data_mean = pd.read_csv('processed_data/train_norm_mean' , index_col=0).reset_index(drop=True)\n",
    "data_median = pd.read_csv('processed_data/train_norm_median' , index_col=0).reset_index(drop=True)\n",
    "data_corr.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  class                 src_n  src_id  significance  flux_aper_hilim_s  \\\n",
       "0    NS  J1748-2021#2          NS0056          6.25           0.335171   \n",
       "1    NS  EXO 1745-248          NS0020         23.47           0.354061   \n",
       "\n",
       "   flux_aper_hilim_u  flux_aper_hilim_m  flux_aper_hilim_h  flux_aper_hilim_b  \\\n",
       "0           0.168648           0.376587           0.254273           0.287741   \n",
       "1           0.569897           0.493711           0.459409           0.481761   \n",
       "\n",
       "   flux_aper_lolim_s  ...  flux_brems  flux_brems_lolim  flux_brems_hilim  \\\n",
       "0           0.376253  ...    0.039243          0.043996          0.036741   \n",
       "1           0.403466  ...    0.040868          0.045665          0.038351   \n",
       "\n",
       "   brems_kt  brems_kt_hilim  brems_kt_lolim  brems_nh  brems_nh_hilim  \\\n",
       "0  0.331771        0.049034        0.434538  0.905741        0.850661   \n",
       "1  0.453253        0.062636        0.616169  1.001875        0.941022   \n",
       "\n",
       "   brems_nh_lolim  brems_stat  \n",
       "0        0.986117    0.694600  \n",
       "1        1.090491    0.705692  \n",
       "\n",
       "[2 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>src_n</th>\n",
       "      <th>src_id</th>\n",
       "      <th>significance</th>\n",
       "      <th>flux_aper_hilim_s</th>\n",
       "      <th>flux_aper_hilim_u</th>\n",
       "      <th>flux_aper_hilim_m</th>\n",
       "      <th>flux_aper_hilim_h</th>\n",
       "      <th>flux_aper_hilim_b</th>\n",
       "      <th>flux_aper_lolim_s</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_brems</th>\n",
       "      <th>flux_brems_lolim</th>\n",
       "      <th>flux_brems_hilim</th>\n",
       "      <th>brems_kt</th>\n",
       "      <th>brems_kt_hilim</th>\n",
       "      <th>brems_kt_lolim</th>\n",
       "      <th>brems_nh</th>\n",
       "      <th>brems_nh_hilim</th>\n",
       "      <th>brems_nh_lolim</th>\n",
       "      <th>brems_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NS</td>\n",
       "      <td>J1748-2021#2</td>\n",
       "      <td>NS0056</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.335171</td>\n",
       "      <td>0.168648</td>\n",
       "      <td>0.376587</td>\n",
       "      <td>0.254273</td>\n",
       "      <td>0.287741</td>\n",
       "      <td>0.376253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039243</td>\n",
       "      <td>0.043996</td>\n",
       "      <td>0.036741</td>\n",
       "      <td>0.331771</td>\n",
       "      <td>0.049034</td>\n",
       "      <td>0.434538</td>\n",
       "      <td>0.905741</td>\n",
       "      <td>0.850661</td>\n",
       "      <td>0.986117</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NS</td>\n",
       "      <td>EXO 1745-248</td>\n",
       "      <td>NS0020</td>\n",
       "      <td>23.47</td>\n",
       "      <td>0.354061</td>\n",
       "      <td>0.569897</td>\n",
       "      <td>0.493711</td>\n",
       "      <td>0.459409</td>\n",
       "      <td>0.481761</td>\n",
       "      <td>0.403466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040868</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.038351</td>\n",
       "      <td>0.453253</td>\n",
       "      <td>0.062636</td>\n",
       "      <td>0.616169</td>\n",
       "      <td>1.001875</td>\n",
       "      <td>0.941022</td>\n",
       "      <td>1.090491</td>\n",
       "      <td>0.705692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 96 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "acc_zero = mc_validation(gen_model_rf , data_corr , obs_split ,model_name = 'RF' , d_type='Normalized' , impute_method='Zero')\n",
    "acc_mean = mc_validation(gen_model_rf , data_zero , obs_split, model_name = 'RF' , d_type = 'Normalized' ,  impute_method='mean')\n",
    "acc_median = mc_validation(gen_model_rf , data_mean  , obs_split ,  model_name = 'RF' , d_type = 'Normalized' ,  impute_method='median')\n",
    "acc_corr = mc_validation(gen_model_rf , data_median  , obs_split ,  model_name = 'RF' , d_type = 'Normalized' ,  impute_method='correlation')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "acc_data =  pd.concat([acc_zero , acc_mean , acc_median , acc_corr]).reset_index(drop=True)\n",
    "acc_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    model impute_method data_processing   acc_type  accuracy\n",
       "0      RF          Zero      Normalized  Train_acc  0.991848\n",
       "1      RF          Zero      Normalized  Train_acc  0.991848\n",
       "2      RF          Zero      Normalized  Train_acc  0.991848\n",
       "3      RF          Zero      Normalized  Train_acc  0.991848\n",
       "4      RF          Zero      Normalized  Train_acc  0.994565\n",
       "..    ...           ...             ...        ...       ...\n",
       "251    RF   correlation      Normalized   Test_acc  0.934783\n",
       "252    RF   correlation      Normalized   Test_acc  0.923913\n",
       "253    RF   correlation      Normalized   Test_acc  0.913043\n",
       "254    RF   correlation      Normalized   Test_acc  0.923913\n",
       "255    RF   correlation      Normalized   Test_acc  0.880435\n",
       "\n",
       "[256 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>impute_method</th>\n",
       "      <th>data_processing</th>\n",
       "      <th>acc_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>Zero</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>Zero</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>Zero</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>Zero</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.991848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>Zero</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Train_acc</td>\n",
       "      <td>0.994565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>RF</td>\n",
       "      <td>correlation</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>RF</td>\n",
       "      <td>correlation</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>RF</td>\n",
       "      <td>correlation</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>RF</td>\n",
       "      <td>correlation</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>RF</td>\n",
       "      <td>correlation</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>Test_acc</td>\n",
       "      <td>0.880435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "acc_data.to_csv('result/acc_rf_norm_all')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "sns.catplot(data = acc_data , y='accuracy' , x = 'impute_method' ,\n",
    "            hue= 'acc_type'  , kind='box' ,  col ='model' , \n",
    "            palette = 'crest' , height=6 , aspect=8/6\n",
    "            )\n",
    "plt.savefig('result/model_var_rf.jpg')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 658.125x432 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"423.126562pt\" version=\"1.1\" viewBox=\"0 0 648.712402 423.126562\" width=\"648.712402pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-10-11T00:45:47.819475</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 423.126562 \nL 648.712402 423.126562 \nL 648.712402 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 385.292187 \nL 557.806152 385.292187 \nL 557.806152 20.798437 \nL 50.14375 20.798437 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"text_1\">\n      <!-- Zero -->\n      <g style=\"fill:#262626;\" transform=\"translate(102.097644 399.890625)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 5.609375 72.90625 \nL 62.890625 72.90625 \nL 62.890625 65.375 \nL 16.796875 8.296875 \nL 64.015625 8.296875 \nL 64.015625 0 \nL 4.5 0 \nL 4.5 7.515625 \nL 50.59375 64.59375 \nL 5.609375 64.59375 \nz\n\" id=\"DejaVuSans-90\"/>\n        <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n        <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n        <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-90\"/>\n       <use x=\"68.505859\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"130.029297\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"168.892578\" xlink:href=\"#DejaVuSans-111\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"text_2\">\n      <!-- mean -->\n      <g style=\"fill:#262626;\" transform=\"translate(226.337463 399.890625)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n        <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n        <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-109\"/>\n       <use x=\"97.412109\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"158.935547\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"220.214844\" xlink:href=\"#DejaVuSans-110\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"text_3\">\n      <!-- median -->\n      <g style=\"fill:#262626;\" transform=\"translate(348.689783 399.890625)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n        <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-109\"/>\n       <use x=\"97.412109\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"158.935547\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"222.412109\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"250.195312\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"311.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"text_4\">\n      <!-- correlation -->\n      <g style=\"fill:#262626;\" transform=\"translate(467.52179 399.890625)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n        <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n        <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-99\"/>\n       <use x=\"54.980469\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"116.162109\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"155.525391\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"194.388672\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"255.912109\" xlink:href=\"#DejaVuSans-108\"/>\n       <use x=\"283.695312\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"344.974609\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"384.183594\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"411.966797\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"473.148438\" xlink:href=\"#DejaVuSans-110\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- impute_method -->\n     <g style=\"fill:#262626;\" transform=\"translate(264.526514 413.56875)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"125.195312\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"188.671875\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"252.050781\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"291.259766\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"352.783203\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"402.783203\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"500.195312\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"561.71875\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"600.927734\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"664.306641\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"725.488281\" xlink:href=\"#DejaVuSans-100\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 362.5389 \nL 557.806152 362.5389 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.84 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 366.338119)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 321.892329 \nL 557.806152 321.892329 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.86 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 325.691548)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 281.245759 \nL 557.806152 281.245759 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.88 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 285.044978)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 240.599188 \nL 557.806152 240.599188 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.90 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 244.398407)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 199.952618 \nL 557.806152 199.952618 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.92 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 203.751836)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 159.306047 \nL 557.806152 159.306047 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.94 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 163.105266)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 118.659476 \nL 557.806152 118.659476 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.96 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 122.458695)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 78.012906 \nL 557.806152 78.012906 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.98 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 81.812125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p377dd5478f)\" d=\"M 50.14375 37.366335 \nL 557.806152 37.366335 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.00 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.878125 41.165554)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- accuracy -->\n     <g style=\"fill:#262626;\" transform=\"translate(14.798438 225.604687)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 63.342972 53.934257 \nL 113.093888 53.934257 \nL 113.093888 48.411657 \nL 63.342972 48.411657 \nL 63.342972 53.934257 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 114.109213 302.452723 \nL 163.860128 302.452723 \nL 163.860128 236.181035 \nL 114.109213 236.181035 \nL 114.109213 302.452723 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 190.258573 53.934257 \nL 240.009488 53.934257 \nL 240.009488 48.411657 \nL 190.258573 48.411657 \nL 190.258573 53.934257 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 241.024813 236.181035 \nL 290.775729 236.181035 \nL 290.775729 147.818946 \nL 241.024813 147.818946 \nL 241.024813 236.181035 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 317.174174 53.934257 \nL 366.925089 53.934257 \nL 366.925089 42.888936 \nL 317.174174 42.888936 \nL 317.174174 53.934257 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 367.940414 241.703666 \nL 417.691329 241.703666 \nL 417.691329 164.386838 \nL 367.940414 164.386838 \nL 367.940414 241.703666 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 444.089774 53.934257 \nL 493.84069 53.934257 \nL 493.84069 42.888936 \nL 444.089774 42.888936 \nL 444.089774 53.934257 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 494.856014 236.181035 \nL 544.60693 236.181035 \nL 544.60693 169.909469 \nL 494.856014 169.909469 \nL 494.856014 236.181035 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 113.60155 2069.694865 \nL 113.60155 2069.694865 \nL 113.60155 2069.694865 \nL 113.60155 2069.694865 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 113.60155 2069.694865 \nL 113.60155 2069.694865 \nL 113.60155 2069.694865 \nL 113.60155 2069.694865 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"line2d_10\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 88.21843 53.934257 \nL 88.21843 59.456857 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 88.21843 48.411657 \nL 88.21843 42.888936 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 75.780701 59.456857 \nL 100.656159 59.456857 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 75.780701 42.888936 \nL 100.656159 42.888936 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <defs>\n     <path d=\"M -0 3.535534 \nL 2.12132 0 \nL -0 -3.535534 \nL -2.12132 -0 \nz\n\" id=\"m2d7b8d3ebb\" style=\"stroke:#323232;stroke-linejoin:miter;\"/>\n    </defs>\n    <g clip-path=\"url(#p377dd5478f)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"88.21843\" xlink:href=\"#m2d7b8d3ebb\" y=\"64.979458\"/>\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"88.21843\" xlink:href=\"#m2d7b8d3ebb\" y=\"64.979458\"/>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 138.98467 302.452723 \nL 138.98467 368.72429 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 138.98467 236.181035 \nL 138.98467 147.818946 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 126.546942 368.72429 \nL 151.422399 368.72429 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 126.546942 147.818946 \nL 151.422399 147.818946 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\"/>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 215.134031 53.934257 \nL 215.134031 59.456857 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 215.134031 48.411657 \nL 215.134031 42.888936 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 202.696302 59.456857 \nL 227.57176 59.456857 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 202.696302 42.888936 \nL 227.57176 42.888936 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <g clip-path=\"url(#p377dd5478f)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"215.134031\" xlink:href=\"#m2d7b8d3ebb\" y=\"64.979458\"/>\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"215.134031\" xlink:href=\"#m2d7b8d3ebb\" y=\"37.366335\"/>\n    </g>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 265.900271 236.181035 \nL 265.900271 346.633768 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 265.900271 147.818946 \nL 265.900271 103.637902 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 253.462542 346.633768 \nL 278.338 346.633768 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 253.462542 103.637902 \nL 278.338 103.637902 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_29\"/>\n   <g id=\"line2d_30\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 342.049631 53.934257 \nL 342.049631 64.979458 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 342.049631 42.888936 \nL 342.049631 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 329.611902 64.979458 \nL 354.48736 64.979458 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 329.611902 37.366335 \nL 354.48736 37.366335 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_34\"/>\n   <g id=\"line2d_35\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 392.815872 241.703666 \nL 392.815872 302.452723 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 392.815872 164.386838 \nL 392.815872 103.637902 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 380.378143 302.452723 \nL 405.2536 302.452723 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 380.378143 103.637902 \nL 405.2536 103.637902 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_39\"/>\n   <g id=\"line2d_40\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 468.965232 53.934257 \nL 468.965232 59.456857 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 468.965232 42.888936 \nL 468.965232 42.888936 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 456.527503 59.456857 \nL 481.402961 59.456857 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 456.527503 42.888936 \nL 481.402961 42.888936 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_44\"/>\n   <g id=\"line2d_45\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 519.731472 236.181035 \nL 519.731472 280.36208 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 519.731472 169.909469 \nL 519.731472 81.54738 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 507.293743 280.36208 \nL 532.169201 280.36208 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 507.293743 81.54738 \nL 532.169201 81.54738 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <g clip-path=\"url(#p377dd5478f)\">\n     <use style=\"fill:#323232;stroke:#323232;stroke-linejoin:miter;\" x=\"519.731472\" xlink:href=\"#m2d7b8d3ebb\" y=\"346.633768\"/>\n    </g>\n   </g>\n   <g id=\"line2d_50\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 63.342972 53.934257 \nL 113.093888 53.934257 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 114.109213 258.271558 \nL 163.860128 258.271558 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 190.258573 53.934257 \nL 240.009488 53.934257 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 241.024813 191.999991 \nL 290.775729 191.999991 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 317.174174 48.411657 \nL 366.925089 48.411657 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 367.940414 214.090513 \nL 417.691329 214.090513 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 444.089774 48.411657 \nL 493.84069 48.411657 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path clip-path=\"url(#p377dd5478f)\" d=\"M 494.856014 214.090513 \nL 544.60693 214.090513 \n\" style=\"fill:none;stroke:#323232;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 50.14375 385.292187 \nL 50.14375 20.798437 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 50.14375 385.292187 \nL 557.806152 385.292187 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- model = RF -->\n    <g style=\"fill:#262626;\" transform=\"translate(274.687451 14.798437)scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      <path d=\"M 9.8125 72.90625 \nL 51.703125 72.90625 \nL 51.703125 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.109375 \nL 48.578125 43.109375 \nL 48.578125 34.8125 \nL 19.671875 34.8125 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-70\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"426.953125\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"458.740234\" xlink:href=\"#DejaVuSans-82\"/>\n     <use x=\"528.222656\" xlink:href=\"#DejaVuSans-70\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"legend_1\">\n   <g id=\"text_17\">\n    <!-- acc_type -->\n    <g style=\"fill:#262626;\" transform=\"translate(580.42334 199.227344)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"171.240234\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"221.240234\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"260.449219\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"319.628906\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"383.105469\" xlink:href=\"#DejaVuSans-101\"/>\n    </g>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 565.599902 214.183594 \nL 585.599902 214.183594 \nL 585.599902 207.183594 \nL 565.599902 207.183594 \nz\n\" style=\"fill:#5a948a;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Train_acc -->\n    <g style=\"fill:#262626;\" transform=\"translate(593.599902 214.183594)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"239.888672\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"289.888672\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"351.167969\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"406.148438\" xlink:href=\"#DejaVuSans-99\"/>\n    </g>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 565.599902 229.139844 \nL 585.599902 229.139844 \nL 585.599902 222.139844 \nL 565.599902 222.139844 \nz\n\" style=\"fill:#2b667c;stroke:#323232;stroke-linejoin:miter;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"text_19\">\n    <!-- Test_acc -->\n    <g style=\"fill:#262626;\" transform=\"translate(593.599902 229.139844)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"196.916016\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"246.916016\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"308.195312\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"363.175781\" xlink:href=\"#DejaVuSans-99\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p377dd5478f\">\n   <rect height=\"364.49375\" width=\"507.662402\" x=\"50.14375\" y=\"20.798437\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}