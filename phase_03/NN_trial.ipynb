{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data =  pd.read_csv('all_data_compiled.csv')\n",
    "print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      index_compiled  index  class  B_B_FLUX_AP  B_B_FLUX_AP_HI  \\\n",
      "0                  0     89    1.0     0.000174        0.000182   \n",
      "1                  1    370    1.0     0.000462        0.000477   \n",
      "2                  2    645    0.0     0.000003        0.000003   \n",
      "3                  3    275    1.0     0.000002        0.000002   \n",
      "4                  4    474    0.0     0.000002        0.000002   \n",
      "...              ...    ...    ...          ...             ...   \n",
      "1466            1466    221    1.0     0.000002        0.000002   \n",
      "1467            1467    864    0.0     0.000000        0.000000   \n",
      "1468            1468    777    0.0     0.000080        0.000084   \n",
      "1469            1469    831    0.0     0.000000        0.000000   \n",
      "1470            1470    374    1.0     0.001739        0.001878   \n",
      "\n",
      "      B_B_FLUX_AP_LO  B_M_FLUX_AP  B_M_FLUX_AP_HI  B_M_FLUX_AP_LO  \\\n",
      "0           0.000166     0.000569        0.000616        0.000526   \n",
      "1           0.000444     0.005532        0.005737        0.005294   \n",
      "2           0.000002     0.000021        0.000027        0.000016   \n",
      "3           0.000002     0.000016        0.000018        0.000014   \n",
      "4           0.000002     0.000018        0.000021        0.000014   \n",
      "...              ...          ...             ...             ...   \n",
      "1466        0.000001     0.000014        0.000016        0.000012   \n",
      "1467        0.000000     0.000000        0.000000        0.000000   \n",
      "1468        0.000076     0.000446        0.000478        0.000409   \n",
      "1469        0.000000     0.000000        0.000000        0.000000   \n",
      "1470        0.001585     0.000214        0.000341        0.000085   \n",
      "\n",
      "      B_APEC_ABUND  ...  B_U_PHOTFLUX_AP_AVG  B_U_PHOTFLUX_AP_AVG_HI  \\\n",
      "0              0.0  ...             0.000635                0.001227   \n",
      "1              0.0  ...             0.003835                0.004409   \n",
      "2              0.0  ...             0.000000                0.000000   \n",
      "3              0.0  ...             0.000000                0.000011   \n",
      "4              0.0  ...             0.000027                0.000037   \n",
      "...            ...  ...                  ...                     ...   \n",
      "1466           0.0  ...             0.000035                0.000049   \n",
      "1467           0.0  ...             0.000000                0.000090   \n",
      "1468           0.0  ...             0.000200                0.000225   \n",
      "1469           0.0  ...             0.002477                0.002582   \n",
      "1470           0.0  ...             0.000000                0.003636   \n",
      "\n",
      "      B_U_PHOTFLUX_AP_AVG_LO  B_U_PHOTFLUX_AP_HI  B_U_PHOTFLUX_AP_LO  \\\n",
      "0                   0.000000            0.001227            0.000000   \n",
      "1                   0.003213            0.000838            0.000039   \n",
      "2                   0.000000            0.000089            0.000041   \n",
      "3                   0.000000            0.000015            0.000000   \n",
      "4                   0.000016            0.000037            0.000016   \n",
      "...                      ...                 ...                 ...   \n",
      "1466                0.000021            0.000081            0.000041   \n",
      "1467                0.000000            0.000000            0.000000   \n",
      "1468                0.000174            0.000163            0.000075   \n",
      "1469                0.002370            0.000000            0.000000   \n",
      "1470                0.000000            0.003636            0.000000   \n",
      "\n",
      "      B_U_VAR_INTER_INDEX  B_U_VAR_INTER_PROB  B_U_VAR_INTER_SIGMA  \\\n",
      "0                   0.625             0.74100             0.004752   \n",
      "1                   0.000             0.00000             0.000000   \n",
      "2                   0.000             0.07640             0.000077   \n",
      "3                   0.000             0.00000             0.000000   \n",
      "4                   0.000             0.00106             0.000483   \n",
      "...                   ...                 ...                  ...   \n",
      "1466                0.625             0.90500             0.001147   \n",
      "1467                0.000             0.00000             0.000000   \n",
      "1468                0.750             0.93400             0.005295   \n",
      "1469                0.000             0.32500             0.001853   \n",
      "1470                0.000             0.00000             0.000000   \n",
      "\n",
      "      B_U_VAR_INTRA_INDEX  B_U_VAR_INTRA_PROB  \n",
      "0                     0.0                0.00  \n",
      "1                     0.2                0.74  \n",
      "2                     0.0                0.00  \n",
      "3                     0.0                0.00  \n",
      "4                     0.0                0.00  \n",
      "...                   ...                 ...  \n",
      "1466                  0.0                0.00  \n",
      "1467                  0.0                0.00  \n",
      "1468                  0.0                0.00  \n",
      "1469                  0.0                0.00  \n",
      "1470                  0.0                0.00  \n",
      "\n",
      "[1471 rows x 364 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(data.shape)\n",
    "x = data.drop(['index_compiled', 'index', 'class'],axis=1)\n",
    "print(x.shape)\n",
    "y = data['class']\n",
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1471, 364)\n",
      "(1471, 361)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1471,)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "x_np =  x.to_numpy()\n",
    "y_np =  y.to_numpy()\n",
    "x_train = x_np[:1000,:]\n",
    "y_train = y_np[:1000]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 361)\n",
      "(1000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def split_data(x,y,s):   \n",
    "    split = 0.7 \n",
    "    split_no = int(split*len(y))\n",
    "    x_train = x[:split_no, :]\n",
    "    y_train = y[:split_no]\n",
    "    x_test = x[split_no:, :]\n",
    "    y_test = y[split_no:]\n",
    "    return ((x_train,y_train) , (x_test ,y_test))\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = split_data(x_np, y_np, 0.8)\n",
    "print(x_train.shape ,y_train.shape)\n",
    "print(x_test.shape ,y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1029, 361) (1029,)\n",
      "(442, 361) (442,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Netork starts here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "one_hot_y_train =  to_categorical(y_train)\n",
    "one_hot_y_test =  to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def model_gen(shape):\n",
    "\n",
    "    inputs =  keras.Input(shape=(361,))\n",
    "    dense =  layers.Dense(64, activation='relu')\n",
    "    x = dense(inputs)\n",
    "    x =  layers.BatchNormalization(axis=-1)(x)\n",
    "    #x = layers.Dropout(0.3)(x)\n",
    "    for s in shape:\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    outputs = layers.Dense(2 , activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=inputs , outputs=outputs , name='trial_model')\n",
    "    model.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = keras.optimizers.Adam(),\n",
    "        metrics = [\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "model = model_gen([64,64,32,8])\n",
    "history = model.fit(x_train, one_hot_y_train, batch_size=128, epochs=40, validation_split=0.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 0.6239 - accuracy: 0.6836 - val_loss: 0.6643 - val_accuracy: 0.6408\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7765 - val_loss: 0.6267 - val_accuracy: 0.6796\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8132 - val_loss: 0.6031 - val_accuracy: 0.6990\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8488 - val_loss: 0.5974 - val_accuracy: 0.7184\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3337 - accuracy: 0.8542 - val_loss: 0.5836 - val_accuracy: 0.7087\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2945 - accuracy: 0.8737 - val_loss: 0.5761 - val_accuracy: 0.7476\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2684 - accuracy: 0.8898 - val_loss: 0.5659 - val_accuracy: 0.6990\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2402 - accuracy: 0.8974 - val_loss: 0.5553 - val_accuracy: 0.7573\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2134 - accuracy: 0.9190 - val_loss: 0.5483 - val_accuracy: 0.6990\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1924 - accuracy: 0.9212 - val_loss: 0.5353 - val_accuracy: 0.7476\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.9406 - val_loss: 0.5299 - val_accuracy: 0.7184\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1580 - accuracy: 0.9428 - val_loss: 0.5289 - val_accuracy: 0.7087\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9330 - val_loss: 0.5086 - val_accuracy: 0.7767\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.9417 - val_loss: 0.5140 - val_accuracy: 0.7184\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9158 - val_loss: 0.5156 - val_accuracy: 0.7282\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9374 - val_loss: 0.4932 - val_accuracy: 0.7961\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9428 - val_loss: 0.5236 - val_accuracy: 0.7282\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9460 - val_loss: 0.4874 - val_accuracy: 0.7767\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9492 - val_loss: 0.4861 - val_accuracy: 0.8058\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9557 - val_loss: 0.4816 - val_accuracy: 0.7961\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9579 - val_loss: 0.4761 - val_accuracy: 0.7864\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9568 - val_loss: 0.4566 - val_accuracy: 0.8058\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9406 - val_loss: 0.4510 - val_accuracy: 0.7961\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9482 - val_loss: 0.4378 - val_accuracy: 0.8252\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1235 - accuracy: 0.9460 - val_loss: 0.4966 - val_accuracy: 0.7670\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9428 - val_loss: 0.4763 - val_accuracy: 0.7476\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.9395 - val_loss: 0.5647 - val_accuracy: 0.7087\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9438 - val_loss: 0.5180 - val_accuracy: 0.7379\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9568 - val_loss: 0.4990 - val_accuracy: 0.7379\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9536 - val_loss: 0.5197 - val_accuracy: 0.7379\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9611 - val_loss: 0.4960 - val_accuracy: 0.7864\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9600 - val_loss: 0.5171 - val_accuracy: 0.7476\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1024 - accuracy: 0.9568 - val_loss: 0.5440 - val_accuracy: 0.7573\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.9590 - val_loss: 0.5403 - val_accuracy: 0.7670\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9600 - val_loss: 0.5268 - val_accuracy: 0.7670\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1007 - accuracy: 0.9525 - val_loss: 0.4851 - val_accuracy: 0.7864\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0932 - accuracy: 0.9568 - val_loss: 0.5335 - val_accuracy: 0.7573\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9590 - val_loss: 0.5265 - val_accuracy: 0.7379\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0943 - accuracy: 0.9600 - val_loss: 0.4739 - val_accuracy: 0.8155\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9557 - val_loss: 0.4886 - val_accuracy: 0.7573\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "def acc_score(model , y_test , x_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    correct = 0\n",
    "    total =  len(y_test)\n",
    "    for y1,y2 in zip(y_pred,y_test):\n",
    "        if(int(y1)==int(y2)):\n",
    "            correct+=1\n",
    "        else:\n",
    "            continue\n",
    "    print('correct prediction :' , correct)\n",
    "    print('total prediction :' , total)\n",
    "    print('score: ' , correct/total*100)\n",
    "    \n",
    "print('training data prediction')\n",
    "acc_score(model, one_hot_y_train, x_train)\n",
    "print('----------------------------------')\n",
    "print('test data prediciton')\n",
    "acc_score(model, y_test, x_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training data prediction\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-299d592894d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training data prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0macc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test data prediciton'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-299d592894d4>\u001b[0m in \u001b[0;36macc_score\u001b[0;34m(model, y_test, x_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mcorrect\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "res = model.predict(x_test)\n",
    "res = [np.argmax(r) for r in res]\n",
    "print(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "count = 0\n",
    "for a,b in zip(res,y_test):\n",
    "    if(int(a)==int(b)):\n",
    "        count+=1\n",
    "print(count , len(y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "369 442\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}